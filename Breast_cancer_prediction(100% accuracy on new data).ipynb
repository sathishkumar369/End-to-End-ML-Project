{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(r\"C:\\Users\\sathish kumar\\Downloads\\breast_cancer_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "      ...       texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0     ...               17.33           184.60      2019.0            0.1622   \n",
       "1     ...               23.41           158.80      1956.0            0.1238   \n",
       "2     ...               25.53           152.50      1709.0            0.1444   \n",
       "3     ...               26.50            98.87       567.7            0.2098   \n",
       "4     ...               16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>926424</td>\n",
       "      <td>M</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>...</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>926682</td>\n",
       "      <td>M</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>...</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>926954</td>\n",
       "      <td>M</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>...</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>927241</td>\n",
       "      <td>M</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>92751</td>\n",
       "      <td>B</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "564  926424         M        21.56         22.39          142.00     1479.0   \n",
       "565  926682         M        20.13         28.25          131.20     1261.0   \n",
       "566  926954         M        16.60         28.08          108.30      858.1   \n",
       "567  927241         M        20.60         29.33          140.10     1265.0   \n",
       "568   92751         B         7.76         24.54           47.92      181.0   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "564          0.11100           0.11590         0.24390              0.13890   \n",
       "565          0.09780           0.10340         0.14400              0.09791   \n",
       "566          0.08455           0.10230         0.09251              0.05302   \n",
       "567          0.11780           0.27700         0.35140              0.15200   \n",
       "568          0.05263           0.04362         0.00000              0.00000   \n",
       "\n",
       "        ...       texture_worst  perimeter_worst  area_worst  \\\n",
       "564     ...               26.40           166.10      2027.0   \n",
       "565     ...               38.25           155.00      1731.0   \n",
       "566     ...               34.12           126.70      1124.0   \n",
       "567     ...               39.42           184.60      1821.0   \n",
       "568     ...               30.37            59.16       268.6   \n",
       "\n",
       "     smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     concave points_worst  symmetry_worst  fractal_dimension_worst  \\\n",
       "564                0.2216          0.2060                  0.07115   \n",
       "565                0.1628          0.2572                  0.06637   \n",
       "566                0.1418          0.2218                  0.07820   \n",
       "567                0.2650          0.4087                  0.12400   \n",
       "568                0.0000          0.2871                  0.07039   \n",
       "\n",
       "     Unnamed: 32  \n",
       "564          NaN  \n",
       "565          NaN  \n",
       "566          NaN  \n",
       "567          NaN  \n",
       "568          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 33)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
       "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
       "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
       "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
       "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
       "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
       "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
       "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
       "       'symmetry_worst', 'fractal_dimension_worst', 'Unnamed: 32'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                           0\n",
       "diagnosis                    0\n",
       "radius_mean                  0\n",
       "texture_mean                 0\n",
       "perimeter_mean               0\n",
       "area_mean                    0\n",
       "smoothness_mean              0\n",
       "compactness_mean             0\n",
       "concavity_mean               0\n",
       "concave points_mean          0\n",
       "symmetry_mean                0\n",
       "fractal_dimension_mean       0\n",
       "radius_se                    0\n",
       "texture_se                   0\n",
       "perimeter_se                 0\n",
       "area_se                      0\n",
       "smoothness_se                0\n",
       "compactness_se               0\n",
       "concavity_se                 0\n",
       "concave points_se            0\n",
       "symmetry_se                  0\n",
       "fractal_dimension_se         0\n",
       "radius_worst                 0\n",
       "texture_worst                0\n",
       "perimeter_worst              0\n",
       "area_worst                   0\n",
       "smoothness_worst             0\n",
       "compactness_worst            0\n",
       "concavity_worst              0\n",
       "concave points_worst         0\n",
       "symmetry_worst               0\n",
       "fractal_dimension_worst      0\n",
       "Unnamed: 32                569\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop([\"id\",\"Unnamed: 32\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 31 columns):\n",
      "diagnosis                  569 non-null object\n",
      "radius_mean                569 non-null float64\n",
      "texture_mean               569 non-null float64\n",
      "perimeter_mean             569 non-null float64\n",
      "area_mean                  569 non-null float64\n",
      "smoothness_mean            569 non-null float64\n",
      "compactness_mean           569 non-null float64\n",
      "concavity_mean             569 non-null float64\n",
      "concave points_mean        569 non-null float64\n",
      "symmetry_mean              569 non-null float64\n",
      "fractal_dimension_mean     569 non-null float64\n",
      "radius_se                  569 non-null float64\n",
      "texture_se                 569 non-null float64\n",
      "perimeter_se               569 non-null float64\n",
      "area_se                    569 non-null float64\n",
      "smoothness_se              569 non-null float64\n",
      "compactness_se             569 non-null float64\n",
      "concavity_se               569 non-null float64\n",
      "concave points_se          569 non-null float64\n",
      "symmetry_se                569 non-null float64\n",
      "fractal_dimension_se       569 non-null float64\n",
      "radius_worst               569 non-null float64\n",
      "texture_worst              569 non-null float64\n",
      "perimeter_worst            569 non-null float64\n",
      "area_worst                 569 non-null float64\n",
      "smoothness_worst           569 non-null float64\n",
      "compactness_worst          569 non-null float64\n",
      "concavity_worst            569 non-null float64\n",
      "concave points_worst       569 non-null float64\n",
      "symmetry_worst             569 non-null float64\n",
      "fractal_dimension_worst    569 non-null float64\n",
      "dtypes: float64(30), object(1)\n",
      "memory usage: 137.9+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B    357\n",
       "M    212\n",
       "Name: diagnosis, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"diagnosis\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"diagnosis\"]=data[\"diagnosis\"].map({'M':1,'B':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    357\n",
       "0    357\n",
       "Name: diagnosis, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate majority and minority classes\n",
    "majority = data[data.diagnosis==0]\n",
    "minority = data[data.diagnosis==1]\n",
    " \n",
    "# Upsample minority class\n",
    "minority_upsampled = resample(minority, \n",
    "                              replace=True,     # sample with replacement\n",
    "                              n_samples=357,    # to match majority class\n",
    "                              random_state=123) # reproducible results\n",
    " \n",
    "# Combine majority class with upsampled minority class\n",
    "data = pd.concat([majority,minority_upsampled])\n",
    " \n",
    "# Display new class counts\n",
    "data.diagnosis.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1404dc366d8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1404cb644a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(data[\"diagnosis\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['diagnosis'].value_counts().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(714, 31)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.rename(columns={\"diagnosis\":\"Tumor_type\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.pairplot(data=data,palette=\"spring\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1404fcf9748>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1404fc94470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(data['radius_mean'], hist=True, kde=True, \n",
    "             bins=int(180/5), color = 'darkblue', \n",
    "             hist_kws={'edgecolor':'black'},\n",
    "             kde_kws={'linewidth': 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7976512662828419"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['radius_mean'].skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tumor_type                 0.000000\n",
       "radius_mean                0.797651\n",
       "texture_mean               0.509263\n",
       "perimeter_mean             0.828474\n",
       "area_mean                  1.465435\n",
       "smoothness_mean            0.489322\n",
       "compactness_mean           1.006159\n",
       "concavity_mean             1.073639\n",
       "concave points_mean        0.841558\n",
       "symmetry_mean              0.684650\n",
       "fractal_dimension_mean     1.438128\n",
       "radius_se                  2.905742\n",
       "texture_se                 1.658913\n",
       "perimeter_se               3.218599\n",
       "area_se                    4.923419\n",
       "smoothness_se              2.226414\n",
       "compactness_se             1.866881\n",
       "concavity_se               4.757337\n",
       "concave points_se          1.185772\n",
       "symmetry_se                2.380385\n",
       "fractal_dimension_se       3.679429\n",
       "radius_worst               0.856317\n",
       "texture_worst              0.432608\n",
       "perimeter_worst            0.867030\n",
       "area_worst                 1.582251\n",
       "smoothness_worst           0.593922\n",
       "compactness_worst          1.387888\n",
       "concavity_worst            0.980212\n",
       "concave points_worst       0.198814\n",
       "symmetry_worst             1.832479\n",
       "fractal_dimension_worst    1.651566\n",
       "dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.skew(axis = 0, skipna = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tumor_type</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>714.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>714.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>14.743094</td>\n",
       "      <td>19.822787</td>\n",
       "      <td>96.361877</td>\n",
       "      <td>716.140896</td>\n",
       "      <td>0.097935</td>\n",
       "      <td>0.114425</td>\n",
       "      <td>0.104367</td>\n",
       "      <td>0.057225</td>\n",
       "      <td>0.183946</td>\n",
       "      <td>...</td>\n",
       "      <td>17.219144</td>\n",
       "      <td>26.539300</td>\n",
       "      <td>114.116751</td>\n",
       "      <td>988.272829</td>\n",
       "      <td>0.135447</td>\n",
       "      <td>0.285700</td>\n",
       "      <td>0.313170</td>\n",
       "      <td>0.129750</td>\n",
       "      <td>0.297733</td>\n",
       "      <td>0.086164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500351</td>\n",
       "      <td>3.740169</td>\n",
       "      <td>4.278616</td>\n",
       "      <td>25.722626</td>\n",
       "      <td>385.147867</td>\n",
       "      <td>0.014376</td>\n",
       "      <td>0.057457</td>\n",
       "      <td>0.084281</td>\n",
       "      <td>0.040800</td>\n",
       "      <td>0.027590</td>\n",
       "      <td>...</td>\n",
       "      <td>5.144401</td>\n",
       "      <td>6.250088</td>\n",
       "      <td>35.771601</td>\n",
       "      <td>625.941672</td>\n",
       "      <td>0.024615</td>\n",
       "      <td>0.180863</td>\n",
       "      <td>0.224673</td>\n",
       "      <td>0.068828</td>\n",
       "      <td>0.070515</td>\n",
       "      <td>0.020801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.930000</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.992500</td>\n",
       "      <td>16.850000</td>\n",
       "      <td>77.580000</td>\n",
       "      <td>442.550000</td>\n",
       "      <td>0.087593</td>\n",
       "      <td>0.071252</td>\n",
       "      <td>0.035370</td>\n",
       "      <td>0.023432</td>\n",
       "      <td>0.164200</td>\n",
       "      <td>...</td>\n",
       "      <td>13.340000</td>\n",
       "      <td>22.020000</td>\n",
       "      <td>86.677500</td>\n",
       "      <td>546.150000</td>\n",
       "      <td>0.118425</td>\n",
       "      <td>0.161250</td>\n",
       "      <td>0.137800</td>\n",
       "      <td>0.073758</td>\n",
       "      <td>0.253000</td>\n",
       "      <td>0.072280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>13.870000</td>\n",
       "      <td>19.575000</td>\n",
       "      <td>90.470000</td>\n",
       "      <td>597.200000</td>\n",
       "      <td>0.097610</td>\n",
       "      <td>0.104400</td>\n",
       "      <td>0.087410</td>\n",
       "      <td>0.052175</td>\n",
       "      <td>0.181300</td>\n",
       "      <td>...</td>\n",
       "      <td>15.995000</td>\n",
       "      <td>26.295000</td>\n",
       "      <td>105.900000</td>\n",
       "      <td>768.900000</td>\n",
       "      <td>0.134300</td>\n",
       "      <td>0.238400</td>\n",
       "      <td>0.280200</td>\n",
       "      <td>0.127000</td>\n",
       "      <td>0.285750</td>\n",
       "      <td>0.081265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>17.140000</td>\n",
       "      <td>22.202500</td>\n",
       "      <td>111.800000</td>\n",
       "      <td>928.200000</td>\n",
       "      <td>0.106600</td>\n",
       "      <td>0.146900</td>\n",
       "      <td>0.152275</td>\n",
       "      <td>0.086460</td>\n",
       "      <td>0.197750</td>\n",
       "      <td>...</td>\n",
       "      <td>20.380000</td>\n",
       "      <td>30.700000</td>\n",
       "      <td>134.700000</td>\n",
       "      <td>1287.000000</td>\n",
       "      <td>0.150375</td>\n",
       "      <td>0.381300</td>\n",
       "      <td>0.431675</td>\n",
       "      <td>0.183400</td>\n",
       "      <td>0.321950</td>\n",
       "      <td>0.093575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426400</td>\n",
       "      <td>0.187800</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>...</td>\n",
       "      <td>36.040000</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Tumor_type  radius_mean  texture_mean  perimeter_mean    area_mean  \\\n",
       "count  714.000000   714.000000    714.000000      714.000000   714.000000   \n",
       "mean     0.500000    14.743094     19.822787       96.361877   716.140896   \n",
       "std      0.500351     3.740169      4.278616       25.722626   385.147867   \n",
       "min      0.000000     6.981000      9.710000       43.790000   143.500000   \n",
       "25%      0.000000    11.992500     16.850000       77.580000   442.550000   \n",
       "50%      0.500000    13.870000     19.575000       90.470000   597.200000   \n",
       "75%      1.000000    17.140000     22.202500      111.800000   928.200000   \n",
       "max      1.000000    28.110000     39.280000      188.500000  2501.000000   \n",
       "\n",
       "       smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "count       714.000000        714.000000      714.000000           714.000000   \n",
       "mean          0.097935          0.114425        0.104367             0.057225   \n",
       "std           0.014376          0.057457        0.084281             0.040800   \n",
       "min           0.052630          0.019380        0.000000             0.000000   \n",
       "25%           0.087593          0.071252        0.035370             0.023432   \n",
       "50%           0.097610          0.104400        0.087410             0.052175   \n",
       "75%           0.106600          0.146900        0.152275             0.086460   \n",
       "max           0.163400          0.345400        0.426400             0.187800   \n",
       "\n",
       "       symmetry_mean           ...             radius_worst  texture_worst  \\\n",
       "count     714.000000           ...               714.000000     714.000000   \n",
       "mean        0.183946           ...                17.219144      26.539300   \n",
       "std         0.027590           ...                 5.144401       6.250088   \n",
       "min         0.106000           ...                 7.930000      12.020000   \n",
       "25%         0.164200           ...                13.340000      22.020000   \n",
       "50%         0.181300           ...                15.995000      26.295000   \n",
       "75%         0.197750           ...                20.380000      30.700000   \n",
       "max         0.304000           ...                36.040000      49.540000   \n",
       "\n",
       "       perimeter_worst   area_worst  smoothness_worst  compactness_worst  \\\n",
       "count       714.000000   714.000000        714.000000         714.000000   \n",
       "mean        114.116751   988.272829          0.135447           0.285700   \n",
       "std          35.771601   625.941672          0.024615           0.180863   \n",
       "min          50.410000   185.200000          0.071170           0.027290   \n",
       "25%          86.677500   546.150000          0.118425           0.161250   \n",
       "50%         105.900000   768.900000          0.134300           0.238400   \n",
       "75%         134.700000  1287.000000          0.150375           0.381300   \n",
       "max         251.200000  4254.000000          0.222600           1.058000   \n",
       "\n",
       "       concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "count       714.000000            714.000000      714.000000   \n",
       "mean          0.313170              0.129750        0.297733   \n",
       "std           0.224673              0.068828        0.070515   \n",
       "min           0.000000              0.000000        0.156500   \n",
       "25%           0.137800              0.073758        0.253000   \n",
       "50%           0.280200              0.127000        0.285750   \n",
       "75%           0.431675              0.183400        0.321950   \n",
       "max           1.252000              0.291000        0.663800   \n",
       "\n",
       "       fractal_dimension_worst  \n",
       "count               714.000000  \n",
       "mean                  0.086164  \n",
       "std                   0.020801  \n",
       "min                   0.055040  \n",
       "25%                   0.072280  \n",
       "50%                   0.081265  \n",
       "75%                   0.093575  \n",
       "max                   0.207500  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.21893775e-01 -1.27765988e+00 -3.46314458e-01 ... -1.38118968e-02\n",
      "  -4.65092350e-04 -6.53024434e-01]\n",
      " [-4.44969077e-01 -9.61916140e-01 -4.17507924e-01 ... -8.27573495e-01\n",
      "   2.93294391e-01 -2.08503230e-01]\n",
      " [-1.40174577e+00 -1.72671764e+00 -1.40137828e+00 ... -9.81107933e-01\n",
      "  -7.48345516e-01 -4.05747487e-01]\n",
      " ...\n",
      " [ 1.44932035e+00 -3.80733427e-02  1.35143573e+00 ...  1.85375773e-01\n",
      "   1.10226887e-01 -1.29094123e+00]\n",
      " [ 4.00504733e-01 -2.46230327e-01  4.83886941e-01 ...  6.31730626e-01\n",
      "  -2.94224576e-01  9.68708228e-01]\n",
      " [ 1.21119639e+00  1.55467842e+00  1.22694443e+00 ...  7.08788629e-01\n",
      "   9.85828825e-01  1.25735836e+00]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "features=data.iloc[:,1:31].values\n",
    "scaler=StandardScaler()\n",
    "df=scaler.fit_transform(features)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.321894</td>\n",
       "      <td>-1.277660</td>\n",
       "      <td>-0.346314</td>\n",
       "      <td>-0.389320</td>\n",
       "      <td>-0.010120</td>\n",
       "      <td>-0.577099</td>\n",
       "      <td>-0.447952</td>\n",
       "      <td>-0.230917</td>\n",
       "      <td>0.165181</td>\n",
       "      <td>-0.681058</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.410276</td>\n",
       "      <td>-1.165488</td>\n",
       "      <td>-0.403305</td>\n",
       "      <td>-0.442960</td>\n",
       "      <td>0.347717</td>\n",
       "      <td>-0.599768</td>\n",
       "      <td>-0.330357</td>\n",
       "      <td>-0.013812</td>\n",
       "      <td>-0.000465</td>\n",
       "      <td>-0.653024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.444969</td>\n",
       "      <td>-0.961916</td>\n",
       "      <td>-0.417508</td>\n",
       "      <td>-0.509618</td>\n",
       "      <td>0.665798</td>\n",
       "      <td>0.219010</td>\n",
       "      <td>-0.696819</td>\n",
       "      <td>-0.640762</td>\n",
       "      <td>0.462603</td>\n",
       "      <td>0.650606</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.528934</td>\n",
       "      <td>-0.968553</td>\n",
       "      <td>-0.504294</td>\n",
       "      <td>-0.571976</td>\n",
       "      <td>-0.172664</td>\n",
       "      <td>-0.044818</td>\n",
       "      <td>-0.553059</td>\n",
       "      <td>-0.827573</td>\n",
       "      <td>0.293294</td>\n",
       "      <td>-0.208503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.401746</td>\n",
       "      <td>-1.726718</td>\n",
       "      <td>-1.401378</td>\n",
       "      <td>-1.149042</td>\n",
       "      <td>0.310785</td>\n",
       "      <td>-0.862207</td>\n",
       "      <td>-0.888219</td>\n",
       "      <td>-0.894371</td>\n",
       "      <td>-0.088717</td>\n",
       "      <td>0.770393</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.359545</td>\n",
       "      <td>-1.741884</td>\n",
       "      <td>-1.370391</td>\n",
       "      <td>-1.076530</td>\n",
       "      <td>-0.123879</td>\n",
       "      <td>-0.945575</td>\n",
       "      <td>-0.999933</td>\n",
       "      <td>-0.981108</td>\n",
       "      <td>-0.748346</td>\n",
       "      <td>-0.405747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.458347</td>\n",
       "      <td>-0.328090</td>\n",
       "      <td>-0.534997</td>\n",
       "      <td>-0.499745</td>\n",
       "      <td>-0.564220</td>\n",
       "      <td>-1.336981</td>\n",
       "      <td>-0.935000</td>\n",
       "      <td>-0.686628</td>\n",
       "      <td>-1.350949</td>\n",
       "      <td>-0.557449</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.762361</td>\n",
       "      <td>-0.597098</td>\n",
       "      <td>-0.829640</td>\n",
       "      <td>-0.707227</td>\n",
       "      <td>-1.562651</td>\n",
       "      <td>-1.325188</td>\n",
       "      <td>-1.179608</td>\n",
       "      <td>-1.157614</td>\n",
       "      <td>-1.405402</td>\n",
       "      <td>-1.177406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.751708</td>\n",
       "      <td>-0.697627</td>\n",
       "      <td>-1.737116</td>\n",
       "      <td>-1.336114</td>\n",
       "      <td>-0.830828</td>\n",
       "      <td>-0.957824</td>\n",
       "      <td>-1.050647</td>\n",
       "      <td>-1.258424</td>\n",
       "      <td>-0.255563</td>\n",
       "      <td>0.258116</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.605810</td>\n",
       "      <td>-0.733191</td>\n",
       "      <td>-1.590552</td>\n",
       "      <td>-1.192756</td>\n",
       "      <td>-0.233647</td>\n",
       "      <td>-0.829937</td>\n",
       "      <td>-1.088434</td>\n",
       "      <td>-1.513681</td>\n",
       "      <td>0.181183</td>\n",
       "      <td>-0.580862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0 -0.321894 -1.277660 -0.346314 -0.389320 -0.010120 -0.577099 -0.447952   \n",
       "1 -0.444969 -0.961916 -0.417508 -0.509618  0.665798  0.219010 -0.696819   \n",
       "2 -1.401746 -1.726718 -1.401378 -1.149042  0.310785 -0.862207 -0.888219   \n",
       "3 -0.458347 -0.328090 -0.534997 -0.499745 -0.564220 -1.336981 -0.935000   \n",
       "4 -1.751708 -0.697627 -1.737116 -1.336114 -0.830828 -0.957824 -1.050647   \n",
       "\n",
       "         7         8         9     ...           20        21        22  \\\n",
       "0 -0.230917  0.165181 -0.681058    ...    -0.410276 -1.165488 -0.403305   \n",
       "1 -0.640762  0.462603  0.650606    ...    -0.528934 -0.968553 -0.504294   \n",
       "2 -0.894371 -0.088717  0.770393    ...    -1.359545 -1.741884 -1.370391   \n",
       "3 -0.686628 -1.350949 -0.557449    ...    -0.762361 -0.597098 -0.829640   \n",
       "4 -1.258424 -0.255563  0.258116    ...    -1.605810 -0.733191 -1.590552   \n",
       "\n",
       "         23        24        25        26        27        28        29  \n",
       "0 -0.442960  0.347717 -0.599768 -0.330357 -0.013812 -0.000465 -0.653024  \n",
       "1 -0.571976 -0.172664 -0.044818 -0.553059 -0.827573  0.293294 -0.208503  \n",
       "2 -1.076530 -0.123879 -0.945575 -0.999933 -0.981108 -0.748346 -0.405747  \n",
       "3 -0.707227 -1.562651 -1.325188 -1.179608 -1.157614 -1.405402 -1.177406  \n",
       "4 -1.192756 -0.233647 -0.829937 -1.088434 -1.513681  0.181183 -0.580862  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.321894</td>\n",
       "      <td>-1.277660</td>\n",
       "      <td>-0.346314</td>\n",
       "      <td>-0.389320</td>\n",
       "      <td>-0.010120</td>\n",
       "      <td>-0.577099</td>\n",
       "      <td>-0.447952</td>\n",
       "      <td>-0.230917</td>\n",
       "      <td>0.165181</td>\n",
       "      <td>-0.681058</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.410276</td>\n",
       "      <td>-1.165488</td>\n",
       "      <td>-0.403305</td>\n",
       "      <td>-0.442960</td>\n",
       "      <td>0.347717</td>\n",
       "      <td>-0.599768</td>\n",
       "      <td>-0.330357</td>\n",
       "      <td>-0.013812</td>\n",
       "      <td>-0.000465</td>\n",
       "      <td>-0.653024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.444969</td>\n",
       "      <td>-0.961916</td>\n",
       "      <td>-0.417508</td>\n",
       "      <td>-0.509618</td>\n",
       "      <td>0.665798</td>\n",
       "      <td>0.219010</td>\n",
       "      <td>-0.696819</td>\n",
       "      <td>-0.640762</td>\n",
       "      <td>0.462603</td>\n",
       "      <td>0.650606</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.528934</td>\n",
       "      <td>-0.968553</td>\n",
       "      <td>-0.504294</td>\n",
       "      <td>-0.571976</td>\n",
       "      <td>-0.172664</td>\n",
       "      <td>-0.044818</td>\n",
       "      <td>-0.553059</td>\n",
       "      <td>-0.827573</td>\n",
       "      <td>0.293294</td>\n",
       "      <td>-0.208503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.401746</td>\n",
       "      <td>-1.726718</td>\n",
       "      <td>-1.401378</td>\n",
       "      <td>-1.149042</td>\n",
       "      <td>0.310785</td>\n",
       "      <td>-0.862207</td>\n",
       "      <td>-0.888219</td>\n",
       "      <td>-0.894371</td>\n",
       "      <td>-0.088717</td>\n",
       "      <td>0.770393</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.359545</td>\n",
       "      <td>-1.741884</td>\n",
       "      <td>-1.370391</td>\n",
       "      <td>-1.076530</td>\n",
       "      <td>-0.123879</td>\n",
       "      <td>-0.945575</td>\n",
       "      <td>-0.999933</td>\n",
       "      <td>-0.981108</td>\n",
       "      <td>-0.748346</td>\n",
       "      <td>-0.405747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.458347</td>\n",
       "      <td>-0.328090</td>\n",
       "      <td>-0.534997</td>\n",
       "      <td>-0.499745</td>\n",
       "      <td>-0.564220</td>\n",
       "      <td>-1.336981</td>\n",
       "      <td>-0.935000</td>\n",
       "      <td>-0.686628</td>\n",
       "      <td>-1.350949</td>\n",
       "      <td>-0.557449</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.762361</td>\n",
       "      <td>-0.597098</td>\n",
       "      <td>-0.829640</td>\n",
       "      <td>-0.707227</td>\n",
       "      <td>-1.562651</td>\n",
       "      <td>-1.325188</td>\n",
       "      <td>-1.179608</td>\n",
       "      <td>-1.157614</td>\n",
       "      <td>-1.405402</td>\n",
       "      <td>-1.177406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.751708</td>\n",
       "      <td>-0.697627</td>\n",
       "      <td>-1.737116</td>\n",
       "      <td>-1.336114</td>\n",
       "      <td>-0.830828</td>\n",
       "      <td>-0.957824</td>\n",
       "      <td>-1.050647</td>\n",
       "      <td>-1.258424</td>\n",
       "      <td>-0.255563</td>\n",
       "      <td>0.258116</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.605810</td>\n",
       "      <td>-0.733191</td>\n",
       "      <td>-1.590552</td>\n",
       "      <td>-1.192756</td>\n",
       "      <td>-0.233647</td>\n",
       "      <td>-0.829937</td>\n",
       "      <td>-1.088434</td>\n",
       "      <td>-1.513681</td>\n",
       "      <td>0.181183</td>\n",
       "      <td>-0.580862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0    -0.321894     -1.277660       -0.346314  -0.389320        -0.010120   \n",
       "1    -0.444969     -0.961916       -0.417508  -0.509618         0.665798   \n",
       "2    -1.401746     -1.726718       -1.401378  -1.149042         0.310785   \n",
       "3    -0.458347     -0.328090       -0.534997  -0.499745        -0.564220   \n",
       "4    -1.751708     -0.697627       -1.737116  -1.336114        -0.830828   \n",
       "\n",
       "   compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "0         -0.577099       -0.447952            -0.230917       0.165181   \n",
       "1          0.219010       -0.696819            -0.640762       0.462603   \n",
       "2         -0.862207       -0.888219            -0.894371      -0.088717   \n",
       "3         -1.336981       -0.935000            -0.686628      -1.350949   \n",
       "4         -0.957824       -1.050647            -1.258424      -0.255563   \n",
       "\n",
       "   fractal_dimension_mean           ...             radius_worst  \\\n",
       "0               -0.681058           ...                -0.410276   \n",
       "1                0.650606           ...                -0.528934   \n",
       "2                0.770393           ...                -1.359545   \n",
       "3               -0.557449           ...                -0.762361   \n",
       "4                0.258116           ...                -1.605810   \n",
       "\n",
       "   texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0      -1.165488        -0.403305   -0.442960          0.347717   \n",
       "1      -0.968553        -0.504294   -0.571976         -0.172664   \n",
       "2      -1.741884        -1.370391   -1.076530         -0.123879   \n",
       "3      -0.597098        -0.829640   -0.707227         -1.562651   \n",
       "4      -0.733191        -1.590552   -1.192756         -0.233647   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0          -0.599768        -0.330357             -0.013812       -0.000465   \n",
       "1          -0.044818        -0.553059             -0.827573        0.293294   \n",
       "2          -0.945575        -0.999933             -0.981108       -0.748346   \n",
       "3          -1.325188        -1.179608             -1.157614       -1.405402   \n",
       "4          -0.829937        -1.088434             -1.513681        0.181183   \n",
       "\n",
       "   fractal_dimension_worst  \n",
       "0                -0.653024  \n",
       "1                -0.208503  \n",
       "2                -0.405747  \n",
       "3                -1.177406  \n",
       "4                -0.580862  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns=['radius_mean', 'texture_mean', 'perimeter_mean',\n",
    "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
    "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
    "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
    "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
    "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
    "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
    "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
    "       'symmetry_worst', 'fractal_dimension_worst']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7.140000e+02</td>\n",
       "      <td>7.140000e+02</td>\n",
       "      <td>7.140000e+02</td>\n",
       "      <td>7.140000e+02</td>\n",
       "      <td>7.140000e+02</td>\n",
       "      <td>7.140000e+02</td>\n",
       "      <td>7.140000e+02</td>\n",
       "      <td>7.140000e+02</td>\n",
       "      <td>7.140000e+02</td>\n",
       "      <td>7.140000e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>7.140000e+02</td>\n",
       "      <td>7.140000e+02</td>\n",
       "      <td>7.140000e+02</td>\n",
       "      <td>7.140000e+02</td>\n",
       "      <td>7.140000e+02</td>\n",
       "      <td>7.140000e+02</td>\n",
       "      <td>7.140000e+02</td>\n",
       "      <td>7.140000e+02</td>\n",
       "      <td>7.140000e+02</td>\n",
       "      <td>7.140000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-3.172066e-17</td>\n",
       "      <td>6.903908e-17</td>\n",
       "      <td>-2.469236e-16</td>\n",
       "      <td>-5.348974e-17</td>\n",
       "      <td>-2.707918e-16</td>\n",
       "      <td>1.020037e-16</td>\n",
       "      <td>-8.318898e-17</td>\n",
       "      <td>-5.652186e-17</td>\n",
       "      <td>-8.836983e-16</td>\n",
       "      <td>-1.866135e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>4.695901e-16</td>\n",
       "      <td>-5.922744e-16</td>\n",
       "      <td>-3.731842e-16</td>\n",
       "      <td>1.063575e-16</td>\n",
       "      <td>2.702476e-16</td>\n",
       "      <td>-2.388379e-16</td>\n",
       "      <td>2.469236e-16</td>\n",
       "      <td>1.131992e-16</td>\n",
       "      <td>5.162382e-16</td>\n",
       "      <td>2.945045e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000701e+00</td>\n",
       "      <td>1.000701e+00</td>\n",
       "      <td>1.000701e+00</td>\n",
       "      <td>1.000701e+00</td>\n",
       "      <td>1.000701e+00</td>\n",
       "      <td>1.000701e+00</td>\n",
       "      <td>1.000701e+00</td>\n",
       "      <td>1.000701e+00</td>\n",
       "      <td>1.000701e+00</td>\n",
       "      <td>1.000701e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000701e+00</td>\n",
       "      <td>1.000701e+00</td>\n",
       "      <td>1.000701e+00</td>\n",
       "      <td>1.000701e+00</td>\n",
       "      <td>1.000701e+00</td>\n",
       "      <td>1.000701e+00</td>\n",
       "      <td>1.000701e+00</td>\n",
       "      <td>1.000701e+00</td>\n",
       "      <td>1.000701e+00</td>\n",
       "      <td>1.000701e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.076787e+00</td>\n",
       "      <td>-2.365222e+00</td>\n",
       "      <td>-2.045232e+00</td>\n",
       "      <td>-1.487850e+00</td>\n",
       "      <td>-3.153731e+00</td>\n",
       "      <td>-1.655355e+00</td>\n",
       "      <td>-1.239197e+00</td>\n",
       "      <td>-1.403550e+00</td>\n",
       "      <td>-2.827180e+00</td>\n",
       "      <td>-1.662285e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.806946e+00</td>\n",
       "      <td>-2.324684e+00</td>\n",
       "      <td>-1.782179e+00</td>\n",
       "      <td>-1.283883e+00</td>\n",
       "      <td>-2.613171e+00</td>\n",
       "      <td>-1.429760e+00</td>\n",
       "      <td>-1.394872e+00</td>\n",
       "      <td>-1.886467e+00</td>\n",
       "      <td>-2.004274e+00</td>\n",
       "      <td>-1.497326e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-7.359351e-01</td>\n",
       "      <td>-6.952881e-01</td>\n",
       "      <td>-7.306814e-01</td>\n",
       "      <td>-7.108508e-01</td>\n",
       "      <td>-7.199732e-01</td>\n",
       "      <td>-7.519172e-01</td>\n",
       "      <td>-8.192341e-01</td>\n",
       "      <td>-8.288225e-01</td>\n",
       "      <td>-7.162056e-01</td>\n",
       "      <td>-7.345795e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.545803e-01</td>\n",
       "      <td>-7.235847e-01</td>\n",
       "      <td>-7.676057e-01</td>\n",
       "      <td>-7.068275e-01</td>\n",
       "      <td>-6.920292e-01</td>\n",
       "      <td>-6.885715e-01</td>\n",
       "      <td>-7.811058e-01</td>\n",
       "      <td>-8.140883e-01</td>\n",
       "      <td>-6.348153e-01</td>\n",
       "      <td>-6.679380e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-2.336006e-01</td>\n",
       "      <td>-5.795350e-02</td>\n",
       "      <td>-2.292148e-01</td>\n",
       "      <td>-3.090353e-01</td>\n",
       "      <td>-2.264975e-02</td>\n",
       "      <td>-1.746033e-01</td>\n",
       "      <td>-2.013409e-01</td>\n",
       "      <td>-1.238573e-01</td>\n",
       "      <td>-9.597092e-02</td>\n",
       "      <td>-1.713300e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.381234e-01</td>\n",
       "      <td>-3.911481e-02</td>\n",
       "      <td>-2.298614e-01</td>\n",
       "      <td>-3.507142e-01</td>\n",
       "      <td>-4.663456e-02</td>\n",
       "      <td>-2.617076e-01</td>\n",
       "      <td>-1.468511e-01</td>\n",
       "      <td>-3.998254e-02</td>\n",
       "      <td>-1.700509e-01</td>\n",
       "      <td>-2.356845e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.413042e-01</td>\n",
       "      <td>5.565774e-01</td>\n",
       "      <td>6.005975e-01</td>\n",
       "      <td>5.509774e-01</td>\n",
       "      <td>6.031489e-01</td>\n",
       "      <td>5.655987e-01</td>\n",
       "      <td>5.688290e-01</td>\n",
       "      <td>7.170484e-01</td>\n",
       "      <td>5.006876e-01</td>\n",
       "      <td>4.734760e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>6.148571e-01</td>\n",
       "      <td>6.661693e-01</td>\n",
       "      <td>5.758109e-01</td>\n",
       "      <td>4.775790e-01</td>\n",
       "      <td>6.068910e-01</td>\n",
       "      <td>5.289449e-01</td>\n",
       "      <td>5.278239e-01</td>\n",
       "      <td>7.800309e-01</td>\n",
       "      <td>3.436734e-01</td>\n",
       "      <td>3.565294e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.576383e+00</td>\n",
       "      <td>4.550736e+00</td>\n",
       "      <td>3.584499e+00</td>\n",
       "      <td>4.637466e+00</td>\n",
       "      <td>4.557027e+00</td>\n",
       "      <td>4.022777e+00</td>\n",
       "      <td>3.823633e+00</td>\n",
       "      <td>3.202607e+00</td>\n",
       "      <td>4.354485e+00</td>\n",
       "      <td>4.388187e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>3.661077e+00</td>\n",
       "      <td>3.682640e+00</td>\n",
       "      <td>3.834867e+00</td>\n",
       "      <td>5.220960e+00</td>\n",
       "      <td>3.543183e+00</td>\n",
       "      <td>4.273064e+00</td>\n",
       "      <td>4.181581e+00</td>\n",
       "      <td>2.344454e+00</td>\n",
       "      <td>5.194962e+00</td>\n",
       "      <td>5.837274e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        radius_mean  texture_mean  perimeter_mean     area_mean  \\\n",
       "count  7.140000e+02  7.140000e+02    7.140000e+02  7.140000e+02   \n",
       "mean  -3.172066e-17  6.903908e-17   -2.469236e-16 -5.348974e-17   \n",
       "std    1.000701e+00  1.000701e+00    1.000701e+00  1.000701e+00   \n",
       "min   -2.076787e+00 -2.365222e+00   -2.045232e+00 -1.487850e+00   \n",
       "25%   -7.359351e-01 -6.952881e-01   -7.306814e-01 -7.108508e-01   \n",
       "50%   -2.336006e-01 -5.795350e-02   -2.292148e-01 -3.090353e-01   \n",
       "75%    6.413042e-01  5.565774e-01    6.005975e-01  5.509774e-01   \n",
       "max    3.576383e+00  4.550736e+00    3.584499e+00  4.637466e+00   \n",
       "\n",
       "       smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "count     7.140000e+02      7.140000e+02    7.140000e+02         7.140000e+02   \n",
       "mean     -2.707918e-16      1.020037e-16   -8.318898e-17        -5.652186e-17   \n",
       "std       1.000701e+00      1.000701e+00    1.000701e+00         1.000701e+00   \n",
       "min      -3.153731e+00     -1.655355e+00   -1.239197e+00        -1.403550e+00   \n",
       "25%      -7.199732e-01     -7.519172e-01   -8.192341e-01        -8.288225e-01   \n",
       "50%      -2.264975e-02     -1.746033e-01   -2.013409e-01        -1.238573e-01   \n",
       "75%       6.031489e-01      5.655987e-01    5.688290e-01         7.170484e-01   \n",
       "max       4.557027e+00      4.022777e+00    3.823633e+00         3.202607e+00   \n",
       "\n",
       "       symmetry_mean  fractal_dimension_mean           ...             \\\n",
       "count   7.140000e+02            7.140000e+02           ...              \n",
       "mean   -8.836983e-16           -1.866135e-15           ...              \n",
       "std     1.000701e+00            1.000701e+00           ...              \n",
       "min    -2.827180e+00           -1.662285e+00           ...              \n",
       "25%    -7.162056e-01           -7.345795e-01           ...              \n",
       "50%    -9.597092e-02           -1.713300e-01           ...              \n",
       "75%     5.006876e-01            4.734760e-01           ...              \n",
       "max     4.354485e+00            4.388187e+00           ...              \n",
       "\n",
       "       radius_worst  texture_worst  perimeter_worst    area_worst  \\\n",
       "count  7.140000e+02   7.140000e+02     7.140000e+02  7.140000e+02   \n",
       "mean   4.695901e-16  -5.922744e-16    -3.731842e-16  1.063575e-16   \n",
       "std    1.000701e+00   1.000701e+00     1.000701e+00  1.000701e+00   \n",
       "min   -1.806946e+00  -2.324684e+00    -1.782179e+00 -1.283883e+00   \n",
       "25%   -7.545803e-01  -7.235847e-01    -7.676057e-01 -7.068275e-01   \n",
       "50%   -2.381234e-01  -3.911481e-02    -2.298614e-01 -3.507142e-01   \n",
       "75%    6.148571e-01   6.661693e-01     5.758109e-01  4.775790e-01   \n",
       "max    3.661077e+00   3.682640e+00     3.834867e+00  5.220960e+00   \n",
       "\n",
       "       smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "count      7.140000e+02       7.140000e+02     7.140000e+02   \n",
       "mean       2.702476e-16      -2.388379e-16     2.469236e-16   \n",
       "std        1.000701e+00       1.000701e+00     1.000701e+00   \n",
       "min       -2.613171e+00      -1.429760e+00    -1.394872e+00   \n",
       "25%       -6.920292e-01      -6.885715e-01    -7.811058e-01   \n",
       "50%       -4.663456e-02      -2.617076e-01    -1.468511e-01   \n",
       "75%        6.068910e-01       5.289449e-01     5.278239e-01   \n",
       "max        3.543183e+00       4.273064e+00     4.181581e+00   \n",
       "\n",
       "       concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "count          7.140000e+02    7.140000e+02             7.140000e+02  \n",
       "mean           1.131992e-16    5.162382e-16             2.945045e-16  \n",
       "std            1.000701e+00    1.000701e+00             1.000701e+00  \n",
       "min           -1.886467e+00   -2.004274e+00            -1.497326e+00  \n",
       "25%           -8.140883e-01   -6.348153e-01            -6.679380e-01  \n",
       "50%           -3.998254e-02   -1.700509e-01            -2.356845e-01  \n",
       "75%            7.800309e-01    3.436734e-01             3.565294e-01  \n",
       "max            2.344454e+00    5.194962e+00             5.837274e+00  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  0\n",
       "1  0\n",
       "2  0\n",
       "3  0\n",
       "4  0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=data.iloc[:,0].values\n",
    "df1=pd.DataFrame(df1)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns=[\"Tumor_type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=pd.concat([df,df1],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data1.to_csv(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Tumor_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.321894</td>\n",
       "      <td>-1.277660</td>\n",
       "      <td>-0.346314</td>\n",
       "      <td>-0.389320</td>\n",
       "      <td>-0.010120</td>\n",
       "      <td>-0.577099</td>\n",
       "      <td>-0.447952</td>\n",
       "      <td>-0.230917</td>\n",
       "      <td>0.165181</td>\n",
       "      <td>-0.681058</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.165488</td>\n",
       "      <td>-0.403305</td>\n",
       "      <td>-0.442960</td>\n",
       "      <td>0.347717</td>\n",
       "      <td>-0.599768</td>\n",
       "      <td>-0.330357</td>\n",
       "      <td>-0.013812</td>\n",
       "      <td>-0.000465</td>\n",
       "      <td>-0.653024</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.444969</td>\n",
       "      <td>-0.961916</td>\n",
       "      <td>-0.417508</td>\n",
       "      <td>-0.509618</td>\n",
       "      <td>0.665798</td>\n",
       "      <td>0.219010</td>\n",
       "      <td>-0.696819</td>\n",
       "      <td>-0.640762</td>\n",
       "      <td>0.462603</td>\n",
       "      <td>0.650606</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.968553</td>\n",
       "      <td>-0.504294</td>\n",
       "      <td>-0.571976</td>\n",
       "      <td>-0.172664</td>\n",
       "      <td>-0.044818</td>\n",
       "      <td>-0.553059</td>\n",
       "      <td>-0.827573</td>\n",
       "      <td>0.293294</td>\n",
       "      <td>-0.208503</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.401746</td>\n",
       "      <td>-1.726718</td>\n",
       "      <td>-1.401378</td>\n",
       "      <td>-1.149042</td>\n",
       "      <td>0.310785</td>\n",
       "      <td>-0.862207</td>\n",
       "      <td>-0.888219</td>\n",
       "      <td>-0.894371</td>\n",
       "      <td>-0.088717</td>\n",
       "      <td>0.770393</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.741884</td>\n",
       "      <td>-1.370391</td>\n",
       "      <td>-1.076530</td>\n",
       "      <td>-0.123879</td>\n",
       "      <td>-0.945575</td>\n",
       "      <td>-0.999933</td>\n",
       "      <td>-0.981108</td>\n",
       "      <td>-0.748346</td>\n",
       "      <td>-0.405747</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.458347</td>\n",
       "      <td>-0.328090</td>\n",
       "      <td>-0.534997</td>\n",
       "      <td>-0.499745</td>\n",
       "      <td>-0.564220</td>\n",
       "      <td>-1.336981</td>\n",
       "      <td>-0.935000</td>\n",
       "      <td>-0.686628</td>\n",
       "      <td>-1.350949</td>\n",
       "      <td>-0.557449</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.597098</td>\n",
       "      <td>-0.829640</td>\n",
       "      <td>-0.707227</td>\n",
       "      <td>-1.562651</td>\n",
       "      <td>-1.325188</td>\n",
       "      <td>-1.179608</td>\n",
       "      <td>-1.157614</td>\n",
       "      <td>-1.405402</td>\n",
       "      <td>-1.177406</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.751708</td>\n",
       "      <td>-0.697627</td>\n",
       "      <td>-1.737116</td>\n",
       "      <td>-1.336114</td>\n",
       "      <td>-0.830828</td>\n",
       "      <td>-0.957824</td>\n",
       "      <td>-1.050647</td>\n",
       "      <td>-1.258424</td>\n",
       "      <td>-0.255563</td>\n",
       "      <td>0.258116</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.733191</td>\n",
       "      <td>-1.590552</td>\n",
       "      <td>-1.192756</td>\n",
       "      <td>-0.233647</td>\n",
       "      <td>-0.829937</td>\n",
       "      <td>-1.088434</td>\n",
       "      <td>-1.513681</td>\n",
       "      <td>0.181183</td>\n",
       "      <td>-0.580862</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0    -0.321894     -1.277660       -0.346314  -0.389320        -0.010120   \n",
       "1    -0.444969     -0.961916       -0.417508  -0.509618         0.665798   \n",
       "2    -1.401746     -1.726718       -1.401378  -1.149042         0.310785   \n",
       "3    -0.458347     -0.328090       -0.534997  -0.499745        -0.564220   \n",
       "4    -1.751708     -0.697627       -1.737116  -1.336114        -0.830828   \n",
       "\n",
       "   compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "0         -0.577099       -0.447952            -0.230917       0.165181   \n",
       "1          0.219010       -0.696819            -0.640762       0.462603   \n",
       "2         -0.862207       -0.888219            -0.894371      -0.088717   \n",
       "3         -1.336981       -0.935000            -0.686628      -1.350949   \n",
       "4         -0.957824       -1.050647            -1.258424      -0.255563   \n",
       "\n",
       "   fractal_dimension_mean     ...      texture_worst  perimeter_worst  \\\n",
       "0               -0.681058     ...          -1.165488        -0.403305   \n",
       "1                0.650606     ...          -0.968553        -0.504294   \n",
       "2                0.770393     ...          -1.741884        -1.370391   \n",
       "3               -0.557449     ...          -0.597098        -0.829640   \n",
       "4                0.258116     ...          -0.733191        -1.590552   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0   -0.442960          0.347717          -0.599768        -0.330357   \n",
       "1   -0.571976         -0.172664          -0.044818        -0.553059   \n",
       "2   -1.076530         -0.123879          -0.945575        -0.999933   \n",
       "3   -0.707227         -1.562651          -1.325188        -1.179608   \n",
       "4   -1.192756         -0.233647          -0.829937        -1.088434   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  Tumor_type  \n",
       "0             -0.013812       -0.000465                -0.653024           0  \n",
       "1             -0.827573        0.293294                -0.208503           0  \n",
       "2             -0.981108       -0.748346                -0.405747           0  \n",
       "3             -1.157614       -1.405402                -1.177406           0  \n",
       "4             -1.513681        0.181183                -0.580862           0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.pairplot(data=data1,palette=\"spring\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "radius_mean                0.797651\n",
       "texture_mean               0.509263\n",
       "perimeter_mean             0.828474\n",
       "area_mean                  1.465435\n",
       "smoothness_mean            0.489322\n",
       "compactness_mean           1.006159\n",
       "concavity_mean             1.073639\n",
       "concave points_mean        0.841558\n",
       "symmetry_mean              0.684650\n",
       "fractal_dimension_mean     1.438128\n",
       "radius_se                  2.905742\n",
       "texture_se                 1.658913\n",
       "perimeter_se               3.218599\n",
       "area_se                    4.923419\n",
       "smoothness_se              2.226414\n",
       "compactness_se             1.866881\n",
       "concavity_se               4.757337\n",
       "concave points_se          1.185772\n",
       "symmetry_se                2.380385\n",
       "fractal_dimension_se       3.679429\n",
       "radius_worst               0.856317\n",
       "texture_worst              0.432608\n",
       "perimeter_worst            0.867030\n",
       "area_worst                 1.582251\n",
       "smoothness_worst           0.593922\n",
       "compactness_worst          1.387888\n",
       "concavity_worst            0.980212\n",
       "concave points_worst       0.198814\n",
       "symmetry_worst             1.832479\n",
       "fractal_dimension_worst    1.651566\n",
       "Tumor_type                 0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.skew(axis = 0, skipna = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "radius_mean                 0.452468\n",
       "texture_mean                0.488978\n",
       "perimeter_mean              0.569711\n",
       "area_mean                   2.826282\n",
       "smoothness_mean             0.855196\n",
       "compactness_mean            0.823119\n",
       "concavity_mean              0.946292\n",
       "concave points_mean         0.308868\n",
       "symmetry_mean               1.219859\n",
       "fractal_dimension_mean      3.562044\n",
       "radius_se                  15.246681\n",
       "texture_se                  5.920726\n",
       "perimeter_se               18.248185\n",
       "area_se                    38.119231\n",
       "smoothness_se              10.924078\n",
       "compactness_se              5.191526\n",
       "concavity_se               47.120604\n",
       "concave points_se           4.053654\n",
       "symmetry_se                 8.004731\n",
       "fractal_dimension_se       25.266546\n",
       "radius_worst                0.280851\n",
       "texture_worst               0.175858\n",
       "perimeter_worst             0.383686\n",
       "area_worst                  3.116665\n",
       "smoothness_worst            0.861146\n",
       "compactness_worst           2.142753\n",
       "concavity_worst             1.090448\n",
       "concave points_worst       -0.843403\n",
       "symmetry_worst              6.495993\n",
       "fractal_dimension_worst     4.033434\n",
       "Tumor_type                 -2.005626\n",
       "dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.kurtosis(axis = 0, skipna = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Tumor_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>radius_mean</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.332085</td>\n",
       "      <td>0.997562</td>\n",
       "      <td>0.987398</td>\n",
       "      <td>0.109233</td>\n",
       "      <td>0.420384</td>\n",
       "      <td>0.645219</td>\n",
       "      <td>0.804236</td>\n",
       "      <td>0.103929</td>\n",
       "      <td>-0.361631</td>\n",
       "      <td>...</td>\n",
       "      <td>0.290182</td>\n",
       "      <td>0.960777</td>\n",
       "      <td>0.938857</td>\n",
       "      <td>0.044892</td>\n",
       "      <td>0.287988</td>\n",
       "      <td>0.450889</td>\n",
       "      <td>0.690235</td>\n",
       "      <td>0.045430</td>\n",
       "      <td>-0.079852</td>\n",
       "      <td>0.694725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texture_mean</th>\n",
       "      <td>0.332085</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.344357</td>\n",
       "      <td>0.321685</td>\n",
       "      <td>0.041540</td>\n",
       "      <td>0.300371</td>\n",
       "      <td>0.355344</td>\n",
       "      <td>0.340014</td>\n",
       "      <td>0.100020</td>\n",
       "      <td>-0.023954</td>\n",
       "      <td>...</td>\n",
       "      <td>0.905327</td>\n",
       "      <td>0.387674</td>\n",
       "      <td>0.351195</td>\n",
       "      <td>0.129277</td>\n",
       "      <td>0.341648</td>\n",
       "      <td>0.365546</td>\n",
       "      <td>0.340085</td>\n",
       "      <td>0.137610</td>\n",
       "      <td>0.177389</td>\n",
       "      <td>0.446257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perimeter_mean</th>\n",
       "      <td>0.997562</td>\n",
       "      <td>0.344357</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985549</td>\n",
       "      <td>0.150908</td>\n",
       "      <td>0.477502</td>\n",
       "      <td>0.689990</td>\n",
       "      <td>0.836713</td>\n",
       "      <td>0.143550</td>\n",
       "      <td>-0.309058</td>\n",
       "      <td>...</td>\n",
       "      <td>0.302529</td>\n",
       "      <td>0.967321</td>\n",
       "      <td>0.938072</td>\n",
       "      <td>0.080736</td>\n",
       "      <td>0.337744</td>\n",
       "      <td>0.495016</td>\n",
       "      <td>0.723247</td>\n",
       "      <td>0.074824</td>\n",
       "      <td>-0.031790</td>\n",
       "      <td>0.711408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area_mean</th>\n",
       "      <td>0.987398</td>\n",
       "      <td>0.321685</td>\n",
       "      <td>0.985549</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.109977</td>\n",
       "      <td>0.402834</td>\n",
       "      <td>0.645443</td>\n",
       "      <td>0.797177</td>\n",
       "      <td>0.095949</td>\n",
       "      <td>-0.343027</td>\n",
       "      <td>...</td>\n",
       "      <td>0.273383</td>\n",
       "      <td>0.951052</td>\n",
       "      <td>0.954319</td>\n",
       "      <td>0.040650</td>\n",
       "      <td>0.257296</td>\n",
       "      <td>0.426802</td>\n",
       "      <td>0.659754</td>\n",
       "      <td>0.015654</td>\n",
       "      <td>-0.090751</td>\n",
       "      <td>0.658262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoothness_mean</th>\n",
       "      <td>0.109233</td>\n",
       "      <td>0.041540</td>\n",
       "      <td>0.150908</td>\n",
       "      <td>0.109977</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.685868</td>\n",
       "      <td>0.555397</td>\n",
       "      <td>0.547234</td>\n",
       "      <td>0.592918</td>\n",
       "      <td>0.644957</td>\n",
       "      <td>...</td>\n",
       "      <td>0.115695</td>\n",
       "      <td>0.202430</td>\n",
       "      <td>0.150547</td>\n",
       "      <td>0.821964</td>\n",
       "      <td>0.544836</td>\n",
       "      <td>0.495536</td>\n",
       "      <td>0.538018</td>\n",
       "      <td>0.473614</td>\n",
       "      <td>0.581191</td>\n",
       "      <td>0.379916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compactness_mean</th>\n",
       "      <td>0.420384</td>\n",
       "      <td>0.300371</td>\n",
       "      <td>0.477502</td>\n",
       "      <td>0.402834</td>\n",
       "      <td>0.685868</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.882442</td>\n",
       "      <td>0.806118</td>\n",
       "      <td>0.641931</td>\n",
       "      <td>0.605441</td>\n",
       "      <td>...</td>\n",
       "      <td>0.313784</td>\n",
       "      <td>0.524468</td>\n",
       "      <td>0.413235</td>\n",
       "      <td>0.600349</td>\n",
       "      <td>0.882386</td>\n",
       "      <td>0.833959</td>\n",
       "      <td>0.817379</td>\n",
       "      <td>0.553359</td>\n",
       "      <td>0.713886</td>\n",
       "      <td>0.598092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concavity_mean</th>\n",
       "      <td>0.645219</td>\n",
       "      <td>0.355344</td>\n",
       "      <td>0.689990</td>\n",
       "      <td>0.645443</td>\n",
       "      <td>0.555397</td>\n",
       "      <td>0.882442</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.923631</td>\n",
       "      <td>0.524330</td>\n",
       "      <td>0.348580</td>\n",
       "      <td>...</td>\n",
       "      <td>0.343633</td>\n",
       "      <td>0.711025</td>\n",
       "      <td>0.632091</td>\n",
       "      <td>0.464076</td>\n",
       "      <td>0.745584</td>\n",
       "      <td>0.878890</td>\n",
       "      <td>0.867114</td>\n",
       "      <td>0.398858</td>\n",
       "      <td>0.511063</td>\n",
       "      <td>0.692335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concave points_mean</th>\n",
       "      <td>0.804236</td>\n",
       "      <td>0.340014</td>\n",
       "      <td>0.836713</td>\n",
       "      <td>0.797177</td>\n",
       "      <td>0.547234</td>\n",
       "      <td>0.806118</td>\n",
       "      <td>0.923631</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.461481</td>\n",
       "      <td>0.160248</td>\n",
       "      <td>...</td>\n",
       "      <td>0.327647</td>\n",
       "      <td>0.846593</td>\n",
       "      <td>0.779507</td>\n",
       "      <td>0.430682</td>\n",
       "      <td>0.624768</td>\n",
       "      <td>0.735843</td>\n",
       "      <td>0.904650</td>\n",
       "      <td>0.327519</td>\n",
       "      <td>0.343633</td>\n",
       "      <td>0.772781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symmetry_mean</th>\n",
       "      <td>0.103929</td>\n",
       "      <td>0.100020</td>\n",
       "      <td>0.143550</td>\n",
       "      <td>0.095949</td>\n",
       "      <td>0.592918</td>\n",
       "      <td>0.641931</td>\n",
       "      <td>0.524330</td>\n",
       "      <td>0.461481</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.540520</td>\n",
       "      <td>...</td>\n",
       "      <td>0.133498</td>\n",
       "      <td>0.193049</td>\n",
       "      <td>0.127878</td>\n",
       "      <td>0.488584</td>\n",
       "      <td>0.549699</td>\n",
       "      <td>0.494963</td>\n",
       "      <td>0.476692</td>\n",
       "      <td>0.709566</td>\n",
       "      <td>0.529056</td>\n",
       "      <td>0.354003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <td>-0.361631</td>\n",
       "      <td>-0.023954</td>\n",
       "      <td>-0.309058</td>\n",
       "      <td>-0.343027</td>\n",
       "      <td>0.644957</td>\n",
       "      <td>0.605441</td>\n",
       "      <td>0.348580</td>\n",
       "      <td>0.160248</td>\n",
       "      <td>0.540520</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024437</td>\n",
       "      <td>-0.237687</td>\n",
       "      <td>-0.289884</td>\n",
       "      <td>0.591673</td>\n",
       "      <td>0.560740</td>\n",
       "      <td>0.407056</td>\n",
       "      <td>0.229681</td>\n",
       "      <td>0.492497</td>\n",
       "      <td>0.819104</td>\n",
       "      <td>0.017469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radius_se</th>\n",
       "      <td>0.681959</td>\n",
       "      <td>0.263519</td>\n",
       "      <td>0.692583</td>\n",
       "      <td>0.732354</td>\n",
       "      <td>0.247419</td>\n",
       "      <td>0.403858</td>\n",
       "      <td>0.580443</td>\n",
       "      <td>0.663240</td>\n",
       "      <td>0.239285</td>\n",
       "      <td>-0.081466</td>\n",
       "      <td>...</td>\n",
       "      <td>0.169281</td>\n",
       "      <td>0.719625</td>\n",
       "      <td>0.753761</td>\n",
       "      <td>0.076494</td>\n",
       "      <td>0.185029</td>\n",
       "      <td>0.302039</td>\n",
       "      <td>0.478267</td>\n",
       "      <td>-0.002878</td>\n",
       "      <td>-0.033896</td>\n",
       "      <td>0.526287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texture_se</th>\n",
       "      <td>-0.096991</td>\n",
       "      <td>0.356625</td>\n",
       "      <td>-0.087150</td>\n",
       "      <td>-0.065927</td>\n",
       "      <td>0.065846</td>\n",
       "      <td>0.044816</td>\n",
       "      <td>0.053907</td>\n",
       "      <td>0.004939</td>\n",
       "      <td>0.113949</td>\n",
       "      <td>0.147719</td>\n",
       "      <td>...</td>\n",
       "      <td>0.382596</td>\n",
       "      <td>-0.092925</td>\n",
       "      <td>-0.071544</td>\n",
       "      <td>-0.063044</td>\n",
       "      <td>-0.056882</td>\n",
       "      <td>-0.067034</td>\n",
       "      <td>-0.127914</td>\n",
       "      <td>-0.101714</td>\n",
       "      <td>-0.025060</td>\n",
       "      <td>-0.024650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perimeter_se</th>\n",
       "      <td>0.680214</td>\n",
       "      <td>0.278188</td>\n",
       "      <td>0.698383</td>\n",
       "      <td>0.729233</td>\n",
       "      <td>0.253590</td>\n",
       "      <td>0.472336</td>\n",
       "      <td>0.626714</td>\n",
       "      <td>0.689464</td>\n",
       "      <td>0.255004</td>\n",
       "      <td>-0.037242</td>\n",
       "      <td>...</td>\n",
       "      <td>0.180108</td>\n",
       "      <td>0.723332</td>\n",
       "      <td>0.732691</td>\n",
       "      <td>0.075642</td>\n",
       "      <td>0.252592</td>\n",
       "      <td>0.355729</td>\n",
       "      <td>0.513030</td>\n",
       "      <td>0.012299</td>\n",
       "      <td>0.006026</td>\n",
       "      <td>0.523860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area_se</th>\n",
       "      <td>0.726737</td>\n",
       "      <td>0.245636</td>\n",
       "      <td>0.733187</td>\n",
       "      <td>0.790068</td>\n",
       "      <td>0.183543</td>\n",
       "      <td>0.346923</td>\n",
       "      <td>0.555754</td>\n",
       "      <td>0.639793</td>\n",
       "      <td>0.153652</td>\n",
       "      <td>-0.169220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.171525</td>\n",
       "      <td>0.749400</td>\n",
       "      <td>0.807279</td>\n",
       "      <td>0.050793</td>\n",
       "      <td>0.163477</td>\n",
       "      <td>0.297699</td>\n",
       "      <td>0.469867</td>\n",
       "      <td>-0.038354</td>\n",
       "      <td>-0.074600</td>\n",
       "      <td>0.491076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoothness_se</th>\n",
       "      <td>-0.244737</td>\n",
       "      <td>-0.014882</td>\n",
       "      <td>-0.225202</td>\n",
       "      <td>-0.190659</td>\n",
       "      <td>0.304707</td>\n",
       "      <td>0.124782</td>\n",
       "      <td>0.068569</td>\n",
       "      <td>-0.006200</td>\n",
       "      <td>0.165469</td>\n",
       "      <td>0.378127</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.100634</td>\n",
       "      <td>-0.238000</td>\n",
       "      <td>-0.205893</td>\n",
       "      <td>0.279393</td>\n",
       "      <td>-0.031031</td>\n",
       "      <td>-0.068973</td>\n",
       "      <td>-0.113837</td>\n",
       "      <td>-0.085768</td>\n",
       "      <td>0.104911</td>\n",
       "      <td>-0.101332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compactness_se</th>\n",
       "      <td>0.153577</td>\n",
       "      <td>0.233460</td>\n",
       "      <td>0.202537</td>\n",
       "      <td>0.150329</td>\n",
       "      <td>0.370753</td>\n",
       "      <td>0.757987</td>\n",
       "      <td>0.657904</td>\n",
       "      <td>0.474296</td>\n",
       "      <td>0.484327</td>\n",
       "      <td>0.570760</td>\n",
       "      <td>...</td>\n",
       "      <td>0.190251</td>\n",
       "      <td>0.222198</td>\n",
       "      <td>0.138490</td>\n",
       "      <td>0.286040</td>\n",
       "      <td>0.721438</td>\n",
       "      <td>0.652689</td>\n",
       "      <td>0.488181</td>\n",
       "      <td>0.374726</td>\n",
       "      <td>0.610805</td>\n",
       "      <td>0.306899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concavity_se</th>\n",
       "      <td>0.190418</td>\n",
       "      <td>0.176449</td>\n",
       "      <td>0.228069</td>\n",
       "      <td>0.197203</td>\n",
       "      <td>0.281116</td>\n",
       "      <td>0.590887</td>\n",
       "      <td>0.688519</td>\n",
       "      <td>0.450960</td>\n",
       "      <td>0.376565</td>\n",
       "      <td>0.424989</td>\n",
       "      <td>...</td>\n",
       "      <td>0.127237</td>\n",
       "      <td>0.230429</td>\n",
       "      <td>0.175544</td>\n",
       "      <td>0.187098</td>\n",
       "      <td>0.509745</td>\n",
       "      <td>0.665916</td>\n",
       "      <td>0.451271</td>\n",
       "      <td>0.224736</td>\n",
       "      <td>0.431385</td>\n",
       "      <td>0.270451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concave points_se</th>\n",
       "      <td>0.378976</td>\n",
       "      <td>0.177938</td>\n",
       "      <td>0.412755</td>\n",
       "      <td>0.368810</td>\n",
       "      <td>0.381811</td>\n",
       "      <td>0.632512</td>\n",
       "      <td>0.676415</td>\n",
       "      <td>0.625222</td>\n",
       "      <td>0.413488</td>\n",
       "      <td>0.295335</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082557</td>\n",
       "      <td>0.404082</td>\n",
       "      <td>0.337045</td>\n",
       "      <td>0.205255</td>\n",
       "      <td>0.436759</td>\n",
       "      <td>0.526173</td>\n",
       "      <td>0.601158</td>\n",
       "      <td>0.143464</td>\n",
       "      <td>0.275913</td>\n",
       "      <td>0.434074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symmetry_se</th>\n",
       "      <td>-0.140962</td>\n",
       "      <td>-0.014265</td>\n",
       "      <td>-0.117758</td>\n",
       "      <td>-0.115633</td>\n",
       "      <td>0.244280</td>\n",
       "      <td>0.279159</td>\n",
       "      <td>0.174890</td>\n",
       "      <td>0.079767</td>\n",
       "      <td>0.454793</td>\n",
       "      <td>0.413703</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.094044</td>\n",
       "      <td>-0.135669</td>\n",
       "      <td>-0.155156</td>\n",
       "      <td>0.058723</td>\n",
       "      <td>0.171865</td>\n",
       "      <td>0.079515</td>\n",
       "      <td>0.002702</td>\n",
       "      <td>0.466703</td>\n",
       "      <td>0.209253</td>\n",
       "      <td>-0.019801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fractal_dimension_se</th>\n",
       "      <td>-0.081344</td>\n",
       "      <td>0.080055</td>\n",
       "      <td>-0.041447</td>\n",
       "      <td>-0.063823</td>\n",
       "      <td>0.338153</td>\n",
       "      <td>0.531117</td>\n",
       "      <td>0.440340</td>\n",
       "      <td>0.248404</td>\n",
       "      <td>0.396279</td>\n",
       "      <td>0.686234</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031731</td>\n",
       "      <td>-0.026816</td>\n",
       "      <td>-0.063031</td>\n",
       "      <td>0.232695</td>\n",
       "      <td>0.445820</td>\n",
       "      <td>0.402880</td>\n",
       "      <td>0.234392</td>\n",
       "      <td>0.221832</td>\n",
       "      <td>0.612982</td>\n",
       "      <td>0.087559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radius_worst</th>\n",
       "      <td>0.966083</td>\n",
       "      <td>0.369341</td>\n",
       "      <td>0.966102</td>\n",
       "      <td>0.956581</td>\n",
       "      <td>0.170375</td>\n",
       "      <td>0.457544</td>\n",
       "      <td>0.659356</td>\n",
       "      <td>0.813792</td>\n",
       "      <td>0.155154</td>\n",
       "      <td>-0.290867</td>\n",
       "      <td>...</td>\n",
       "      <td>0.367855</td>\n",
       "      <td>0.992314</td>\n",
       "      <td>0.983096</td>\n",
       "      <td>0.159832</td>\n",
       "      <td>0.355697</td>\n",
       "      <td>0.501906</td>\n",
       "      <td>0.740859</td>\n",
       "      <td>0.138146</td>\n",
       "      <td>0.014303</td>\n",
       "      <td>0.746838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texture_worst</th>\n",
       "      <td>0.290182</td>\n",
       "      <td>0.905327</td>\n",
       "      <td>0.302529</td>\n",
       "      <td>0.273383</td>\n",
       "      <td>0.115695</td>\n",
       "      <td>0.313784</td>\n",
       "      <td>0.343633</td>\n",
       "      <td>0.327647</td>\n",
       "      <td>0.133498</td>\n",
       "      <td>0.024437</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.384779</td>\n",
       "      <td>0.346245</td>\n",
       "      <td>0.298839</td>\n",
       "      <td>0.428125</td>\n",
       "      <td>0.433099</td>\n",
       "      <td>0.402635</td>\n",
       "      <td>0.271695</td>\n",
       "      <td>0.287193</td>\n",
       "      <td>0.484209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perimeter_worst</th>\n",
       "      <td>0.960777</td>\n",
       "      <td>0.387674</td>\n",
       "      <td>0.967321</td>\n",
       "      <td>0.951052</td>\n",
       "      <td>0.202430</td>\n",
       "      <td>0.524468</td>\n",
       "      <td>0.711025</td>\n",
       "      <td>0.846593</td>\n",
       "      <td>0.193049</td>\n",
       "      <td>-0.237687</td>\n",
       "      <td>...</td>\n",
       "      <td>0.384779</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.973695</td>\n",
       "      <td>0.185620</td>\n",
       "      <td>0.421184</td>\n",
       "      <td>0.559603</td>\n",
       "      <td>0.778771</td>\n",
       "      <td>0.165361</td>\n",
       "      <td>0.065067</td>\n",
       "      <td>0.758418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area_worst</th>\n",
       "      <td>0.938857</td>\n",
       "      <td>0.351195</td>\n",
       "      <td>0.938072</td>\n",
       "      <td>0.954319</td>\n",
       "      <td>0.150547</td>\n",
       "      <td>0.413235</td>\n",
       "      <td>0.632091</td>\n",
       "      <td>0.779507</td>\n",
       "      <td>0.127878</td>\n",
       "      <td>-0.289884</td>\n",
       "      <td>...</td>\n",
       "      <td>0.346245</td>\n",
       "      <td>0.973695</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.137289</td>\n",
       "      <td>0.301807</td>\n",
       "      <td>0.456288</td>\n",
       "      <td>0.686279</td>\n",
       "      <td>0.083964</td>\n",
       "      <td>-0.017631</td>\n",
       "      <td>0.686445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoothness_worst</th>\n",
       "      <td>0.044892</td>\n",
       "      <td>0.129277</td>\n",
       "      <td>0.080736</td>\n",
       "      <td>0.040650</td>\n",
       "      <td>0.821964</td>\n",
       "      <td>0.600349</td>\n",
       "      <td>0.464076</td>\n",
       "      <td>0.430682</td>\n",
       "      <td>0.488584</td>\n",
       "      <td>0.591673</td>\n",
       "      <td>...</td>\n",
       "      <td>0.298839</td>\n",
       "      <td>0.185620</td>\n",
       "      <td>0.137289</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.628456</td>\n",
       "      <td>0.552307</td>\n",
       "      <td>0.569055</td>\n",
       "      <td>0.575604</td>\n",
       "      <td>0.683425</td>\n",
       "      <td>0.426371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compactness_worst</th>\n",
       "      <td>0.287988</td>\n",
       "      <td>0.341648</td>\n",
       "      <td>0.337744</td>\n",
       "      <td>0.257296</td>\n",
       "      <td>0.544836</td>\n",
       "      <td>0.882386</td>\n",
       "      <td>0.745584</td>\n",
       "      <td>0.624768</td>\n",
       "      <td>0.549699</td>\n",
       "      <td>0.560740</td>\n",
       "      <td>...</td>\n",
       "      <td>0.428125</td>\n",
       "      <td>0.421184</td>\n",
       "      <td>0.301807</td>\n",
       "      <td>0.628456</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.892712</td>\n",
       "      <td>0.778965</td>\n",
       "      <td>0.670094</td>\n",
       "      <td>0.835955</td>\n",
       "      <td>0.570043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concavity_worst</th>\n",
       "      <td>0.450889</td>\n",
       "      <td>0.365546</td>\n",
       "      <td>0.495016</td>\n",
       "      <td>0.426802</td>\n",
       "      <td>0.495536</td>\n",
       "      <td>0.833959</td>\n",
       "      <td>0.878890</td>\n",
       "      <td>0.735843</td>\n",
       "      <td>0.494963</td>\n",
       "      <td>0.407056</td>\n",
       "      <td>...</td>\n",
       "      <td>0.433099</td>\n",
       "      <td>0.559603</td>\n",
       "      <td>0.456288</td>\n",
       "      <td>0.552307</td>\n",
       "      <td>0.892712</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.849029</td>\n",
       "      <td>0.552274</td>\n",
       "      <td>0.699492</td>\n",
       "      <td>0.654443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concave points_worst</th>\n",
       "      <td>0.690235</td>\n",
       "      <td>0.340085</td>\n",
       "      <td>0.723247</td>\n",
       "      <td>0.659754</td>\n",
       "      <td>0.538018</td>\n",
       "      <td>0.817379</td>\n",
       "      <td>0.867114</td>\n",
       "      <td>0.904650</td>\n",
       "      <td>0.476692</td>\n",
       "      <td>0.229681</td>\n",
       "      <td>...</td>\n",
       "      <td>0.402635</td>\n",
       "      <td>0.778771</td>\n",
       "      <td>0.686279</td>\n",
       "      <td>0.569055</td>\n",
       "      <td>0.778965</td>\n",
       "      <td>0.849029</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.501215</td>\n",
       "      <td>0.522938</td>\n",
       "      <td>0.804102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symmetry_worst</th>\n",
       "      <td>0.045430</td>\n",
       "      <td>0.137610</td>\n",
       "      <td>0.074824</td>\n",
       "      <td>0.015654</td>\n",
       "      <td>0.473614</td>\n",
       "      <td>0.553359</td>\n",
       "      <td>0.398858</td>\n",
       "      <td>0.327519</td>\n",
       "      <td>0.709566</td>\n",
       "      <td>0.492497</td>\n",
       "      <td>...</td>\n",
       "      <td>0.271695</td>\n",
       "      <td>0.165361</td>\n",
       "      <td>0.083964</td>\n",
       "      <td>0.575604</td>\n",
       "      <td>0.670094</td>\n",
       "      <td>0.552274</td>\n",
       "      <td>0.501215</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.654164</td>\n",
       "      <td>0.390073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <td>-0.079852</td>\n",
       "      <td>0.177389</td>\n",
       "      <td>-0.031790</td>\n",
       "      <td>-0.090751</td>\n",
       "      <td>0.581191</td>\n",
       "      <td>0.713886</td>\n",
       "      <td>0.511063</td>\n",
       "      <td>0.343633</td>\n",
       "      <td>0.529056</td>\n",
       "      <td>0.819104</td>\n",
       "      <td>...</td>\n",
       "      <td>0.287193</td>\n",
       "      <td>0.065067</td>\n",
       "      <td>-0.017631</td>\n",
       "      <td>0.683425</td>\n",
       "      <td>0.835955</td>\n",
       "      <td>0.699492</td>\n",
       "      <td>0.522938</td>\n",
       "      <td>0.654164</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.323382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tumor_type</th>\n",
       "      <td>0.694725</td>\n",
       "      <td>0.446257</td>\n",
       "      <td>0.711408</td>\n",
       "      <td>0.658262</td>\n",
       "      <td>0.379916</td>\n",
       "      <td>0.598092</td>\n",
       "      <td>0.692335</td>\n",
       "      <td>0.772781</td>\n",
       "      <td>0.354003</td>\n",
       "      <td>0.017469</td>\n",
       "      <td>...</td>\n",
       "      <td>0.484209</td>\n",
       "      <td>0.758418</td>\n",
       "      <td>0.686445</td>\n",
       "      <td>0.426371</td>\n",
       "      <td>0.570043</td>\n",
       "      <td>0.654443</td>\n",
       "      <td>0.804102</td>\n",
       "      <td>0.390073</td>\n",
       "      <td>0.323382</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "radius_mean                 1.000000      0.332085        0.997562   0.987398   \n",
       "texture_mean                0.332085      1.000000        0.344357   0.321685   \n",
       "perimeter_mean              0.997562      0.344357        1.000000   0.985549   \n",
       "area_mean                   0.987398      0.321685        0.985549   1.000000   \n",
       "smoothness_mean             0.109233      0.041540        0.150908   0.109977   \n",
       "compactness_mean            0.420384      0.300371        0.477502   0.402834   \n",
       "concavity_mean              0.645219      0.355344        0.689990   0.645443   \n",
       "concave points_mean         0.804236      0.340014        0.836713   0.797177   \n",
       "symmetry_mean               0.103929      0.100020        0.143550   0.095949   \n",
       "fractal_dimension_mean     -0.361631     -0.023954       -0.309058  -0.343027   \n",
       "radius_se                   0.681959      0.263519        0.692583   0.732354   \n",
       "texture_se                 -0.096991      0.356625       -0.087150  -0.065927   \n",
       "perimeter_se                0.680214      0.278188        0.698383   0.729233   \n",
       "area_se                     0.726737      0.245636        0.733187   0.790068   \n",
       "smoothness_se              -0.244737     -0.014882       -0.225202  -0.190659   \n",
       "compactness_se              0.153577      0.233460        0.202537   0.150329   \n",
       "concavity_se                0.190418      0.176449        0.228069   0.197203   \n",
       "concave points_se           0.378976      0.177938        0.412755   0.368810   \n",
       "symmetry_se                -0.140962     -0.014265       -0.117758  -0.115633   \n",
       "fractal_dimension_se       -0.081344      0.080055       -0.041447  -0.063823   \n",
       "radius_worst                0.966083      0.369341        0.966102   0.956581   \n",
       "texture_worst               0.290182      0.905327        0.302529   0.273383   \n",
       "perimeter_worst             0.960777      0.387674        0.967321   0.951052   \n",
       "area_worst                  0.938857      0.351195        0.938072   0.954319   \n",
       "smoothness_worst            0.044892      0.129277        0.080736   0.040650   \n",
       "compactness_worst           0.287988      0.341648        0.337744   0.257296   \n",
       "concavity_worst             0.450889      0.365546        0.495016   0.426802   \n",
       "concave points_worst        0.690235      0.340085        0.723247   0.659754   \n",
       "symmetry_worst              0.045430      0.137610        0.074824   0.015654   \n",
       "fractal_dimension_worst    -0.079852      0.177389       -0.031790  -0.090751   \n",
       "Tumor_type                  0.694725      0.446257        0.711408   0.658262   \n",
       "\n",
       "                         smoothness_mean  compactness_mean  concavity_mean  \\\n",
       "radius_mean                     0.109233          0.420384        0.645219   \n",
       "texture_mean                    0.041540          0.300371        0.355344   \n",
       "perimeter_mean                  0.150908          0.477502        0.689990   \n",
       "area_mean                       0.109977          0.402834        0.645443   \n",
       "smoothness_mean                 1.000000          0.685868        0.555397   \n",
       "compactness_mean                0.685868          1.000000        0.882442   \n",
       "concavity_mean                  0.555397          0.882442        1.000000   \n",
       "concave points_mean             0.547234          0.806118        0.923631   \n",
       "symmetry_mean                   0.592918          0.641931        0.524330   \n",
       "fractal_dimension_mean          0.644957          0.605441        0.348580   \n",
       "radius_se                       0.247419          0.403858        0.580443   \n",
       "texture_se                      0.065846          0.044816        0.053907   \n",
       "perimeter_se                    0.253590          0.472336        0.626714   \n",
       "area_se                         0.183543          0.346923        0.555754   \n",
       "smoothness_se                   0.304707          0.124782        0.068569   \n",
       "compactness_se                  0.370753          0.757987        0.657904   \n",
       "concavity_se                    0.281116          0.590887        0.688519   \n",
       "concave points_se               0.381811          0.632512        0.676415   \n",
       "symmetry_se                     0.244280          0.279159        0.174890   \n",
       "fractal_dimension_se            0.338153          0.531117        0.440340   \n",
       "radius_worst                    0.170375          0.457544        0.659356   \n",
       "texture_worst                   0.115695          0.313784        0.343633   \n",
       "perimeter_worst                 0.202430          0.524468        0.711025   \n",
       "area_worst                      0.150547          0.413235        0.632091   \n",
       "smoothness_worst                0.821964          0.600349        0.464076   \n",
       "compactness_worst               0.544836          0.882386        0.745584   \n",
       "concavity_worst                 0.495536          0.833959        0.878890   \n",
       "concave points_worst            0.538018          0.817379        0.867114   \n",
       "symmetry_worst                  0.473614          0.553359        0.398858   \n",
       "fractal_dimension_worst         0.581191          0.713886        0.511063   \n",
       "Tumor_type                      0.379916          0.598092        0.692335   \n",
       "\n",
       "                         concave points_mean  symmetry_mean  \\\n",
       "radius_mean                         0.804236       0.103929   \n",
       "texture_mean                        0.340014       0.100020   \n",
       "perimeter_mean                      0.836713       0.143550   \n",
       "area_mean                           0.797177       0.095949   \n",
       "smoothness_mean                     0.547234       0.592918   \n",
       "compactness_mean                    0.806118       0.641931   \n",
       "concavity_mean                      0.923631       0.524330   \n",
       "concave points_mean                 1.000000       0.461481   \n",
       "symmetry_mean                       0.461481       1.000000   \n",
       "fractal_dimension_mean              0.160248       0.540520   \n",
       "radius_se                           0.663240       0.239285   \n",
       "texture_se                          0.004939       0.113949   \n",
       "perimeter_se                        0.689464       0.255004   \n",
       "area_se                             0.639793       0.153652   \n",
       "smoothness_se                      -0.006200       0.165469   \n",
       "compactness_se                      0.474296       0.484327   \n",
       "concavity_se                        0.450960       0.376565   \n",
       "concave points_se                   0.625222       0.413488   \n",
       "symmetry_se                         0.079767       0.454793   \n",
       "fractal_dimension_se                0.248404       0.396279   \n",
       "radius_worst                        0.813792       0.155154   \n",
       "texture_worst                       0.327647       0.133498   \n",
       "perimeter_worst                     0.846593       0.193049   \n",
       "area_worst                          0.779507       0.127878   \n",
       "smoothness_worst                    0.430682       0.488584   \n",
       "compactness_worst                   0.624768       0.549699   \n",
       "concavity_worst                     0.735843       0.494963   \n",
       "concave points_worst                0.904650       0.476692   \n",
       "symmetry_worst                      0.327519       0.709566   \n",
       "fractal_dimension_worst             0.343633       0.529056   \n",
       "Tumor_type                          0.772781       0.354003   \n",
       "\n",
       "                         fractal_dimension_mean     ...      texture_worst  \\\n",
       "radius_mean                           -0.361631     ...           0.290182   \n",
       "texture_mean                          -0.023954     ...           0.905327   \n",
       "perimeter_mean                        -0.309058     ...           0.302529   \n",
       "area_mean                             -0.343027     ...           0.273383   \n",
       "smoothness_mean                        0.644957     ...           0.115695   \n",
       "compactness_mean                       0.605441     ...           0.313784   \n",
       "concavity_mean                         0.348580     ...           0.343633   \n",
       "concave points_mean                    0.160248     ...           0.327647   \n",
       "symmetry_mean                          0.540520     ...           0.133498   \n",
       "fractal_dimension_mean                 1.000000     ...           0.024437   \n",
       "radius_se                             -0.081466     ...           0.169281   \n",
       "texture_se                             0.147719     ...           0.382596   \n",
       "perimeter_se                          -0.037242     ...           0.180108   \n",
       "area_se                               -0.169220     ...           0.171525   \n",
       "smoothness_se                          0.378127     ...          -0.100634   \n",
       "compactness_se                         0.570760     ...           0.190251   \n",
       "concavity_se                           0.424989     ...           0.127237   \n",
       "concave points_se                      0.295335     ...           0.082557   \n",
       "symmetry_se                            0.413703     ...          -0.094044   \n",
       "fractal_dimension_se                   0.686234     ...           0.031731   \n",
       "radius_worst                          -0.290867     ...           0.367855   \n",
       "texture_worst                          0.024437     ...           1.000000   \n",
       "perimeter_worst                       -0.237687     ...           0.384779   \n",
       "area_worst                            -0.289884     ...           0.346245   \n",
       "smoothness_worst                       0.591673     ...           0.298839   \n",
       "compactness_worst                      0.560740     ...           0.428125   \n",
       "concavity_worst                        0.407056     ...           0.433099   \n",
       "concave points_worst                   0.229681     ...           0.402635   \n",
       "symmetry_worst                         0.492497     ...           0.271695   \n",
       "fractal_dimension_worst                0.819104     ...           0.287193   \n",
       "Tumor_type                             0.017469     ...           0.484209   \n",
       "\n",
       "                         perimeter_worst  area_worst  smoothness_worst  \\\n",
       "radius_mean                     0.960777    0.938857          0.044892   \n",
       "texture_mean                    0.387674    0.351195          0.129277   \n",
       "perimeter_mean                  0.967321    0.938072          0.080736   \n",
       "area_mean                       0.951052    0.954319          0.040650   \n",
       "smoothness_mean                 0.202430    0.150547          0.821964   \n",
       "compactness_mean                0.524468    0.413235          0.600349   \n",
       "concavity_mean                  0.711025    0.632091          0.464076   \n",
       "concave points_mean             0.846593    0.779507          0.430682   \n",
       "symmetry_mean                   0.193049    0.127878          0.488584   \n",
       "fractal_dimension_mean         -0.237687   -0.289884          0.591673   \n",
       "radius_se                       0.719625    0.753761          0.076494   \n",
       "texture_se                     -0.092925   -0.071544         -0.063044   \n",
       "perimeter_se                    0.723332    0.732691          0.075642   \n",
       "area_se                         0.749400    0.807279          0.050793   \n",
       "smoothness_se                  -0.238000   -0.205893          0.279393   \n",
       "compactness_se                  0.222198    0.138490          0.286040   \n",
       "concavity_se                    0.230429    0.175544          0.187098   \n",
       "concave points_se               0.404082    0.337045          0.205255   \n",
       "symmetry_se                    -0.135669   -0.155156          0.058723   \n",
       "fractal_dimension_se           -0.026816   -0.063031          0.232695   \n",
       "radius_worst                    0.992314    0.983096          0.159832   \n",
       "texture_worst                   0.384779    0.346245          0.298839   \n",
       "perimeter_worst                 1.000000    0.973695          0.185620   \n",
       "area_worst                      0.973695    1.000000          0.137289   \n",
       "smoothness_worst                0.185620    0.137289          1.000000   \n",
       "compactness_worst               0.421184    0.301807          0.628456   \n",
       "concavity_worst                 0.559603    0.456288          0.552307   \n",
       "concave points_worst            0.778771    0.686279          0.569055   \n",
       "symmetry_worst                  0.165361    0.083964          0.575604   \n",
       "fractal_dimension_worst         0.065067   -0.017631          0.683425   \n",
       "Tumor_type                      0.758418    0.686445          0.426371   \n",
       "\n",
       "                         compactness_worst  concavity_worst  \\\n",
       "radius_mean                       0.287988         0.450889   \n",
       "texture_mean                      0.341648         0.365546   \n",
       "perimeter_mean                    0.337744         0.495016   \n",
       "area_mean                         0.257296         0.426802   \n",
       "smoothness_mean                   0.544836         0.495536   \n",
       "compactness_mean                  0.882386         0.833959   \n",
       "concavity_mean                    0.745584         0.878890   \n",
       "concave points_mean               0.624768         0.735843   \n",
       "symmetry_mean                     0.549699         0.494963   \n",
       "fractal_dimension_mean            0.560740         0.407056   \n",
       "radius_se                         0.185029         0.302039   \n",
       "texture_se                       -0.056882        -0.067034   \n",
       "perimeter_se                      0.252592         0.355729   \n",
       "area_se                           0.163477         0.297699   \n",
       "smoothness_se                    -0.031031        -0.068973   \n",
       "compactness_se                    0.721438         0.652689   \n",
       "concavity_se                      0.509745         0.665916   \n",
       "concave points_se                 0.436759         0.526173   \n",
       "symmetry_se                       0.171865         0.079515   \n",
       "fractal_dimension_se              0.445820         0.402880   \n",
       "radius_worst                      0.355697         0.501906   \n",
       "texture_worst                     0.428125         0.433099   \n",
       "perimeter_worst                   0.421184         0.559603   \n",
       "area_worst                        0.301807         0.456288   \n",
       "smoothness_worst                  0.628456         0.552307   \n",
       "compactness_worst                 1.000000         0.892712   \n",
       "concavity_worst                   0.892712         1.000000   \n",
       "concave points_worst              0.778965         0.849029   \n",
       "symmetry_worst                    0.670094         0.552274   \n",
       "fractal_dimension_worst           0.835955         0.699492   \n",
       "Tumor_type                        0.570043         0.654443   \n",
       "\n",
       "                         concave points_worst  symmetry_worst  \\\n",
       "radius_mean                          0.690235        0.045430   \n",
       "texture_mean                         0.340085        0.137610   \n",
       "perimeter_mean                       0.723247        0.074824   \n",
       "area_mean                            0.659754        0.015654   \n",
       "smoothness_mean                      0.538018        0.473614   \n",
       "compactness_mean                     0.817379        0.553359   \n",
       "concavity_mean                       0.867114        0.398858   \n",
       "concave points_mean                  0.904650        0.327519   \n",
       "symmetry_mean                        0.476692        0.709566   \n",
       "fractal_dimension_mean               0.229681        0.492497   \n",
       "radius_se                            0.478267       -0.002878   \n",
       "texture_se                          -0.127914       -0.101714   \n",
       "perimeter_se                         0.513030        0.012299   \n",
       "area_se                              0.469867       -0.038354   \n",
       "smoothness_se                       -0.113837       -0.085768   \n",
       "compactness_se                       0.488181        0.374726   \n",
       "concavity_se                         0.451271        0.224736   \n",
       "concave points_se                    0.601158        0.143464   \n",
       "symmetry_se                          0.002702        0.466703   \n",
       "fractal_dimension_se                 0.234392        0.221832   \n",
       "radius_worst                         0.740859        0.138146   \n",
       "texture_worst                        0.402635        0.271695   \n",
       "perimeter_worst                      0.778771        0.165361   \n",
       "area_worst                           0.686279        0.083964   \n",
       "smoothness_worst                     0.569055        0.575604   \n",
       "compactness_worst                    0.778965        0.670094   \n",
       "concavity_worst                      0.849029        0.552274   \n",
       "concave points_worst                 1.000000        0.501215   \n",
       "symmetry_worst                       0.501215        1.000000   \n",
       "fractal_dimension_worst              0.522938        0.654164   \n",
       "Tumor_type                           0.804102        0.390073   \n",
       "\n",
       "                         fractal_dimension_worst  Tumor_type  \n",
       "radius_mean                            -0.079852    0.694725  \n",
       "texture_mean                            0.177389    0.446257  \n",
       "perimeter_mean                         -0.031790    0.711408  \n",
       "area_mean                              -0.090751    0.658262  \n",
       "smoothness_mean                         0.581191    0.379916  \n",
       "compactness_mean                        0.713886    0.598092  \n",
       "concavity_mean                          0.511063    0.692335  \n",
       "concave points_mean                     0.343633    0.772781  \n",
       "symmetry_mean                           0.529056    0.354003  \n",
       "fractal_dimension_mean                  0.819104    0.017469  \n",
       "radius_se                              -0.033896    0.526287  \n",
       "texture_se                             -0.025060   -0.024650  \n",
       "perimeter_se                            0.006026    0.523860  \n",
       "area_se                                -0.074600    0.491076  \n",
       "smoothness_se                           0.104911   -0.101332  \n",
       "compactness_se                          0.610805    0.306899  \n",
       "concavity_se                            0.431385    0.270451  \n",
       "concave points_se                       0.275913    0.434074  \n",
       "symmetry_se                             0.209253   -0.019801  \n",
       "fractal_dimension_se                    0.612982    0.087559  \n",
       "radius_worst                            0.014303    0.746838  \n",
       "texture_worst                           0.287193    0.484209  \n",
       "perimeter_worst                         0.065067    0.758418  \n",
       "area_worst                             -0.017631    0.686445  \n",
       "smoothness_worst                        0.683425    0.426371  \n",
       "compactness_worst                       0.835955    0.570043  \n",
       "concavity_worst                         0.699492    0.654443  \n",
       "concave points_worst                    0.522938    0.804102  \n",
       "symmetry_worst                          0.654164    0.390073  \n",
       "fractal_dimension_worst                 1.000000    0.323382  \n",
       "Tumor_type                              0.323382    1.000000  \n",
       "\n",
       "[31 rows x 31 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Tumor_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7.140000e+02</td>\n",
       "      <td>7.140000e+02</td>\n",
       "      <td>7.140000e+02</td>\n",
       "      <td>7.140000e+02</td>\n",
       "      <td>7.140000e+02</td>\n",
       "      <td>7.140000e+02</td>\n",
       "      <td>7.140000e+02</td>\n",
       "      <td>7.140000e+02</td>\n",
       "      <td>7.140000e+02</td>\n",
       "      <td>7.140000e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>7.140000e+02</td>\n",
       "      <td>7.140000e+02</td>\n",
       "      <td>7.140000e+02</td>\n",
       "      <td>7.140000e+02</td>\n",
       "      <td>7.140000e+02</td>\n",
       "      <td>7.140000e+02</td>\n",
       "      <td>7.140000e+02</td>\n",
       "      <td>7.140000e+02</td>\n",
       "      <td>7.140000e+02</td>\n",
       "      <td>714.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-3.172066e-17</td>\n",
       "      <td>6.903908e-17</td>\n",
       "      <td>-2.469236e-16</td>\n",
       "      <td>-5.348974e-17</td>\n",
       "      <td>-2.707918e-16</td>\n",
       "      <td>1.020037e-16</td>\n",
       "      <td>-8.318898e-17</td>\n",
       "      <td>-5.652186e-17</td>\n",
       "      <td>-8.836983e-16</td>\n",
       "      <td>-1.866135e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.922744e-16</td>\n",
       "      <td>-3.731842e-16</td>\n",
       "      <td>1.063575e-16</td>\n",
       "      <td>2.702476e-16</td>\n",
       "      <td>-2.388379e-16</td>\n",
       "      <td>2.469236e-16</td>\n",
       "      <td>1.131992e-16</td>\n",
       "      <td>5.162382e-16</td>\n",
       "      <td>2.945045e-16</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000701e+00</td>\n",
       "      <td>1.000701e+00</td>\n",
       "      <td>1.000701e+00</td>\n",
       "      <td>1.000701e+00</td>\n",
       "      <td>1.000701e+00</td>\n",
       "      <td>1.000701e+00</td>\n",
       "      <td>1.000701e+00</td>\n",
       "      <td>1.000701e+00</td>\n",
       "      <td>1.000701e+00</td>\n",
       "      <td>1.000701e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000701e+00</td>\n",
       "      <td>1.000701e+00</td>\n",
       "      <td>1.000701e+00</td>\n",
       "      <td>1.000701e+00</td>\n",
       "      <td>1.000701e+00</td>\n",
       "      <td>1.000701e+00</td>\n",
       "      <td>1.000701e+00</td>\n",
       "      <td>1.000701e+00</td>\n",
       "      <td>1.000701e+00</td>\n",
       "      <td>0.500351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.076787e+00</td>\n",
       "      <td>-2.365222e+00</td>\n",
       "      <td>-2.045232e+00</td>\n",
       "      <td>-1.487850e+00</td>\n",
       "      <td>-3.153731e+00</td>\n",
       "      <td>-1.655355e+00</td>\n",
       "      <td>-1.239197e+00</td>\n",
       "      <td>-1.403550e+00</td>\n",
       "      <td>-2.827180e+00</td>\n",
       "      <td>-1.662285e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.324684e+00</td>\n",
       "      <td>-1.782179e+00</td>\n",
       "      <td>-1.283883e+00</td>\n",
       "      <td>-2.613171e+00</td>\n",
       "      <td>-1.429760e+00</td>\n",
       "      <td>-1.394872e+00</td>\n",
       "      <td>-1.886467e+00</td>\n",
       "      <td>-2.004274e+00</td>\n",
       "      <td>-1.497326e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-7.359351e-01</td>\n",
       "      <td>-6.952881e-01</td>\n",
       "      <td>-7.306814e-01</td>\n",
       "      <td>-7.108508e-01</td>\n",
       "      <td>-7.199732e-01</td>\n",
       "      <td>-7.519172e-01</td>\n",
       "      <td>-8.192341e-01</td>\n",
       "      <td>-8.288225e-01</td>\n",
       "      <td>-7.162056e-01</td>\n",
       "      <td>-7.345795e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.235847e-01</td>\n",
       "      <td>-7.676057e-01</td>\n",
       "      <td>-7.068275e-01</td>\n",
       "      <td>-6.920292e-01</td>\n",
       "      <td>-6.885715e-01</td>\n",
       "      <td>-7.811058e-01</td>\n",
       "      <td>-8.140883e-01</td>\n",
       "      <td>-6.348153e-01</td>\n",
       "      <td>-6.679380e-01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-2.336006e-01</td>\n",
       "      <td>-5.795350e-02</td>\n",
       "      <td>-2.292148e-01</td>\n",
       "      <td>-3.090353e-01</td>\n",
       "      <td>-2.264975e-02</td>\n",
       "      <td>-1.746033e-01</td>\n",
       "      <td>-2.013409e-01</td>\n",
       "      <td>-1.238573e-01</td>\n",
       "      <td>-9.597092e-02</td>\n",
       "      <td>-1.713300e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.911481e-02</td>\n",
       "      <td>-2.298614e-01</td>\n",
       "      <td>-3.507142e-01</td>\n",
       "      <td>-4.663456e-02</td>\n",
       "      <td>-2.617076e-01</td>\n",
       "      <td>-1.468511e-01</td>\n",
       "      <td>-3.998254e-02</td>\n",
       "      <td>-1.700509e-01</td>\n",
       "      <td>-2.356845e-01</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.413042e-01</td>\n",
       "      <td>5.565774e-01</td>\n",
       "      <td>6.005975e-01</td>\n",
       "      <td>5.509774e-01</td>\n",
       "      <td>6.031489e-01</td>\n",
       "      <td>5.655987e-01</td>\n",
       "      <td>5.688290e-01</td>\n",
       "      <td>7.170484e-01</td>\n",
       "      <td>5.006876e-01</td>\n",
       "      <td>4.734760e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>6.661693e-01</td>\n",
       "      <td>5.758109e-01</td>\n",
       "      <td>4.775790e-01</td>\n",
       "      <td>6.068910e-01</td>\n",
       "      <td>5.289449e-01</td>\n",
       "      <td>5.278239e-01</td>\n",
       "      <td>7.800309e-01</td>\n",
       "      <td>3.436734e-01</td>\n",
       "      <td>3.565294e-01</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.576383e+00</td>\n",
       "      <td>4.550736e+00</td>\n",
       "      <td>3.584499e+00</td>\n",
       "      <td>4.637466e+00</td>\n",
       "      <td>4.557027e+00</td>\n",
       "      <td>4.022777e+00</td>\n",
       "      <td>3.823633e+00</td>\n",
       "      <td>3.202607e+00</td>\n",
       "      <td>4.354485e+00</td>\n",
       "      <td>4.388187e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>3.682640e+00</td>\n",
       "      <td>3.834867e+00</td>\n",
       "      <td>5.220960e+00</td>\n",
       "      <td>3.543183e+00</td>\n",
       "      <td>4.273064e+00</td>\n",
       "      <td>4.181581e+00</td>\n",
       "      <td>2.344454e+00</td>\n",
       "      <td>5.194962e+00</td>\n",
       "      <td>5.837274e+00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        radius_mean  texture_mean  perimeter_mean     area_mean  \\\n",
       "count  7.140000e+02  7.140000e+02    7.140000e+02  7.140000e+02   \n",
       "mean  -3.172066e-17  6.903908e-17   -2.469236e-16 -5.348974e-17   \n",
       "std    1.000701e+00  1.000701e+00    1.000701e+00  1.000701e+00   \n",
       "min   -2.076787e+00 -2.365222e+00   -2.045232e+00 -1.487850e+00   \n",
       "25%   -7.359351e-01 -6.952881e-01   -7.306814e-01 -7.108508e-01   \n",
       "50%   -2.336006e-01 -5.795350e-02   -2.292148e-01 -3.090353e-01   \n",
       "75%    6.413042e-01  5.565774e-01    6.005975e-01  5.509774e-01   \n",
       "max    3.576383e+00  4.550736e+00    3.584499e+00  4.637466e+00   \n",
       "\n",
       "       smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "count     7.140000e+02      7.140000e+02    7.140000e+02         7.140000e+02   \n",
       "mean     -2.707918e-16      1.020037e-16   -8.318898e-17        -5.652186e-17   \n",
       "std       1.000701e+00      1.000701e+00    1.000701e+00         1.000701e+00   \n",
       "min      -3.153731e+00     -1.655355e+00   -1.239197e+00        -1.403550e+00   \n",
       "25%      -7.199732e-01     -7.519172e-01   -8.192341e-01        -8.288225e-01   \n",
       "50%      -2.264975e-02     -1.746033e-01   -2.013409e-01        -1.238573e-01   \n",
       "75%       6.031489e-01      5.655987e-01    5.688290e-01         7.170484e-01   \n",
       "max       4.557027e+00      4.022777e+00    3.823633e+00         3.202607e+00   \n",
       "\n",
       "       symmetry_mean  fractal_dimension_mean     ...      texture_worst  \\\n",
       "count   7.140000e+02            7.140000e+02     ...       7.140000e+02   \n",
       "mean   -8.836983e-16           -1.866135e-15     ...      -5.922744e-16   \n",
       "std     1.000701e+00            1.000701e+00     ...       1.000701e+00   \n",
       "min    -2.827180e+00           -1.662285e+00     ...      -2.324684e+00   \n",
       "25%    -7.162056e-01           -7.345795e-01     ...      -7.235847e-01   \n",
       "50%    -9.597092e-02           -1.713300e-01     ...      -3.911481e-02   \n",
       "75%     5.006876e-01            4.734760e-01     ...       6.661693e-01   \n",
       "max     4.354485e+00            4.388187e+00     ...       3.682640e+00   \n",
       "\n",
       "       perimeter_worst    area_worst  smoothness_worst  compactness_worst  \\\n",
       "count     7.140000e+02  7.140000e+02      7.140000e+02       7.140000e+02   \n",
       "mean     -3.731842e-16  1.063575e-16      2.702476e-16      -2.388379e-16   \n",
       "std       1.000701e+00  1.000701e+00      1.000701e+00       1.000701e+00   \n",
       "min      -1.782179e+00 -1.283883e+00     -2.613171e+00      -1.429760e+00   \n",
       "25%      -7.676057e-01 -7.068275e-01     -6.920292e-01      -6.885715e-01   \n",
       "50%      -2.298614e-01 -3.507142e-01     -4.663456e-02      -2.617076e-01   \n",
       "75%       5.758109e-01  4.775790e-01      6.068910e-01       5.289449e-01   \n",
       "max       3.834867e+00  5.220960e+00      3.543183e+00       4.273064e+00   \n",
       "\n",
       "       concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "count     7.140000e+02          7.140000e+02    7.140000e+02   \n",
       "mean      2.469236e-16          1.131992e-16    5.162382e-16   \n",
       "std       1.000701e+00          1.000701e+00    1.000701e+00   \n",
       "min      -1.394872e+00         -1.886467e+00   -2.004274e+00   \n",
       "25%      -7.811058e-01         -8.140883e-01   -6.348153e-01   \n",
       "50%      -1.468511e-01         -3.998254e-02   -1.700509e-01   \n",
       "75%       5.278239e-01          7.800309e-01    3.436734e-01   \n",
       "max       4.181581e+00          2.344454e+00    5.194962e+00   \n",
       "\n",
       "       fractal_dimension_worst  Tumor_type  \n",
       "count             7.140000e+02  714.000000  \n",
       "mean              2.945045e-16    0.500000  \n",
       "std               1.000701e+00    0.500351  \n",
       "min              -1.497326e+00    0.000000  \n",
       "25%              -6.679380e-01    0.000000  \n",
       "50%              -2.356845e-01    0.500000  \n",
       "75%               3.565294e-01    1.000000  \n",
       "max               5.837274e+00    1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = data1.iloc[:, 0:30].values\n",
    "y_train= data1.Tumor_type\n",
    "x_test= data1.iloc[:, 0:30].values\n",
    "y_test= data1.Tumor_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(714, 30)\n",
      "(714, 30)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(714,)\n",
      "(714,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from scipy.stats import randint \n",
    "#from sklearn.tree import DecisionTreeClassifier \n",
    "#from sklearn.model_selection import RandomizedSearchCV \n",
    "  \n",
    "#param_dist = {\"max_depth\": [3, None],\n",
    "#              \"max_features\": randint(1, 9), \n",
    "#              \"min_samples_leaf\": randint(1, 9),\n",
    "#              \"criterion\": [\"gini\", \"entropy\"]} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyper Parameters: {'C': 3, 'kernel': 'rbf'}\n",
      "Training Accuracy: 0.9944\n",
      "Testing Accuracy: {:.4f} 0.9943977591036415\n",
      "Confusion Metrix:\n",
      " [[357   4]\n",
      " [  0 353]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       1.00      0.99      0.99       357\n",
      "          0       0.99      1.00      0.99       357\n",
      "\n",
      "avg / total       0.99      0.99      0.99       714\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Support Vector Machine\n",
    "#importing modules\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm\n",
    "#making the instance\n",
    "model=svm.SVC()\n",
    "#Hyper Parameters Set\n",
    "params = {'C': [3,4,5,6,7,8,9,10,11,12], \n",
    "          'kernel': ['linear','rbf']}\n",
    "#Making models with hyper parameters sets\n",
    "model1 = GridSearchCV(model, param_grid=params, cv=10, scoring=\"accuracy\", n_jobs=-1)\n",
    "#Learning\n",
    "model1.fit(x_train,y_train)\n",
    "#The best hyper parameters set\n",
    "print(\"Best Hyper Parameters:\", model1.best_params_)\n",
    "#Prediction\n",
    "prediction=model1.predict(x_test)\n",
    "#importing the metrics module\n",
    "from sklearn import metrics\n",
    "#evaluation(Train Score)\n",
    "train_score=model1.score(x_train,y_train)\n",
    "print('Training Accuracy: {:.4f}'.format(train_score))\n",
    "#evaluation(Accuracy)\n",
    "print(\"Testing Accuracy: {:.4f}\",metrics.accuracy_score(prediction,y_test))\n",
    "#evaluation(Confusion Metrix)\n",
    "print(\"Confusion Metrix:\\n\",metrics.confusion_matrix(prediction,y_test))\n",
    "#evaluation(Classification_report)\n",
    "print(\"Classification Report:\\n\",metrics.classification_report(y_test, prediction, labels=[1,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sathish kumar\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[mean: 0.97479, std: 0.01387, params: {'C': 3, 'kernel': 'linear'},\n",
       " mean: 0.98599, std: 0.01690, params: {'C': 3, 'kernel': 'rbf'},\n",
       " mean: 0.97479, std: 0.01772, params: {'C': 4, 'kernel': 'linear'},\n",
       " mean: 0.98599, std: 0.01278, params: {'C': 4, 'kernel': 'rbf'},\n",
       " mean: 0.97059, std: 0.01726, params: {'C': 5, 'kernel': 'linear'},\n",
       " mean: 0.98179, std: 0.01422, params: {'C': 5, 'kernel': 'rbf'},\n",
       " mean: 0.97059, std: 0.02050, params: {'C': 6, 'kernel': 'linear'},\n",
       " mean: 0.98039, std: 0.01568, params: {'C': 6, 'kernel': 'rbf'},\n",
       " mean: 0.97199, std: 0.01896, params: {'C': 7, 'kernel': 'linear'},\n",
       " mean: 0.98459, std: 0.01457, params: {'C': 7, 'kernel': 'rbf'},\n",
       " mean: 0.97339, std: 0.01944, params: {'C': 8, 'kernel': 'linear'},\n",
       " mean: 0.98459, std: 0.01457, params: {'C': 8, 'kernel': 'rbf'},\n",
       " mean: 0.97339, std: 0.01944, params: {'C': 9, 'kernel': 'linear'},\n",
       " mean: 0.98459, std: 0.01457, params: {'C': 9, 'kernel': 'rbf'},\n",
       " mean: 0.97339, std: 0.01944, params: {'C': 10, 'kernel': 'linear'},\n",
       " mean: 0.98599, std: 0.01397, params: {'C': 10, 'kernel': 'rbf'},\n",
       " mean: 0.97479, std: 0.01775, params: {'C': 11, 'kernel': 'linear'},\n",
       " mean: 0.98599, std: 0.01389, params: {'C': 11, 'kernel': 'rbf'},\n",
       " mean: 0.97479, std: 0.01775, params: {'C': 12, 'kernel': 'linear'},\n",
       " mean: 0.98599, std: 0.01389, params: {'C': 12, 'kernel': 'rbf'}]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyper Parameters: {'algorithm': 'auto', 'leaf_size': 1, 'n_jobs': -1, 'n_neighbors': 8, 'weights': 'distance'}\n",
      "Training Accuracy: 1.0000\n",
      "Testing Accuracy: {:.4f} 1.0\n",
      "Confusion Metrix:\n",
      " [[357   0]\n",
      " [  0 357]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       1.00      1.00      1.00       357\n",
      "          0       1.00      1.00      1.00       357\n",
      "\n",
      "avg / total       1.00      1.00      1.00       714\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#kNearestNeighbors\n",
    "#importing modules\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from scipy.stats import randint\n",
    "#making the instance\n",
    "model = KNeighborsClassifier(n_jobs=-1)\n",
    "#Hyper Parameters Set\n",
    "params = {'n_neighbors':[3,4,5,6,7,8,9],\n",
    "          'leaf_size':[1,2,3,5],\n",
    "          'weights':['uniform', 'distance'],\n",
    "          'algorithm':['auto', 'ball_tree','kd_tree','brute'],\n",
    "          'n_jobs':[-1]}\n",
    "#Making models with hyper parameters sets\n",
    "model2 = GridSearchCV(model, param_grid=params,cv=10, scoring=\"accuracy\", n_jobs=-1)\n",
    "#Learing\n",
    "model2.fit(x_train,y_train)\n",
    "#The best hyper parameters set\n",
    "print(\"Best Hyper Parameters:\",model2.best_params_)\n",
    "#Prediction\n",
    "prediction=model2.predict(x_test)\n",
    "#importing the metrics module\n",
    "from sklearn import metrics\n",
    "#evaluation(Train Score)\n",
    "train_score=model2.score(x_train,y_train)\n",
    "print('Training Accuracy: {:.4f}'.format(train_score))\n",
    "#evaluation(Accuracy)\n",
    "print(\"Testing Accuracy: {:.4f}\",metrics.accuracy_score(prediction,y_test))\n",
    "#evaluation(Confusion Metrix)\n",
    "print(\"Confusion Metrix:\\n\",metrics.confusion_matrix(prediction,y_test))\n",
    "#evaluation(Classification_report)\n",
    "print(\"Classification Report:\\n\",metrics.classification_report(y_test, prediction, labels=[1,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sathish kumar\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[mean: 0.97199, std: 0.02360, params: {'algorithm': 'auto', 'leaf_size': 1, 'n_jobs': -1, 'n_neighbors': 3, 'weights': 'uniform'},\n",
       " mean: 0.97199, std: 0.02360, params: {'algorithm': 'auto', 'leaf_size': 1, 'n_jobs': -1, 'n_neighbors': 3, 'weights': 'distance'},\n",
       " mean: 0.97059, std: 0.02050, params: {'algorithm': 'auto', 'leaf_size': 1, 'n_jobs': -1, 'n_neighbors': 4, 'weights': 'uniform'},\n",
       " mean: 0.97339, std: 0.02219, params: {'algorithm': 'auto', 'leaf_size': 1, 'n_jobs': -1, 'n_neighbors': 4, 'weights': 'distance'},\n",
       " mean: 0.97199, std: 0.02297, params: {'algorithm': 'auto', 'leaf_size': 1, 'n_jobs': -1, 'n_neighbors': 5, 'weights': 'uniform'},\n",
       " mean: 0.97619, std: 0.02112, params: {'algorithm': 'auto', 'leaf_size': 1, 'n_jobs': -1, 'n_neighbors': 5, 'weights': 'distance'},\n",
       " mean: 0.97479, std: 0.01891, params: {'algorithm': 'auto', 'leaf_size': 1, 'n_jobs': -1, 'n_neighbors': 6, 'weights': 'uniform'},\n",
       " mean: 0.97479, std: 0.02073, params: {'algorithm': 'auto', 'leaf_size': 1, 'n_jobs': -1, 'n_neighbors': 6, 'weights': 'distance'},\n",
       " mean: 0.97339, std: 0.01965, params: {'algorithm': 'auto', 'leaf_size': 1, 'n_jobs': -1, 'n_neighbors': 7, 'weights': 'uniform'},\n",
       " mean: 0.97619, std: 0.01802, params: {'algorithm': 'auto', 'leaf_size': 1, 'n_jobs': -1, 'n_neighbors': 7, 'weights': 'distance'},\n",
       " mean: 0.97059, std: 0.01623, params: {'algorithm': 'auto', 'leaf_size': 1, 'n_jobs': -1, 'n_neighbors': 8, 'weights': 'uniform'},\n",
       " mean: 0.97759, std: 0.01711, params: {'algorithm': 'auto', 'leaf_size': 1, 'n_jobs': -1, 'n_neighbors': 8, 'weights': 'distance'},\n",
       " mean: 0.97199, std: 0.02015, params: {'algorithm': 'auto', 'leaf_size': 1, 'n_jobs': -1, 'n_neighbors': 9, 'weights': 'uniform'},\n",
       " mean: 0.97759, std: 0.01575, params: {'algorithm': 'auto', 'leaf_size': 1, 'n_jobs': -1, 'n_neighbors': 9, 'weights': 'distance'},\n",
       " mean: 0.97199, std: 0.02360, params: {'algorithm': 'auto', 'leaf_size': 2, 'n_jobs': -1, 'n_neighbors': 3, 'weights': 'uniform'},\n",
       " mean: 0.97199, std: 0.02360, params: {'algorithm': 'auto', 'leaf_size': 2, 'n_jobs': -1, 'n_neighbors': 3, 'weights': 'distance'},\n",
       " mean: 0.97059, std: 0.02050, params: {'algorithm': 'auto', 'leaf_size': 2, 'n_jobs': -1, 'n_neighbors': 4, 'weights': 'uniform'},\n",
       " mean: 0.97339, std: 0.02219, params: {'algorithm': 'auto', 'leaf_size': 2, 'n_jobs': -1, 'n_neighbors': 4, 'weights': 'distance'},\n",
       " mean: 0.97199, std: 0.02297, params: {'algorithm': 'auto', 'leaf_size': 2, 'n_jobs': -1, 'n_neighbors': 5, 'weights': 'uniform'},\n",
       " mean: 0.97619, std: 0.02112, params: {'algorithm': 'auto', 'leaf_size': 2, 'n_jobs': -1, 'n_neighbors': 5, 'weights': 'distance'},\n",
       " mean: 0.97479, std: 0.01891, params: {'algorithm': 'auto', 'leaf_size': 2, 'n_jobs': -1, 'n_neighbors': 6, 'weights': 'uniform'},\n",
       " mean: 0.97479, std: 0.02073, params: {'algorithm': 'auto', 'leaf_size': 2, 'n_jobs': -1, 'n_neighbors': 6, 'weights': 'distance'},\n",
       " mean: 0.97339, std: 0.01965, params: {'algorithm': 'auto', 'leaf_size': 2, 'n_jobs': -1, 'n_neighbors': 7, 'weights': 'uniform'},\n",
       " mean: 0.97619, std: 0.01802, params: {'algorithm': 'auto', 'leaf_size': 2, 'n_jobs': -1, 'n_neighbors': 7, 'weights': 'distance'},\n",
       " mean: 0.97059, std: 0.01623, params: {'algorithm': 'auto', 'leaf_size': 2, 'n_jobs': -1, 'n_neighbors': 8, 'weights': 'uniform'},\n",
       " mean: 0.97759, std: 0.01711, params: {'algorithm': 'auto', 'leaf_size': 2, 'n_jobs': -1, 'n_neighbors': 8, 'weights': 'distance'},\n",
       " mean: 0.97199, std: 0.02015, params: {'algorithm': 'auto', 'leaf_size': 2, 'n_jobs': -1, 'n_neighbors': 9, 'weights': 'uniform'},\n",
       " mean: 0.97759, std: 0.01575, params: {'algorithm': 'auto', 'leaf_size': 2, 'n_jobs': -1, 'n_neighbors': 9, 'weights': 'distance'},\n",
       " mean: 0.97199, std: 0.02360, params: {'algorithm': 'auto', 'leaf_size': 3, 'n_jobs': -1, 'n_neighbors': 3, 'weights': 'uniform'},\n",
       " mean: 0.97199, std: 0.02360, params: {'algorithm': 'auto', 'leaf_size': 3, 'n_jobs': -1, 'n_neighbors': 3, 'weights': 'distance'},\n",
       " mean: 0.97059, std: 0.02050, params: {'algorithm': 'auto', 'leaf_size': 3, 'n_jobs': -1, 'n_neighbors': 4, 'weights': 'uniform'},\n",
       " mean: 0.97339, std: 0.02219, params: {'algorithm': 'auto', 'leaf_size': 3, 'n_jobs': -1, 'n_neighbors': 4, 'weights': 'distance'},\n",
       " mean: 0.97199, std: 0.02297, params: {'algorithm': 'auto', 'leaf_size': 3, 'n_jobs': -1, 'n_neighbors': 5, 'weights': 'uniform'},\n",
       " mean: 0.97619, std: 0.02112, params: {'algorithm': 'auto', 'leaf_size': 3, 'n_jobs': -1, 'n_neighbors': 5, 'weights': 'distance'},\n",
       " mean: 0.97479, std: 0.01891, params: {'algorithm': 'auto', 'leaf_size': 3, 'n_jobs': -1, 'n_neighbors': 6, 'weights': 'uniform'},\n",
       " mean: 0.97479, std: 0.02073, params: {'algorithm': 'auto', 'leaf_size': 3, 'n_jobs': -1, 'n_neighbors': 6, 'weights': 'distance'},\n",
       " mean: 0.97339, std: 0.01965, params: {'algorithm': 'auto', 'leaf_size': 3, 'n_jobs': -1, 'n_neighbors': 7, 'weights': 'uniform'},\n",
       " mean: 0.97619, std: 0.01802, params: {'algorithm': 'auto', 'leaf_size': 3, 'n_jobs': -1, 'n_neighbors': 7, 'weights': 'distance'},\n",
       " mean: 0.97059, std: 0.01623, params: {'algorithm': 'auto', 'leaf_size': 3, 'n_jobs': -1, 'n_neighbors': 8, 'weights': 'uniform'},\n",
       " mean: 0.97759, std: 0.01711, params: {'algorithm': 'auto', 'leaf_size': 3, 'n_jobs': -1, 'n_neighbors': 8, 'weights': 'distance'},\n",
       " mean: 0.97199, std: 0.02015, params: {'algorithm': 'auto', 'leaf_size': 3, 'n_jobs': -1, 'n_neighbors': 9, 'weights': 'uniform'},\n",
       " mean: 0.97759, std: 0.01575, params: {'algorithm': 'auto', 'leaf_size': 3, 'n_jobs': -1, 'n_neighbors': 9, 'weights': 'distance'},\n",
       " mean: 0.97199, std: 0.02360, params: {'algorithm': 'auto', 'leaf_size': 5, 'n_jobs': -1, 'n_neighbors': 3, 'weights': 'uniform'},\n",
       " mean: 0.97199, std: 0.02360, params: {'algorithm': 'auto', 'leaf_size': 5, 'n_jobs': -1, 'n_neighbors': 3, 'weights': 'distance'},\n",
       " mean: 0.97059, std: 0.02050, params: {'algorithm': 'auto', 'leaf_size': 5, 'n_jobs': -1, 'n_neighbors': 4, 'weights': 'uniform'},\n",
       " mean: 0.97339, std: 0.02219, params: {'algorithm': 'auto', 'leaf_size': 5, 'n_jobs': -1, 'n_neighbors': 4, 'weights': 'distance'},\n",
       " mean: 0.97199, std: 0.02297, params: {'algorithm': 'auto', 'leaf_size': 5, 'n_jobs': -1, 'n_neighbors': 5, 'weights': 'uniform'},\n",
       " mean: 0.97619, std: 0.02112, params: {'algorithm': 'auto', 'leaf_size': 5, 'n_jobs': -1, 'n_neighbors': 5, 'weights': 'distance'},\n",
       " mean: 0.97479, std: 0.01891, params: {'algorithm': 'auto', 'leaf_size': 5, 'n_jobs': -1, 'n_neighbors': 6, 'weights': 'uniform'},\n",
       " mean: 0.97479, std: 0.02073, params: {'algorithm': 'auto', 'leaf_size': 5, 'n_jobs': -1, 'n_neighbors': 6, 'weights': 'distance'},\n",
       " mean: 0.97339, std: 0.01965, params: {'algorithm': 'auto', 'leaf_size': 5, 'n_jobs': -1, 'n_neighbors': 7, 'weights': 'uniform'},\n",
       " mean: 0.97619, std: 0.01802, params: {'algorithm': 'auto', 'leaf_size': 5, 'n_jobs': -1, 'n_neighbors': 7, 'weights': 'distance'},\n",
       " mean: 0.97059, std: 0.01623, params: {'algorithm': 'auto', 'leaf_size': 5, 'n_jobs': -1, 'n_neighbors': 8, 'weights': 'uniform'},\n",
       " mean: 0.97759, std: 0.01711, params: {'algorithm': 'auto', 'leaf_size': 5, 'n_jobs': -1, 'n_neighbors': 8, 'weights': 'distance'},\n",
       " mean: 0.97199, std: 0.02015, params: {'algorithm': 'auto', 'leaf_size': 5, 'n_jobs': -1, 'n_neighbors': 9, 'weights': 'uniform'},\n",
       " mean: 0.97759, std: 0.01575, params: {'algorithm': 'auto', 'leaf_size': 5, 'n_jobs': -1, 'n_neighbors': 9, 'weights': 'distance'},\n",
       " mean: 0.97199, std: 0.02360, params: {'algorithm': 'ball_tree', 'leaf_size': 1, 'n_jobs': -1, 'n_neighbors': 3, 'weights': 'uniform'},\n",
       " mean: 0.97199, std: 0.02360, params: {'algorithm': 'ball_tree', 'leaf_size': 1, 'n_jobs': -1, 'n_neighbors': 3, 'weights': 'distance'},\n",
       " mean: 0.97059, std: 0.02050, params: {'algorithm': 'ball_tree', 'leaf_size': 1, 'n_jobs': -1, 'n_neighbors': 4, 'weights': 'uniform'},\n",
       " mean: 0.97339, std: 0.02219, params: {'algorithm': 'ball_tree', 'leaf_size': 1, 'n_jobs': -1, 'n_neighbors': 4, 'weights': 'distance'},\n",
       " mean: 0.97199, std: 0.02297, params: {'algorithm': 'ball_tree', 'leaf_size': 1, 'n_jobs': -1, 'n_neighbors': 5, 'weights': 'uniform'},\n",
       " mean: 0.97619, std: 0.02112, params: {'algorithm': 'ball_tree', 'leaf_size': 1, 'n_jobs': -1, 'n_neighbors': 5, 'weights': 'distance'},\n",
       " mean: 0.97479, std: 0.01891, params: {'algorithm': 'ball_tree', 'leaf_size': 1, 'n_jobs': -1, 'n_neighbors': 6, 'weights': 'uniform'},\n",
       " mean: 0.97479, std: 0.02073, params: {'algorithm': 'ball_tree', 'leaf_size': 1, 'n_jobs': -1, 'n_neighbors': 6, 'weights': 'distance'},\n",
       " mean: 0.97339, std: 0.01965, params: {'algorithm': 'ball_tree', 'leaf_size': 1, 'n_jobs': -1, 'n_neighbors': 7, 'weights': 'uniform'},\n",
       " mean: 0.97619, std: 0.01802, params: {'algorithm': 'ball_tree', 'leaf_size': 1, 'n_jobs': -1, 'n_neighbors': 7, 'weights': 'distance'},\n",
       " mean: 0.97059, std: 0.01623, params: {'algorithm': 'ball_tree', 'leaf_size': 1, 'n_jobs': -1, 'n_neighbors': 8, 'weights': 'uniform'},\n",
       " mean: 0.97759, std: 0.01711, params: {'algorithm': 'ball_tree', 'leaf_size': 1, 'n_jobs': -1, 'n_neighbors': 8, 'weights': 'distance'},\n",
       " mean: 0.97199, std: 0.02015, params: {'algorithm': 'ball_tree', 'leaf_size': 1, 'n_jobs': -1, 'n_neighbors': 9, 'weights': 'uniform'},\n",
       " mean: 0.97759, std: 0.01575, params: {'algorithm': 'ball_tree', 'leaf_size': 1, 'n_jobs': -1, 'n_neighbors': 9, 'weights': 'distance'},\n",
       " mean: 0.97199, std: 0.02360, params: {'algorithm': 'ball_tree', 'leaf_size': 2, 'n_jobs': -1, 'n_neighbors': 3, 'weights': 'uniform'},\n",
       " mean: 0.97199, std: 0.02360, params: {'algorithm': 'ball_tree', 'leaf_size': 2, 'n_jobs': -1, 'n_neighbors': 3, 'weights': 'distance'},\n",
       " mean: 0.97059, std: 0.02050, params: {'algorithm': 'ball_tree', 'leaf_size': 2, 'n_jobs': -1, 'n_neighbors': 4, 'weights': 'uniform'},\n",
       " mean: 0.97339, std: 0.02219, params: {'algorithm': 'ball_tree', 'leaf_size': 2, 'n_jobs': -1, 'n_neighbors': 4, 'weights': 'distance'},\n",
       " mean: 0.97199, std: 0.02297, params: {'algorithm': 'ball_tree', 'leaf_size': 2, 'n_jobs': -1, 'n_neighbors': 5, 'weights': 'uniform'},\n",
       " mean: 0.97619, std: 0.02112, params: {'algorithm': 'ball_tree', 'leaf_size': 2, 'n_jobs': -1, 'n_neighbors': 5, 'weights': 'distance'},\n",
       " mean: 0.97479, std: 0.01891, params: {'algorithm': 'ball_tree', 'leaf_size': 2, 'n_jobs': -1, 'n_neighbors': 6, 'weights': 'uniform'},\n",
       " mean: 0.97479, std: 0.02073, params: {'algorithm': 'ball_tree', 'leaf_size': 2, 'n_jobs': -1, 'n_neighbors': 6, 'weights': 'distance'},\n",
       " mean: 0.97339, std: 0.01965, params: {'algorithm': 'ball_tree', 'leaf_size': 2, 'n_jobs': -1, 'n_neighbors': 7, 'weights': 'uniform'},\n",
       " mean: 0.97619, std: 0.01802, params: {'algorithm': 'ball_tree', 'leaf_size': 2, 'n_jobs': -1, 'n_neighbors': 7, 'weights': 'distance'},\n",
       " mean: 0.97059, std: 0.01623, params: {'algorithm': 'ball_tree', 'leaf_size': 2, 'n_jobs': -1, 'n_neighbors': 8, 'weights': 'uniform'},\n",
       " mean: 0.97759, std: 0.01711, params: {'algorithm': 'ball_tree', 'leaf_size': 2, 'n_jobs': -1, 'n_neighbors': 8, 'weights': 'distance'},\n",
       " mean: 0.97199, std: 0.02015, params: {'algorithm': 'ball_tree', 'leaf_size': 2, 'n_jobs': -1, 'n_neighbors': 9, 'weights': 'uniform'},\n",
       " mean: 0.97759, std: 0.01575, params: {'algorithm': 'ball_tree', 'leaf_size': 2, 'n_jobs': -1, 'n_neighbors': 9, 'weights': 'distance'},\n",
       " mean: 0.97199, std: 0.02360, params: {'algorithm': 'ball_tree', 'leaf_size': 3, 'n_jobs': -1, 'n_neighbors': 3, 'weights': 'uniform'},\n",
       " mean: 0.97199, std: 0.02360, params: {'algorithm': 'ball_tree', 'leaf_size': 3, 'n_jobs': -1, 'n_neighbors': 3, 'weights': 'distance'},\n",
       " mean: 0.97059, std: 0.02050, params: {'algorithm': 'ball_tree', 'leaf_size': 3, 'n_jobs': -1, 'n_neighbors': 4, 'weights': 'uniform'},\n",
       " mean: 0.97339, std: 0.02219, params: {'algorithm': 'ball_tree', 'leaf_size': 3, 'n_jobs': -1, 'n_neighbors': 4, 'weights': 'distance'},\n",
       " mean: 0.97199, std: 0.02297, params: {'algorithm': 'ball_tree', 'leaf_size': 3, 'n_jobs': -1, 'n_neighbors': 5, 'weights': 'uniform'},\n",
       " mean: 0.97619, std: 0.02112, params: {'algorithm': 'ball_tree', 'leaf_size': 3, 'n_jobs': -1, 'n_neighbors': 5, 'weights': 'distance'},\n",
       " mean: 0.97479, std: 0.01891, params: {'algorithm': 'ball_tree', 'leaf_size': 3, 'n_jobs': -1, 'n_neighbors': 6, 'weights': 'uniform'},\n",
       " mean: 0.97479, std: 0.02073, params: {'algorithm': 'ball_tree', 'leaf_size': 3, 'n_jobs': -1, 'n_neighbors': 6, 'weights': 'distance'},\n",
       " mean: 0.97339, std: 0.01965, params: {'algorithm': 'ball_tree', 'leaf_size': 3, 'n_jobs': -1, 'n_neighbors': 7, 'weights': 'uniform'},\n",
       " mean: 0.97619, std: 0.01802, params: {'algorithm': 'ball_tree', 'leaf_size': 3, 'n_jobs': -1, 'n_neighbors': 7, 'weights': 'distance'},\n",
       " mean: 0.97059, std: 0.01623, params: {'algorithm': 'ball_tree', 'leaf_size': 3, 'n_jobs': -1, 'n_neighbors': 8, 'weights': 'uniform'},\n",
       " mean: 0.97759, std: 0.01711, params: {'algorithm': 'ball_tree', 'leaf_size': 3, 'n_jobs': -1, 'n_neighbors': 8, 'weights': 'distance'},\n",
       " mean: 0.97199, std: 0.02015, params: {'algorithm': 'ball_tree', 'leaf_size': 3, 'n_jobs': -1, 'n_neighbors': 9, 'weights': 'uniform'},\n",
       " mean: 0.97759, std: 0.01575, params: {'algorithm': 'ball_tree', 'leaf_size': 3, 'n_jobs': -1, 'n_neighbors': 9, 'weights': 'distance'},\n",
       " mean: 0.97199, std: 0.02360, params: {'algorithm': 'ball_tree', 'leaf_size': 5, 'n_jobs': -1, 'n_neighbors': 3, 'weights': 'uniform'},\n",
       " mean: 0.97199, std: 0.02360, params: {'algorithm': 'ball_tree', 'leaf_size': 5, 'n_jobs': -1, 'n_neighbors': 3, 'weights': 'distance'},\n",
       " mean: 0.97059, std: 0.02050, params: {'algorithm': 'ball_tree', 'leaf_size': 5, 'n_jobs': -1, 'n_neighbors': 4, 'weights': 'uniform'},\n",
       " mean: 0.97339, std: 0.02219, params: {'algorithm': 'ball_tree', 'leaf_size': 5, 'n_jobs': -1, 'n_neighbors': 4, 'weights': 'distance'},\n",
       " mean: 0.97199, std: 0.02297, params: {'algorithm': 'ball_tree', 'leaf_size': 5, 'n_jobs': -1, 'n_neighbors': 5, 'weights': 'uniform'},\n",
       " mean: 0.97619, std: 0.02112, params: {'algorithm': 'ball_tree', 'leaf_size': 5, 'n_jobs': -1, 'n_neighbors': 5, 'weights': 'distance'},\n",
       " mean: 0.97479, std: 0.01891, params: {'algorithm': 'ball_tree', 'leaf_size': 5, 'n_jobs': -1, 'n_neighbors': 6, 'weights': 'uniform'},\n",
       " mean: 0.97479, std: 0.02073, params: {'algorithm': 'ball_tree', 'leaf_size': 5, 'n_jobs': -1, 'n_neighbors': 6, 'weights': 'distance'},\n",
       " mean: 0.97339, std: 0.01965, params: {'algorithm': 'ball_tree', 'leaf_size': 5, 'n_jobs': -1, 'n_neighbors': 7, 'weights': 'uniform'},\n",
       " mean: 0.97619, std: 0.01802, params: {'algorithm': 'ball_tree', 'leaf_size': 5, 'n_jobs': -1, 'n_neighbors': 7, 'weights': 'distance'},\n",
       " mean: 0.97059, std: 0.01623, params: {'algorithm': 'ball_tree', 'leaf_size': 5, 'n_jobs': -1, 'n_neighbors': 8, 'weights': 'uniform'},\n",
       " mean: 0.97759, std: 0.01711, params: {'algorithm': 'ball_tree', 'leaf_size': 5, 'n_jobs': -1, 'n_neighbors': 8, 'weights': 'distance'},\n",
       " mean: 0.97199, std: 0.02015, params: {'algorithm': 'ball_tree', 'leaf_size': 5, 'n_jobs': -1, 'n_neighbors': 9, 'weights': 'uniform'},\n",
       " mean: 0.97759, std: 0.01575, params: {'algorithm': 'ball_tree', 'leaf_size': 5, 'n_jobs': -1, 'n_neighbors': 9, 'weights': 'distance'},\n",
       " mean: 0.97199, std: 0.02360, params: {'algorithm': 'kd_tree', 'leaf_size': 1, 'n_jobs': -1, 'n_neighbors': 3, 'weights': 'uniform'},\n",
       " mean: 0.97199, std: 0.02360, params: {'algorithm': 'kd_tree', 'leaf_size': 1, 'n_jobs': -1, 'n_neighbors': 3, 'weights': 'distance'},\n",
       " mean: 0.97059, std: 0.02050, params: {'algorithm': 'kd_tree', 'leaf_size': 1, 'n_jobs': -1, 'n_neighbors': 4, 'weights': 'uniform'},\n",
       " mean: 0.97339, std: 0.02219, params: {'algorithm': 'kd_tree', 'leaf_size': 1, 'n_jobs': -1, 'n_neighbors': 4, 'weights': 'distance'},\n",
       " mean: 0.97199, std: 0.02297, params: {'algorithm': 'kd_tree', 'leaf_size': 1, 'n_jobs': -1, 'n_neighbors': 5, 'weights': 'uniform'},\n",
       " mean: 0.97619, std: 0.02112, params: {'algorithm': 'kd_tree', 'leaf_size': 1, 'n_jobs': -1, 'n_neighbors': 5, 'weights': 'distance'},\n",
       " mean: 0.97479, std: 0.01891, params: {'algorithm': 'kd_tree', 'leaf_size': 1, 'n_jobs': -1, 'n_neighbors': 6, 'weights': 'uniform'},\n",
       " mean: 0.97479, std: 0.02073, params: {'algorithm': 'kd_tree', 'leaf_size': 1, 'n_jobs': -1, 'n_neighbors': 6, 'weights': 'distance'},\n",
       " mean: 0.97339, std: 0.01965, params: {'algorithm': 'kd_tree', 'leaf_size': 1, 'n_jobs': -1, 'n_neighbors': 7, 'weights': 'uniform'},\n",
       " mean: 0.97619, std: 0.01802, params: {'algorithm': 'kd_tree', 'leaf_size': 1, 'n_jobs': -1, 'n_neighbors': 7, 'weights': 'distance'},\n",
       " mean: 0.97059, std: 0.01623, params: {'algorithm': 'kd_tree', 'leaf_size': 1, 'n_jobs': -1, 'n_neighbors': 8, 'weights': 'uniform'},\n",
       " mean: 0.97759, std: 0.01711, params: {'algorithm': 'kd_tree', 'leaf_size': 1, 'n_jobs': -1, 'n_neighbors': 8, 'weights': 'distance'},\n",
       " mean: 0.97199, std: 0.02015, params: {'algorithm': 'kd_tree', 'leaf_size': 1, 'n_jobs': -1, 'n_neighbors': 9, 'weights': 'uniform'},\n",
       " mean: 0.97759, std: 0.01575, params: {'algorithm': 'kd_tree', 'leaf_size': 1, 'n_jobs': -1, 'n_neighbors': 9, 'weights': 'distance'},\n",
       " mean: 0.97199, std: 0.02360, params: {'algorithm': 'kd_tree', 'leaf_size': 2, 'n_jobs': -1, 'n_neighbors': 3, 'weights': 'uniform'},\n",
       " mean: 0.97199, std: 0.02360, params: {'algorithm': 'kd_tree', 'leaf_size': 2, 'n_jobs': -1, 'n_neighbors': 3, 'weights': 'distance'},\n",
       " mean: 0.97059, std: 0.02050, params: {'algorithm': 'kd_tree', 'leaf_size': 2, 'n_jobs': -1, 'n_neighbors': 4, 'weights': 'uniform'},\n",
       " mean: 0.97339, std: 0.02219, params: {'algorithm': 'kd_tree', 'leaf_size': 2, 'n_jobs': -1, 'n_neighbors': 4, 'weights': 'distance'},\n",
       " mean: 0.97199, std: 0.02297, params: {'algorithm': 'kd_tree', 'leaf_size': 2, 'n_jobs': -1, 'n_neighbors': 5, 'weights': 'uniform'},\n",
       " mean: 0.97619, std: 0.02112, params: {'algorithm': 'kd_tree', 'leaf_size': 2, 'n_jobs': -1, 'n_neighbors': 5, 'weights': 'distance'},\n",
       " mean: 0.97479, std: 0.01891, params: {'algorithm': 'kd_tree', 'leaf_size': 2, 'n_jobs': -1, 'n_neighbors': 6, 'weights': 'uniform'},\n",
       " mean: 0.97479, std: 0.02073, params: {'algorithm': 'kd_tree', 'leaf_size': 2, 'n_jobs': -1, 'n_neighbors': 6, 'weights': 'distance'},\n",
       " mean: 0.97339, std: 0.01965, params: {'algorithm': 'kd_tree', 'leaf_size': 2, 'n_jobs': -1, 'n_neighbors': 7, 'weights': 'uniform'},\n",
       " mean: 0.97619, std: 0.01802, params: {'algorithm': 'kd_tree', 'leaf_size': 2, 'n_jobs': -1, 'n_neighbors': 7, 'weights': 'distance'},\n",
       " mean: 0.97059, std: 0.01623, params: {'algorithm': 'kd_tree', 'leaf_size': 2, 'n_jobs': -1, 'n_neighbors': 8, 'weights': 'uniform'},\n",
       " mean: 0.97759, std: 0.01711, params: {'algorithm': 'kd_tree', 'leaf_size': 2, 'n_jobs': -1, 'n_neighbors': 8, 'weights': 'distance'},\n",
       " mean: 0.97199, std: 0.02015, params: {'algorithm': 'kd_tree', 'leaf_size': 2, 'n_jobs': -1, 'n_neighbors': 9, 'weights': 'uniform'},\n",
       " mean: 0.97759, std: 0.01575, params: {'algorithm': 'kd_tree', 'leaf_size': 2, 'n_jobs': -1, 'n_neighbors': 9, 'weights': 'distance'},\n",
       " mean: 0.97199, std: 0.02360, params: {'algorithm': 'kd_tree', 'leaf_size': 3, 'n_jobs': -1, 'n_neighbors': 3, 'weights': 'uniform'},\n",
       " mean: 0.97199, std: 0.02360, params: {'algorithm': 'kd_tree', 'leaf_size': 3, 'n_jobs': -1, 'n_neighbors': 3, 'weights': 'distance'},\n",
       " mean: 0.97059, std: 0.02050, params: {'algorithm': 'kd_tree', 'leaf_size': 3, 'n_jobs': -1, 'n_neighbors': 4, 'weights': 'uniform'},\n",
       " mean: 0.97339, std: 0.02219, params: {'algorithm': 'kd_tree', 'leaf_size': 3, 'n_jobs': -1, 'n_neighbors': 4, 'weights': 'distance'},\n",
       " mean: 0.97199, std: 0.02297, params: {'algorithm': 'kd_tree', 'leaf_size': 3, 'n_jobs': -1, 'n_neighbors': 5, 'weights': 'uniform'},\n",
       " mean: 0.97619, std: 0.02112, params: {'algorithm': 'kd_tree', 'leaf_size': 3, 'n_jobs': -1, 'n_neighbors': 5, 'weights': 'distance'},\n",
       " mean: 0.97479, std: 0.01891, params: {'algorithm': 'kd_tree', 'leaf_size': 3, 'n_jobs': -1, 'n_neighbors': 6, 'weights': 'uniform'},\n",
       " mean: 0.97479, std: 0.02073, params: {'algorithm': 'kd_tree', 'leaf_size': 3, 'n_jobs': -1, 'n_neighbors': 6, 'weights': 'distance'},\n",
       " mean: 0.97339, std: 0.01965, params: {'algorithm': 'kd_tree', 'leaf_size': 3, 'n_jobs': -1, 'n_neighbors': 7, 'weights': 'uniform'},\n",
       " mean: 0.97619, std: 0.01802, params: {'algorithm': 'kd_tree', 'leaf_size': 3, 'n_jobs': -1, 'n_neighbors': 7, 'weights': 'distance'},\n",
       " mean: 0.97059, std: 0.01623, params: {'algorithm': 'kd_tree', 'leaf_size': 3, 'n_jobs': -1, 'n_neighbors': 8, 'weights': 'uniform'},\n",
       " mean: 0.97759, std: 0.01711, params: {'algorithm': 'kd_tree', 'leaf_size': 3, 'n_jobs': -1, 'n_neighbors': 8, 'weights': 'distance'},\n",
       " mean: 0.97199, std: 0.02015, params: {'algorithm': 'kd_tree', 'leaf_size': 3, 'n_jobs': -1, 'n_neighbors': 9, 'weights': 'uniform'},\n",
       " mean: 0.97759, std: 0.01575, params: {'algorithm': 'kd_tree', 'leaf_size': 3, 'n_jobs': -1, 'n_neighbors': 9, 'weights': 'distance'},\n",
       " mean: 0.97199, std: 0.02360, params: {'algorithm': 'kd_tree', 'leaf_size': 5, 'n_jobs': -1, 'n_neighbors': 3, 'weights': 'uniform'},\n",
       " mean: 0.97199, std: 0.02360, params: {'algorithm': 'kd_tree', 'leaf_size': 5, 'n_jobs': -1, 'n_neighbors': 3, 'weights': 'distance'},\n",
       " mean: 0.97059, std: 0.02050, params: {'algorithm': 'kd_tree', 'leaf_size': 5, 'n_jobs': -1, 'n_neighbors': 4, 'weights': 'uniform'},\n",
       " mean: 0.97339, std: 0.02219, params: {'algorithm': 'kd_tree', 'leaf_size': 5, 'n_jobs': -1, 'n_neighbors': 4, 'weights': 'distance'},\n",
       " mean: 0.97199, std: 0.02297, params: {'algorithm': 'kd_tree', 'leaf_size': 5, 'n_jobs': -1, 'n_neighbors': 5, 'weights': 'uniform'},\n",
       " mean: 0.97619, std: 0.02112, params: {'algorithm': 'kd_tree', 'leaf_size': 5, 'n_jobs': -1, 'n_neighbors': 5, 'weights': 'distance'},\n",
       " mean: 0.97479, std: 0.01891, params: {'algorithm': 'kd_tree', 'leaf_size': 5, 'n_jobs': -1, 'n_neighbors': 6, 'weights': 'uniform'},\n",
       " mean: 0.97479, std: 0.02073, params: {'algorithm': 'kd_tree', 'leaf_size': 5, 'n_jobs': -1, 'n_neighbors': 6, 'weights': 'distance'},\n",
       " mean: 0.97339, std: 0.01965, params: {'algorithm': 'kd_tree', 'leaf_size': 5, 'n_jobs': -1, 'n_neighbors': 7, 'weights': 'uniform'},\n",
       " mean: 0.97619, std: 0.01802, params: {'algorithm': 'kd_tree', 'leaf_size': 5, 'n_jobs': -1, 'n_neighbors': 7, 'weights': 'distance'},\n",
       " mean: 0.97059, std: 0.01623, params: {'algorithm': 'kd_tree', 'leaf_size': 5, 'n_jobs': -1, 'n_neighbors': 8, 'weights': 'uniform'},\n",
       " mean: 0.97759, std: 0.01711, params: {'algorithm': 'kd_tree', 'leaf_size': 5, 'n_jobs': -1, 'n_neighbors': 8, 'weights': 'distance'},\n",
       " mean: 0.97199, std: 0.02015, params: {'algorithm': 'kd_tree', 'leaf_size': 5, 'n_jobs': -1, 'n_neighbors': 9, 'weights': 'uniform'},\n",
       " mean: 0.97759, std: 0.01575, params: {'algorithm': 'kd_tree', 'leaf_size': 5, 'n_jobs': -1, 'n_neighbors': 9, 'weights': 'distance'},\n",
       " mean: 0.97199, std: 0.02360, params: {'algorithm': 'brute', 'leaf_size': 1, 'n_jobs': -1, 'n_neighbors': 3, 'weights': 'uniform'},\n",
       " mean: 0.97199, std: 0.02360, params: {'algorithm': 'brute', 'leaf_size': 1, 'n_jobs': -1, 'n_neighbors': 3, 'weights': 'distance'},\n",
       " mean: 0.97059, std: 0.02050, params: {'algorithm': 'brute', 'leaf_size': 1, 'n_jobs': -1, 'n_neighbors': 4, 'weights': 'uniform'},\n",
       " mean: 0.97339, std: 0.02219, params: {'algorithm': 'brute', 'leaf_size': 1, 'n_jobs': -1, 'n_neighbors': 4, 'weights': 'distance'},\n",
       " mean: 0.97199, std: 0.02297, params: {'algorithm': 'brute', 'leaf_size': 1, 'n_jobs': -1, 'n_neighbors': 5, 'weights': 'uniform'},\n",
       " mean: 0.97619, std: 0.02112, params: {'algorithm': 'brute', 'leaf_size': 1, 'n_jobs': -1, 'n_neighbors': 5, 'weights': 'distance'},\n",
       " mean: 0.97479, std: 0.01891, params: {'algorithm': 'brute', 'leaf_size': 1, 'n_jobs': -1, 'n_neighbors': 6, 'weights': 'uniform'},\n",
       " mean: 0.97479, std: 0.02073, params: {'algorithm': 'brute', 'leaf_size': 1, 'n_jobs': -1, 'n_neighbors': 6, 'weights': 'distance'},\n",
       " mean: 0.97339, std: 0.01965, params: {'algorithm': 'brute', 'leaf_size': 1, 'n_jobs': -1, 'n_neighbors': 7, 'weights': 'uniform'},\n",
       " mean: 0.97619, std: 0.01802, params: {'algorithm': 'brute', 'leaf_size': 1, 'n_jobs': -1, 'n_neighbors': 7, 'weights': 'distance'},\n",
       " mean: 0.97059, std: 0.01623, params: {'algorithm': 'brute', 'leaf_size': 1, 'n_jobs': -1, 'n_neighbors': 8, 'weights': 'uniform'},\n",
       " mean: 0.97759, std: 0.01711, params: {'algorithm': 'brute', 'leaf_size': 1, 'n_jobs': -1, 'n_neighbors': 8, 'weights': 'distance'},\n",
       " mean: 0.97199, std: 0.02015, params: {'algorithm': 'brute', 'leaf_size': 1, 'n_jobs': -1, 'n_neighbors': 9, 'weights': 'uniform'},\n",
       " mean: 0.97759, std: 0.01575, params: {'algorithm': 'brute', 'leaf_size': 1, 'n_jobs': -1, 'n_neighbors': 9, 'weights': 'distance'},\n",
       " mean: 0.97199, std: 0.02360, params: {'algorithm': 'brute', 'leaf_size': 2, 'n_jobs': -1, 'n_neighbors': 3, 'weights': 'uniform'},\n",
       " mean: 0.97199, std: 0.02360, params: {'algorithm': 'brute', 'leaf_size': 2, 'n_jobs': -1, 'n_neighbors': 3, 'weights': 'distance'},\n",
       " mean: 0.97059, std: 0.02050, params: {'algorithm': 'brute', 'leaf_size': 2, 'n_jobs': -1, 'n_neighbors': 4, 'weights': 'uniform'},\n",
       " mean: 0.97339, std: 0.02219, params: {'algorithm': 'brute', 'leaf_size': 2, 'n_jobs': -1, 'n_neighbors': 4, 'weights': 'distance'},\n",
       " mean: 0.97199, std: 0.02297, params: {'algorithm': 'brute', 'leaf_size': 2, 'n_jobs': -1, 'n_neighbors': 5, 'weights': 'uniform'},\n",
       " mean: 0.97619, std: 0.02112, params: {'algorithm': 'brute', 'leaf_size': 2, 'n_jobs': -1, 'n_neighbors': 5, 'weights': 'distance'},\n",
       " mean: 0.97479, std: 0.01891, params: {'algorithm': 'brute', 'leaf_size': 2, 'n_jobs': -1, 'n_neighbors': 6, 'weights': 'uniform'},\n",
       " mean: 0.97479, std: 0.02073, params: {'algorithm': 'brute', 'leaf_size': 2, 'n_jobs': -1, 'n_neighbors': 6, 'weights': 'distance'},\n",
       " mean: 0.97339, std: 0.01965, params: {'algorithm': 'brute', 'leaf_size': 2, 'n_jobs': -1, 'n_neighbors': 7, 'weights': 'uniform'},\n",
       " mean: 0.97619, std: 0.01802, params: {'algorithm': 'brute', 'leaf_size': 2, 'n_jobs': -1, 'n_neighbors': 7, 'weights': 'distance'},\n",
       " mean: 0.97059, std: 0.01623, params: {'algorithm': 'brute', 'leaf_size': 2, 'n_jobs': -1, 'n_neighbors': 8, 'weights': 'uniform'},\n",
       " mean: 0.97759, std: 0.01711, params: {'algorithm': 'brute', 'leaf_size': 2, 'n_jobs': -1, 'n_neighbors': 8, 'weights': 'distance'},\n",
       " mean: 0.97199, std: 0.02015, params: {'algorithm': 'brute', 'leaf_size': 2, 'n_jobs': -1, 'n_neighbors': 9, 'weights': 'uniform'},\n",
       " mean: 0.97759, std: 0.01575, params: {'algorithm': 'brute', 'leaf_size': 2, 'n_jobs': -1, 'n_neighbors': 9, 'weights': 'distance'},\n",
       " mean: 0.97199, std: 0.02360, params: {'algorithm': 'brute', 'leaf_size': 3, 'n_jobs': -1, 'n_neighbors': 3, 'weights': 'uniform'},\n",
       " mean: 0.97199, std: 0.02360, params: {'algorithm': 'brute', 'leaf_size': 3, 'n_jobs': -1, 'n_neighbors': 3, 'weights': 'distance'},\n",
       " mean: 0.97059, std: 0.02050, params: {'algorithm': 'brute', 'leaf_size': 3, 'n_jobs': -1, 'n_neighbors': 4, 'weights': 'uniform'},\n",
       " mean: 0.97339, std: 0.02219, params: {'algorithm': 'brute', 'leaf_size': 3, 'n_jobs': -1, 'n_neighbors': 4, 'weights': 'distance'},\n",
       " mean: 0.97199, std: 0.02297, params: {'algorithm': 'brute', 'leaf_size': 3, 'n_jobs': -1, 'n_neighbors': 5, 'weights': 'uniform'},\n",
       " mean: 0.97619, std: 0.02112, params: {'algorithm': 'brute', 'leaf_size': 3, 'n_jobs': -1, 'n_neighbors': 5, 'weights': 'distance'},\n",
       " mean: 0.97479, std: 0.01891, params: {'algorithm': 'brute', 'leaf_size': 3, 'n_jobs': -1, 'n_neighbors': 6, 'weights': 'uniform'},\n",
       " mean: 0.97479, std: 0.02073, params: {'algorithm': 'brute', 'leaf_size': 3, 'n_jobs': -1, 'n_neighbors': 6, 'weights': 'distance'},\n",
       " mean: 0.97339, std: 0.01965, params: {'algorithm': 'brute', 'leaf_size': 3, 'n_jobs': -1, 'n_neighbors': 7, 'weights': 'uniform'},\n",
       " mean: 0.97619, std: 0.01802, params: {'algorithm': 'brute', 'leaf_size': 3, 'n_jobs': -1, 'n_neighbors': 7, 'weights': 'distance'},\n",
       " mean: 0.97059, std: 0.01623, params: {'algorithm': 'brute', 'leaf_size': 3, 'n_jobs': -1, 'n_neighbors': 8, 'weights': 'uniform'},\n",
       " mean: 0.97759, std: 0.01711, params: {'algorithm': 'brute', 'leaf_size': 3, 'n_jobs': -1, 'n_neighbors': 8, 'weights': 'distance'},\n",
       " mean: 0.97199, std: 0.02015, params: {'algorithm': 'brute', 'leaf_size': 3, 'n_jobs': -1, 'n_neighbors': 9, 'weights': 'uniform'},\n",
       " mean: 0.97759, std: 0.01575, params: {'algorithm': 'brute', 'leaf_size': 3, 'n_jobs': -1, 'n_neighbors': 9, 'weights': 'distance'},\n",
       " mean: 0.97199, std: 0.02360, params: {'algorithm': 'brute', 'leaf_size': 5, 'n_jobs': -1, 'n_neighbors': 3, 'weights': 'uniform'},\n",
       " mean: 0.97199, std: 0.02360, params: {'algorithm': 'brute', 'leaf_size': 5, 'n_jobs': -1, 'n_neighbors': 3, 'weights': 'distance'},\n",
       " mean: 0.97059, std: 0.02050, params: {'algorithm': 'brute', 'leaf_size': 5, 'n_jobs': -1, 'n_neighbors': 4, 'weights': 'uniform'},\n",
       " mean: 0.97339, std: 0.02219, params: {'algorithm': 'brute', 'leaf_size': 5, 'n_jobs': -1, 'n_neighbors': 4, 'weights': 'distance'},\n",
       " mean: 0.97199, std: 0.02297, params: {'algorithm': 'brute', 'leaf_size': 5, 'n_jobs': -1, 'n_neighbors': 5, 'weights': 'uniform'},\n",
       " mean: 0.97619, std: 0.02112, params: {'algorithm': 'brute', 'leaf_size': 5, 'n_jobs': -1, 'n_neighbors': 5, 'weights': 'distance'},\n",
       " mean: 0.97479, std: 0.01891, params: {'algorithm': 'brute', 'leaf_size': 5, 'n_jobs': -1, 'n_neighbors': 6, 'weights': 'uniform'},\n",
       " mean: 0.97479, std: 0.02073, params: {'algorithm': 'brute', 'leaf_size': 5, 'n_jobs': -1, 'n_neighbors': 6, 'weights': 'distance'},\n",
       " mean: 0.97339, std: 0.01965, params: {'algorithm': 'brute', 'leaf_size': 5, 'n_jobs': -1, 'n_neighbors': 7, 'weights': 'uniform'},\n",
       " mean: 0.97619, std: 0.01802, params: {'algorithm': 'brute', 'leaf_size': 5, 'n_jobs': -1, 'n_neighbors': 7, 'weights': 'distance'},\n",
       " mean: 0.97059, std: 0.01623, params: {'algorithm': 'brute', 'leaf_size': 5, 'n_jobs': -1, 'n_neighbors': 8, 'weights': 'uniform'},\n",
       " mean: 0.97759, std: 0.01711, params: {'algorithm': 'brute', 'leaf_size': 5, 'n_jobs': -1, 'n_neighbors': 8, 'weights': 'distance'},\n",
       " mean: 0.97199, std: 0.02015, params: {'algorithm': 'brute', 'leaf_size': 5, 'n_jobs': -1, 'n_neighbors': 9, 'weights': 'uniform'},\n",
       " mean: 0.97759, std: 0.01575, params: {'algorithm': 'brute', 'leaf_size': 5, 'n_jobs': -1, 'n_neighbors': 9, 'weights': 'distance'}]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyper Parameters: {'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'random_state': 123}\n",
      "Training Accuracy: 1.0000\n",
      "Testing Accuracy: {:.4f} 1.0\n",
      "Confusion Metrix:\n",
      " [[357   0]\n",
      " [  0 357]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       1.00      1.00      1.00       357\n",
      "          0       1.00      1.00      1.00       357\n",
      "\n",
      "avg / total       1.00      1.00      1.00       714\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "#importing modules\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from scipy.stats import randint \n",
    "#making the instance\n",
    "model= DecisionTreeClassifier(random_state=123)\n",
    "#Hyper Parameters Set\n",
    "params = {'max_features': ['auto', 'sqrt', 'log2'],\n",
    "          'min_samples_split': [2,3,4,5,6,7,8,9,10] , \n",
    "          'min_samples_leaf':[1,2,3,4,5],\n",
    "          'random_state':[123]}\n",
    "#Making models with hyper parameters sets\n",
    "model3 = GridSearchCV(model, param_grid=params, cv=10, scoring=\"accuracy\", n_jobs=-1)\n",
    "#Learning\n",
    "model3.fit(x_train,y_train)\n",
    "#The best hyper parameters set\n",
    "print(\"Best Hyper Parameters:\",model3.best_params_)\n",
    "#Prediction\n",
    "prediction=model3.predict(x_test)\n",
    "#importing the metrics module\n",
    "from sklearn import metrics\n",
    "#evaluation(Train Score)\n",
    "train_score=model3.score(x_train,y_train)\n",
    "print('Training Accuracy: {:.4f}'.format(train_score))\n",
    "#evaluation(Accuracy)\n",
    "print(\"Testing Accuracy: {:.4f}\",metrics.accuracy_score(prediction,y_test))\n",
    "#evaluation(Confusion Metrix)\n",
    "print(\"Confusion Metrix:\\n\",metrics.confusion_matrix(prediction,y_test))\n",
    "#evaluation(Classification_report)\n",
    "print(\"Classification Report:\\n\",metrics.classification_report(y_test, prediction, labels=[1,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sathish kumar\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[mean: 0.96779, std: 0.01810, params: {'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'random_state': 123},\n",
       " mean: 0.96639, std: 0.01714, params: {'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 3, 'random_state': 123},\n",
       " mean: 0.96359, std: 0.01838, params: {'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 4, 'random_state': 123},\n",
       " mean: 0.96078, std: 0.02004, params: {'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 5, 'random_state': 123},\n",
       " mean: 0.95658, std: 0.02071, params: {'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 6, 'random_state': 123},\n",
       " mean: 0.95798, std: 0.01935, params: {'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 7, 'random_state': 123},\n",
       " mean: 0.96218, std: 0.01934, params: {'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 8, 'random_state': 123},\n",
       " mean: 0.95938, std: 0.02153, params: {'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 9, 'random_state': 123},\n",
       " mean: 0.95238, std: 0.02749, params: {'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 10, 'random_state': 123},\n",
       " mean: 0.95938, std: 0.01610, params: {'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 2, 'random_state': 123},\n",
       " mean: 0.95938, std: 0.01610, params: {'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 3, 'random_state': 123},\n",
       " mean: 0.95938, std: 0.01610, params: {'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 4, 'random_state': 123},\n",
       " mean: 0.95938, std: 0.02073, params: {'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 5, 'random_state': 123},\n",
       " mean: 0.95098, std: 0.02353, params: {'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 6, 'random_state': 123},\n",
       " mean: 0.94678, std: 0.02129, params: {'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 7, 'random_state': 123},\n",
       " mean: 0.95238, std: 0.01826, params: {'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 8, 'random_state': 123},\n",
       " mean: 0.95098, std: 0.01930, params: {'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 9, 'random_state': 123},\n",
       " mean: 0.94678, std: 0.02568, params: {'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 10, 'random_state': 123},\n",
       " mean: 0.95238, std: 0.02250, params: {'max_features': 'auto', 'min_samples_leaf': 3, 'min_samples_split': 2, 'random_state': 123},\n",
       " mean: 0.95238, std: 0.02250, params: {'max_features': 'auto', 'min_samples_leaf': 3, 'min_samples_split': 3, 'random_state': 123},\n",
       " mean: 0.95238, std: 0.02250, params: {'max_features': 'auto', 'min_samples_leaf': 3, 'min_samples_split': 4, 'random_state': 123},\n",
       " mean: 0.95238, std: 0.02250, params: {'max_features': 'auto', 'min_samples_leaf': 3, 'min_samples_split': 5, 'random_state': 123},\n",
       " mean: 0.95238, std: 0.02250, params: {'max_features': 'auto', 'min_samples_leaf': 3, 'min_samples_split': 6, 'random_state': 123},\n",
       " mean: 0.95238, std: 0.02645, params: {'max_features': 'auto', 'min_samples_leaf': 3, 'min_samples_split': 7, 'random_state': 123},\n",
       " mean: 0.95518, std: 0.02165, params: {'max_features': 'auto', 'min_samples_leaf': 3, 'min_samples_split': 8, 'random_state': 123},\n",
       " mean: 0.95518, std: 0.02165, params: {'max_features': 'auto', 'min_samples_leaf': 3, 'min_samples_split': 9, 'random_state': 123},\n",
       " mean: 0.95518, std: 0.02856, params: {'max_features': 'auto', 'min_samples_leaf': 3, 'min_samples_split': 10, 'random_state': 123},\n",
       " mean: 0.94258, std: 0.01907, params: {'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 2, 'random_state': 123},\n",
       " mean: 0.94258, std: 0.01907, params: {'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 3, 'random_state': 123},\n",
       " mean: 0.94258, std: 0.01907, params: {'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 4, 'random_state': 123},\n",
       " mean: 0.94258, std: 0.01907, params: {'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 5, 'random_state': 123},\n",
       " mean: 0.94258, std: 0.01907, params: {'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 6, 'random_state': 123},\n",
       " mean: 0.94258, std: 0.01907, params: {'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 7, 'random_state': 123},\n",
       " mean: 0.94258, std: 0.01907, params: {'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 8, 'random_state': 123},\n",
       " mean: 0.94538, std: 0.01701, params: {'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 9, 'random_state': 123},\n",
       " mean: 0.95098, std: 0.01308, params: {'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 10, 'random_state': 123},\n",
       " mean: 0.94258, std: 0.01998, params: {'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 2, 'random_state': 123},\n",
       " mean: 0.94258, std: 0.01998, params: {'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 3, 'random_state': 123},\n",
       " mean: 0.94258, std: 0.01998, params: {'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 4, 'random_state': 123},\n",
       " mean: 0.94258, std: 0.01998, params: {'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 5, 'random_state': 123},\n",
       " mean: 0.94258, std: 0.01998, params: {'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 6, 'random_state': 123},\n",
       " mean: 0.94258, std: 0.01998, params: {'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 7, 'random_state': 123},\n",
       " mean: 0.94258, std: 0.01998, params: {'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 8, 'random_state': 123},\n",
       " mean: 0.94258, std: 0.01998, params: {'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 9, 'random_state': 123},\n",
       " mean: 0.94258, std: 0.01998, params: {'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 10, 'random_state': 123},\n",
       " mean: 0.96779, std: 0.01810, params: {'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'random_state': 123},\n",
       " mean: 0.96639, std: 0.01714, params: {'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 3, 'random_state': 123},\n",
       " mean: 0.96359, std: 0.01838, params: {'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 4, 'random_state': 123},\n",
       " mean: 0.96078, std: 0.02004, params: {'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'random_state': 123},\n",
       " mean: 0.95658, std: 0.02071, params: {'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 6, 'random_state': 123},\n",
       " mean: 0.95798, std: 0.01935, params: {'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 7, 'random_state': 123},\n",
       " mean: 0.96218, std: 0.01934, params: {'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 8, 'random_state': 123},\n",
       " mean: 0.95938, std: 0.02153, params: {'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 9, 'random_state': 123},\n",
       " mean: 0.95238, std: 0.02749, params: {'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 10, 'random_state': 123},\n",
       " mean: 0.95938, std: 0.01610, params: {'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 2, 'random_state': 123},\n",
       " mean: 0.95938, std: 0.01610, params: {'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 3, 'random_state': 123},\n",
       " mean: 0.95938, std: 0.01610, params: {'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 4, 'random_state': 123},\n",
       " mean: 0.95938, std: 0.02073, params: {'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 5, 'random_state': 123},\n",
       " mean: 0.95098, std: 0.02353, params: {'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 6, 'random_state': 123},\n",
       " mean: 0.94678, std: 0.02129, params: {'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 7, 'random_state': 123},\n",
       " mean: 0.95238, std: 0.01826, params: {'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 8, 'random_state': 123},\n",
       " mean: 0.95098, std: 0.01930, params: {'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 9, 'random_state': 123},\n",
       " mean: 0.94678, std: 0.02568, params: {'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 10, 'random_state': 123},\n",
       " mean: 0.95238, std: 0.02250, params: {'max_features': 'sqrt', 'min_samples_leaf': 3, 'min_samples_split': 2, 'random_state': 123},\n",
       " mean: 0.95238, std: 0.02250, params: {'max_features': 'sqrt', 'min_samples_leaf': 3, 'min_samples_split': 3, 'random_state': 123},\n",
       " mean: 0.95238, std: 0.02250, params: {'max_features': 'sqrt', 'min_samples_leaf': 3, 'min_samples_split': 4, 'random_state': 123},\n",
       " mean: 0.95238, std: 0.02250, params: {'max_features': 'sqrt', 'min_samples_leaf': 3, 'min_samples_split': 5, 'random_state': 123},\n",
       " mean: 0.95238, std: 0.02250, params: {'max_features': 'sqrt', 'min_samples_leaf': 3, 'min_samples_split': 6, 'random_state': 123},\n",
       " mean: 0.95238, std: 0.02645, params: {'max_features': 'sqrt', 'min_samples_leaf': 3, 'min_samples_split': 7, 'random_state': 123},\n",
       " mean: 0.95518, std: 0.02165, params: {'max_features': 'sqrt', 'min_samples_leaf': 3, 'min_samples_split': 8, 'random_state': 123},\n",
       " mean: 0.95518, std: 0.02165, params: {'max_features': 'sqrt', 'min_samples_leaf': 3, 'min_samples_split': 9, 'random_state': 123},\n",
       " mean: 0.95518, std: 0.02856, params: {'max_features': 'sqrt', 'min_samples_leaf': 3, 'min_samples_split': 10, 'random_state': 123},\n",
       " mean: 0.94258, std: 0.01907, params: {'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 2, 'random_state': 123},\n",
       " mean: 0.94258, std: 0.01907, params: {'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 3, 'random_state': 123},\n",
       " mean: 0.94258, std: 0.01907, params: {'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 4, 'random_state': 123},\n",
       " mean: 0.94258, std: 0.01907, params: {'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 5, 'random_state': 123},\n",
       " mean: 0.94258, std: 0.01907, params: {'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 6, 'random_state': 123},\n",
       " mean: 0.94258, std: 0.01907, params: {'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 7, 'random_state': 123},\n",
       " mean: 0.94258, std: 0.01907, params: {'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 8, 'random_state': 123},\n",
       " mean: 0.94538, std: 0.01701, params: {'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 9, 'random_state': 123},\n",
       " mean: 0.95098, std: 0.01308, params: {'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 10, 'random_state': 123},\n",
       " mean: 0.94258, std: 0.01998, params: {'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 2, 'random_state': 123},\n",
       " mean: 0.94258, std: 0.01998, params: {'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 3, 'random_state': 123},\n",
       " mean: 0.94258, std: 0.01998, params: {'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 4, 'random_state': 123},\n",
       " mean: 0.94258, std: 0.01998, params: {'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 5, 'random_state': 123},\n",
       " mean: 0.94258, std: 0.01998, params: {'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 6, 'random_state': 123},\n",
       " mean: 0.94258, std: 0.01998, params: {'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 7, 'random_state': 123},\n",
       " mean: 0.94258, std: 0.01998, params: {'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 8, 'random_state': 123},\n",
       " mean: 0.94258, std: 0.01998, params: {'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 9, 'random_state': 123},\n",
       " mean: 0.94258, std: 0.01998, params: {'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 10, 'random_state': 123},\n",
       " mean: 0.96359, std: 0.02837, params: {'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'random_state': 123},\n",
       " mean: 0.95798, std: 0.02285, params: {'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 3, 'random_state': 123},\n",
       " mean: 0.96499, std: 0.01410, params: {'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 4, 'random_state': 123},\n",
       " mean: 0.95798, std: 0.01077, params: {'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 5, 'random_state': 123},\n",
       " mean: 0.95238, std: 0.00945, params: {'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 6, 'random_state': 123},\n",
       " mean: 0.95378, std: 0.02130, params: {'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 7, 'random_state': 123},\n",
       " mean: 0.95238, std: 0.02479, params: {'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 8, 'random_state': 123},\n",
       " mean: 0.95098, std: 0.02405, params: {'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 9, 'random_state': 123},\n",
       " mean: 0.95238, std: 0.02124, params: {'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 10, 'random_state': 123},\n",
       " mean: 0.96779, std: 0.01755, params: {'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 2, 'random_state': 123},\n",
       " mean: 0.96779, std: 0.01755, params: {'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 3, 'random_state': 123},\n",
       " mean: 0.96779, std: 0.01755, params: {'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 4, 'random_state': 123},\n",
       " mean: 0.96218, std: 0.01643, params: {'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 5, 'random_state': 123},\n",
       " mean: 0.95658, std: 0.01706, params: {'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 6, 'random_state': 123},\n",
       " mean: 0.94678, std: 0.02099, params: {'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 7, 'random_state': 123},\n",
       " mean: 0.94818, std: 0.02462, params: {'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 8, 'random_state': 123},\n",
       " mean: 0.94818, std: 0.02462, params: {'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 9, 'random_state': 123},\n",
       " mean: 0.94958, std: 0.02207, params: {'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 10, 'random_state': 123},\n",
       " mean: 0.95378, std: 0.01918, params: {'max_features': 'log2', 'min_samples_leaf': 3, 'min_samples_split': 2, 'random_state': 123},\n",
       " mean: 0.95378, std: 0.01918, params: {'max_features': 'log2', 'min_samples_leaf': 3, 'min_samples_split': 3, 'random_state': 123},\n",
       " mean: 0.95378, std: 0.01918, params: {'max_features': 'log2', 'min_samples_leaf': 3, 'min_samples_split': 4, 'random_state': 123},\n",
       " mean: 0.95378, std: 0.01918, params: {'max_features': 'log2', 'min_samples_leaf': 3, 'min_samples_split': 5, 'random_state': 123},\n",
       " mean: 0.95378, std: 0.01918, params: {'max_features': 'log2', 'min_samples_leaf': 3, 'min_samples_split': 6, 'random_state': 123},\n",
       " mean: 0.94538, std: 0.02732, params: {'max_features': 'log2', 'min_samples_leaf': 3, 'min_samples_split': 7, 'random_state': 123},\n",
       " mean: 0.94678, std: 0.02544, params: {'max_features': 'log2', 'min_samples_leaf': 3, 'min_samples_split': 8, 'random_state': 123},\n",
       " mean: 0.94678, std: 0.02544, params: {'max_features': 'log2', 'min_samples_leaf': 3, 'min_samples_split': 9, 'random_state': 123},\n",
       " mean: 0.94818, std: 0.02308, params: {'max_features': 'log2', 'min_samples_leaf': 3, 'min_samples_split': 10, 'random_state': 123},\n",
       " mean: 0.94678, std: 0.01879, params: {'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 2, 'random_state': 123},\n",
       " mean: 0.94678, std: 0.01879, params: {'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 3, 'random_state': 123},\n",
       " mean: 0.94678, std: 0.01879, params: {'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 4, 'random_state': 123},\n",
       " mean: 0.94678, std: 0.01879, params: {'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 5, 'random_state': 123},\n",
       " mean: 0.94678, std: 0.01879, params: {'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 6, 'random_state': 123},\n",
       " mean: 0.94678, std: 0.01879, params: {'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 7, 'random_state': 123},\n",
       " mean: 0.94678, std: 0.01879, params: {'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 8, 'random_state': 123},\n",
       " mean: 0.94538, std: 0.01848, params: {'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 9, 'random_state': 123},\n",
       " mean: 0.94538, std: 0.01848, params: {'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 10, 'random_state': 123},\n",
       " mean: 0.94398, std: 0.02552, params: {'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 2, 'random_state': 123},\n",
       " mean: 0.94398, std: 0.02552, params: {'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 3, 'random_state': 123},\n",
       " mean: 0.94398, std: 0.02552, params: {'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 4, 'random_state': 123},\n",
       " mean: 0.94398, std: 0.02552, params: {'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 5, 'random_state': 123},\n",
       " mean: 0.94398, std: 0.02552, params: {'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 6, 'random_state': 123},\n",
       " mean: 0.94398, std: 0.02552, params: {'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 7, 'random_state': 123},\n",
       " mean: 0.94398, std: 0.02552, params: {'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 8, 'random_state': 123},\n",
       " mean: 0.94398, std: 0.02552, params: {'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 9, 'random_state': 123},\n",
       " mean: 0.94398, std: 0.02552, params: {'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 10, 'random_state': 123}]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyper Parameters: {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 15, 'n_jobs': -1}\n",
      "Training Accuracy: 1.0000\n",
      "Testing Accuracy: {:.4f} 1.0\n",
      "Confusion Metrix:\n",
      " [[357   0]\n",
      " [  0 357]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       1.00      1.00      1.00       357\n",
      "          0       1.00      1.00      1.00       357\n",
      "\n",
      "avg / total       1.00      1.00      1.00       714\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Randomforest\n",
    "#importing modules\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#making the instance\n",
    "model=RandomForestClassifier(random_state = 123)\n",
    "#hyper parameters set\n",
    "params = {'criterion':['gini','entropy'],\n",
    "          'n_estimators':[10,15,20,25,30],\n",
    "          'min_samples_leaf':[1,2,3,4,5],\n",
    "          'min_samples_split':[2,3,4,5,6], \n",
    "          'n_jobs':[-1]}\n",
    "#Making models with hyper parameters sets\n",
    "model4 = GridSearchCV(model, param_grid=params, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
    "#Learning\n",
    "model4.fit(x_train,y_train)\n",
    "#The best hyper parameters set\n",
    "print(\"Best Hyper Parameters:\",model4.best_params_)\n",
    "#Prediction\n",
    "prediction=model4.predict(x_test)\n",
    "#importing the metrics module\n",
    "from sklearn import metrics\n",
    "#evaluation(Train Score)\n",
    "train_score=model4.score(x_train,y_train)\n",
    "print('Training Accuracy: {:.4f}'.format(train_score))\n",
    "#evaluation(Accuracy)\n",
    "print(\"Testing Accuracy: {:.4f}\",metrics.accuracy_score(prediction,y_test))\n",
    "#evaluation(Confusion Metrix)\n",
    "print(\"Confusion Metrix:\\n\",metrics.confusion_matrix(prediction,y_test))\n",
    "#evaluation(Classification_report)\n",
    "print(\"Classification Report:\\n\",metrics.classification_report(y_test, prediction, labels=[1,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sathish kumar\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[mean: 0.97899, std: 0.00879, params: {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 10, 'n_jobs': -1},\n",
       " mean: 0.98459, std: 0.00810, params: {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 15, 'n_jobs': -1},\n",
       " mean: 0.98459, std: 0.00676, params: {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 20, 'n_jobs': -1},\n",
       " mean: 0.98319, std: 0.00938, params: {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 25, 'n_jobs': -1},\n",
       " mean: 0.98459, std: 0.01017, params: {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 30, 'n_jobs': -1},\n",
       " mean: 0.98179, std: 0.00710, params: {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 10, 'n_jobs': -1},\n",
       " mean: 0.98739, std: 0.00517, params: {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 15, 'n_jobs': -1},\n",
       " mean: 0.98739, std: 0.00806, params: {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 20, 'n_jobs': -1},\n",
       " mean: 0.98739, std: 0.00806, params: {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 25, 'n_jobs': -1},\n",
       " mean: 0.98599, std: 0.01072, params: {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 30, 'n_jobs': -1},\n",
       " mean: 0.98179, std: 0.00710, params: {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 10, 'n_jobs': -1},\n",
       " mean: 0.98599, std: 0.00436, params: {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 15, 'n_jobs': -1},\n",
       " mean: 0.98459, std: 0.01017, params: {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 20, 'n_jobs': -1},\n",
       " mean: 0.98599, std: 0.00757, params: {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 25, 'n_jobs': -1},\n",
       " mean: 0.98599, std: 0.01072, params: {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 30, 'n_jobs': -1},\n",
       " mean: 0.98179, std: 0.00838, params: {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 10, 'n_jobs': -1},\n",
       " mean: 0.98179, std: 0.00714, params: {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 15, 'n_jobs': -1},\n",
       " mean: 0.98599, std: 0.00623, params: {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 20, 'n_jobs': -1},\n",
       " mean: 0.98179, std: 0.01131, params: {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 25, 'n_jobs': -1},\n",
       " mean: 0.98179, std: 0.01286, params: {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 30, 'n_jobs': -1},\n",
       " mean: 0.97899, std: 0.00982, params: {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 6, 'n_estimators': 10, 'n_jobs': -1},\n",
       " mean: 0.98319, std: 0.00716, params: {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 6, 'n_estimators': 15, 'n_jobs': -1},\n",
       " mean: 0.98319, std: 0.01038, params: {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 6, 'n_estimators': 20, 'n_jobs': -1},\n",
       " mean: 0.97899, std: 0.01242, params: {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 6, 'n_estimators': 25, 'n_jobs': -1},\n",
       " mean: 0.98179, std: 0.00940, params: {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 6, 'n_estimators': 30, 'n_jobs': -1},\n",
       " mean: 0.98039, std: 0.00920, params: {'criterion': 'gini', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 10, 'n_jobs': -1},\n",
       " mean: 0.98179, std: 0.00838, params: {'criterion': 'gini', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 15, 'n_jobs': -1},\n",
       " mean: 0.98319, std: 0.00947, params: {'criterion': 'gini', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 20, 'n_jobs': -1},\n",
       " mean: 0.97899, std: 0.01242, params: {'criterion': 'gini', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 25, 'n_jobs': -1},\n",
       " mean: 0.97899, std: 0.01242, params: {'criterion': 'gini', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 30, 'n_jobs': -1},\n",
       " mean: 0.98039, std: 0.00920, params: {'criterion': 'gini', 'min_samples_leaf': 2, 'min_samples_split': 3, 'n_estimators': 10, 'n_jobs': -1},\n",
       " mean: 0.98179, std: 0.00838, params: {'criterion': 'gini', 'min_samples_leaf': 2, 'min_samples_split': 3, 'n_estimators': 15, 'n_jobs': -1},\n",
       " mean: 0.98319, std: 0.00947, params: {'criterion': 'gini', 'min_samples_leaf': 2, 'min_samples_split': 3, 'n_estimators': 20, 'n_jobs': -1},\n",
       " mean: 0.97899, std: 0.01242, params: {'criterion': 'gini', 'min_samples_leaf': 2, 'min_samples_split': 3, 'n_estimators': 25, 'n_jobs': -1},\n",
       " mean: 0.97899, std: 0.01242, params: {'criterion': 'gini', 'min_samples_leaf': 2, 'min_samples_split': 3, 'n_estimators': 30, 'n_jobs': -1},\n",
       " mean: 0.98039, std: 0.00920, params: {'criterion': 'gini', 'min_samples_leaf': 2, 'min_samples_split': 4, 'n_estimators': 10, 'n_jobs': -1},\n",
       " mean: 0.98179, std: 0.00838, params: {'criterion': 'gini', 'min_samples_leaf': 2, 'min_samples_split': 4, 'n_estimators': 15, 'n_jobs': -1},\n",
       " mean: 0.98319, std: 0.00947, params: {'criterion': 'gini', 'min_samples_leaf': 2, 'min_samples_split': 4, 'n_estimators': 20, 'n_jobs': -1},\n",
       " mean: 0.97899, std: 0.01242, params: {'criterion': 'gini', 'min_samples_leaf': 2, 'min_samples_split': 4, 'n_estimators': 25, 'n_jobs': -1},\n",
       " mean: 0.97899, std: 0.01242, params: {'criterion': 'gini', 'min_samples_leaf': 2, 'min_samples_split': 4, 'n_estimators': 30, 'n_jobs': -1},\n",
       " mean: 0.98319, std: 0.00708, params: {'criterion': 'gini', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 10, 'n_jobs': -1},\n",
       " mean: 0.98039, std: 0.01023, params: {'criterion': 'gini', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 15, 'n_jobs': -1},\n",
       " mean: 0.97759, std: 0.01482, params: {'criterion': 'gini', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 20, 'n_jobs': -1},\n",
       " mean: 0.97759, std: 0.01482, params: {'criterion': 'gini', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 25, 'n_jobs': -1},\n",
       " mean: 0.98039, std: 0.01668, params: {'criterion': 'gini', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 30, 'n_jobs': -1},\n",
       " mean: 0.97899, std: 0.01320, params: {'criterion': 'gini', 'min_samples_leaf': 2, 'min_samples_split': 6, 'n_estimators': 10, 'n_jobs': -1},\n",
       " mean: 0.98179, std: 0.00710, params: {'criterion': 'gini', 'min_samples_leaf': 2, 'min_samples_split': 6, 'n_estimators': 15, 'n_jobs': -1},\n",
       " mean: 0.97759, std: 0.01195, params: {'criterion': 'gini', 'min_samples_leaf': 2, 'min_samples_split': 6, 'n_estimators': 20, 'n_jobs': -1},\n",
       " mean: 0.97759, std: 0.01109, params: {'criterion': 'gini', 'min_samples_leaf': 2, 'min_samples_split': 6, 'n_estimators': 25, 'n_jobs': -1},\n",
       " mean: 0.97899, std: 0.01242, params: {'criterion': 'gini', 'min_samples_leaf': 2, 'min_samples_split': 6, 'n_estimators': 30, 'n_jobs': -1},\n",
       " mean: 0.97339, std: 0.01835, params: {'criterion': 'gini', 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 10, 'n_jobs': -1},\n",
       " mean: 0.97899, std: 0.00757, params: {'criterion': 'gini', 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 15, 'n_jobs': -1},\n",
       " mean: 0.97759, std: 0.00677, params: {'criterion': 'gini', 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 20, 'n_jobs': -1},\n",
       " mean: 0.97899, std: 0.00626, params: {'criterion': 'gini', 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 25, 'n_jobs': -1},\n",
       " mean: 0.97899, std: 0.00626, params: {'criterion': 'gini', 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 30, 'n_jobs': -1},\n",
       " mean: 0.97339, std: 0.01835, params: {'criterion': 'gini', 'min_samples_leaf': 3, 'min_samples_split': 3, 'n_estimators': 10, 'n_jobs': -1},\n",
       " mean: 0.97899, std: 0.00757, params: {'criterion': 'gini', 'min_samples_leaf': 3, 'min_samples_split': 3, 'n_estimators': 15, 'n_jobs': -1},\n",
       " mean: 0.97759, std: 0.00677, params: {'criterion': 'gini', 'min_samples_leaf': 3, 'min_samples_split': 3, 'n_estimators': 20, 'n_jobs': -1},\n",
       " mean: 0.97899, std: 0.00626, params: {'criterion': 'gini', 'min_samples_leaf': 3, 'min_samples_split': 3, 'n_estimators': 25, 'n_jobs': -1},\n",
       " mean: 0.97899, std: 0.00626, params: {'criterion': 'gini', 'min_samples_leaf': 3, 'min_samples_split': 3, 'n_estimators': 30, 'n_jobs': -1},\n",
       " mean: 0.97339, std: 0.01835, params: {'criterion': 'gini', 'min_samples_leaf': 3, 'min_samples_split': 4, 'n_estimators': 10, 'n_jobs': -1},\n",
       " mean: 0.97899, std: 0.00757, params: {'criterion': 'gini', 'min_samples_leaf': 3, 'min_samples_split': 4, 'n_estimators': 15, 'n_jobs': -1},\n",
       " mean: 0.97759, std: 0.00677, params: {'criterion': 'gini', 'min_samples_leaf': 3, 'min_samples_split': 4, 'n_estimators': 20, 'n_jobs': -1},\n",
       " mean: 0.97899, std: 0.00626, params: {'criterion': 'gini', 'min_samples_leaf': 3, 'min_samples_split': 4, 'n_estimators': 25, 'n_jobs': -1},\n",
       " mean: 0.97899, std: 0.00626, params: {'criterion': 'gini', 'min_samples_leaf': 3, 'min_samples_split': 4, 'n_estimators': 30, 'n_jobs': -1},\n",
       " mean: 0.97339, std: 0.01835, params: {'criterion': 'gini', 'min_samples_leaf': 3, 'min_samples_split': 5, 'n_estimators': 10, 'n_jobs': -1},\n",
       " mean: 0.97899, std: 0.00757, params: {'criterion': 'gini', 'min_samples_leaf': 3, 'min_samples_split': 5, 'n_estimators': 15, 'n_jobs': -1},\n",
       " mean: 0.97759, std: 0.00677, params: {'criterion': 'gini', 'min_samples_leaf': 3, 'min_samples_split': 5, 'n_estimators': 20, 'n_jobs': -1},\n",
       " mean: 0.97899, std: 0.00626, params: {'criterion': 'gini', 'min_samples_leaf': 3, 'min_samples_split': 5, 'n_estimators': 25, 'n_jobs': -1},\n",
       " mean: 0.97899, std: 0.00626, params: {'criterion': 'gini', 'min_samples_leaf': 3, 'min_samples_split': 5, 'n_estimators': 30, 'n_jobs': -1},\n",
       " mean: 0.97339, std: 0.01835, params: {'criterion': 'gini', 'min_samples_leaf': 3, 'min_samples_split': 6, 'n_estimators': 10, 'n_jobs': -1},\n",
       " mean: 0.97899, std: 0.00757, params: {'criterion': 'gini', 'min_samples_leaf': 3, 'min_samples_split': 6, 'n_estimators': 15, 'n_jobs': -1},\n",
       " mean: 0.97759, std: 0.00677, params: {'criterion': 'gini', 'min_samples_leaf': 3, 'min_samples_split': 6, 'n_estimators': 20, 'n_jobs': -1},\n",
       " mean: 0.97899, std: 0.00626, params: {'criterion': 'gini', 'min_samples_leaf': 3, 'min_samples_split': 6, 'n_estimators': 25, 'n_jobs': -1},\n",
       " mean: 0.97899, std: 0.00626, params: {'criterion': 'gini', 'min_samples_leaf': 3, 'min_samples_split': 6, 'n_estimators': 30, 'n_jobs': -1},\n",
       " mean: 0.96499, std: 0.01238, params: {'criterion': 'gini', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 10, 'n_jobs': -1},\n",
       " mean: 0.97059, std: 0.00805, params: {'criterion': 'gini', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 15, 'n_jobs': -1},\n",
       " mean: 0.96919, std: 0.01212, params: {'criterion': 'gini', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 20, 'n_jobs': -1},\n",
       " mean: 0.97059, std: 0.01107, params: {'criterion': 'gini', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 25, 'n_jobs': -1},\n",
       " mean: 0.97059, std: 0.01339, params: {'criterion': 'gini', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 30, 'n_jobs': -1},\n",
       " mean: 0.96499, std: 0.01238, params: {'criterion': 'gini', 'min_samples_leaf': 4, 'min_samples_split': 3, 'n_estimators': 10, 'n_jobs': -1},\n",
       " mean: 0.97059, std: 0.00805, params: {'criterion': 'gini', 'min_samples_leaf': 4, 'min_samples_split': 3, 'n_estimators': 15, 'n_jobs': -1},\n",
       " mean: 0.96919, std: 0.01212, params: {'criterion': 'gini', 'min_samples_leaf': 4, 'min_samples_split': 3, 'n_estimators': 20, 'n_jobs': -1},\n",
       " mean: 0.97059, std: 0.01107, params: {'criterion': 'gini', 'min_samples_leaf': 4, 'min_samples_split': 3, 'n_estimators': 25, 'n_jobs': -1},\n",
       " mean: 0.97059, std: 0.01339, params: {'criterion': 'gini', 'min_samples_leaf': 4, 'min_samples_split': 3, 'n_estimators': 30, 'n_jobs': -1},\n",
       " mean: 0.96499, std: 0.01238, params: {'criterion': 'gini', 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 10, 'n_jobs': -1},\n",
       " mean: 0.97059, std: 0.00805, params: {'criterion': 'gini', 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 15, 'n_jobs': -1},\n",
       " mean: 0.96919, std: 0.01212, params: {'criterion': 'gini', 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 20, 'n_jobs': -1},\n",
       " mean: 0.97059, std: 0.01107, params: {'criterion': 'gini', 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 25, 'n_jobs': -1},\n",
       " mean: 0.97059, std: 0.01339, params: {'criterion': 'gini', 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 30, 'n_jobs': -1},\n",
       " mean: 0.96499, std: 0.01238, params: {'criterion': 'gini', 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 10, 'n_jobs': -1},\n",
       " mean: 0.97059, std: 0.00805, params: {'criterion': 'gini', 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 15, 'n_jobs': -1},\n",
       " mean: 0.96919, std: 0.01212, params: {'criterion': 'gini', 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 20, 'n_jobs': -1},\n",
       " mean: 0.97059, std: 0.01107, params: {'criterion': 'gini', 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 25, 'n_jobs': -1},\n",
       " mean: 0.97059, std: 0.01339, params: {'criterion': 'gini', 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 30, 'n_jobs': -1},\n",
       " mean: 0.96499, std: 0.01238, params: {'criterion': 'gini', 'min_samples_leaf': 4, 'min_samples_split': 6, 'n_estimators': 10, 'n_jobs': -1},\n",
       " mean: 0.97059, std: 0.00805, params: {'criterion': 'gini', 'min_samples_leaf': 4, 'min_samples_split': 6, 'n_estimators': 15, 'n_jobs': -1},\n",
       " mean: 0.96919, std: 0.01212, params: {'criterion': 'gini', 'min_samples_leaf': 4, 'min_samples_split': 6, 'n_estimators': 20, 'n_jobs': -1},\n",
       " mean: 0.97059, std: 0.01107, params: {'criterion': 'gini', 'min_samples_leaf': 4, 'min_samples_split': 6, 'n_estimators': 25, 'n_jobs': -1},\n",
       " mean: 0.97059, std: 0.01339, params: {'criterion': 'gini', 'min_samples_leaf': 4, 'min_samples_split': 6, 'n_estimators': 30, 'n_jobs': -1},\n",
       " mean: 0.96779, std: 0.01429, params: {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 10, 'n_jobs': -1},\n",
       " mean: 0.96639, std: 0.01664, params: {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 15, 'n_jobs': -1},\n",
       " mean: 0.96499, std: 0.01580, params: {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 20, 'n_jobs': -1},\n",
       " mean: 0.96499, std: 0.01461, params: {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 25, 'n_jobs': -1},\n",
       " mean: 0.96639, std: 0.01664, params: {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 30, 'n_jobs': -1},\n",
       " mean: 0.96779, std: 0.01429, params: {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 10, 'n_jobs': -1},\n",
       " mean: 0.96639, std: 0.01664, params: {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 15, 'n_jobs': -1},\n",
       " mean: 0.96499, std: 0.01580, params: {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 20, 'n_jobs': -1},\n",
       " mean: 0.96499, std: 0.01461, params: {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 25, 'n_jobs': -1},\n",
       " mean: 0.96639, std: 0.01664, params: {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 30, 'n_jobs': -1},\n",
       " mean: 0.96779, std: 0.01429, params: {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 10, 'n_jobs': -1},\n",
       " mean: 0.96639, std: 0.01664, params: {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 15, 'n_jobs': -1},\n",
       " mean: 0.96499, std: 0.01580, params: {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 20, 'n_jobs': -1},\n",
       " mean: 0.96499, std: 0.01461, params: {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 25, 'n_jobs': -1},\n",
       " mean: 0.96639, std: 0.01664, params: {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 30, 'n_jobs': -1},\n",
       " mean: 0.96779, std: 0.01429, params: {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 10, 'n_jobs': -1},\n",
       " mean: 0.96639, std: 0.01664, params: {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 15, 'n_jobs': -1},\n",
       " mean: 0.96499, std: 0.01580, params: {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 20, 'n_jobs': -1},\n",
       " mean: 0.96499, std: 0.01461, params: {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 25, 'n_jobs': -1},\n",
       " mean: 0.96639, std: 0.01664, params: {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 30, 'n_jobs': -1},\n",
       " mean: 0.96779, std: 0.01429, params: {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 6, 'n_estimators': 10, 'n_jobs': -1},\n",
       " mean: 0.96639, std: 0.01664, params: {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 6, 'n_estimators': 15, 'n_jobs': -1},\n",
       " mean: 0.96499, std: 0.01580, params: {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 6, 'n_estimators': 20, 'n_jobs': -1},\n",
       " mean: 0.96499, std: 0.01461, params: {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 6, 'n_estimators': 25, 'n_jobs': -1},\n",
       " mean: 0.96639, std: 0.01664, params: {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 6, 'n_estimators': 30, 'n_jobs': -1},\n",
       " mean: 0.97899, std: 0.00879, params: {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 10, 'n_jobs': -1},\n",
       " mean: 0.97619, std: 0.00705, params: {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 15, 'n_jobs': -1},\n",
       " mean: 0.98039, std: 0.00920, params: {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 20, 'n_jobs': -1},\n",
       " mean: 0.98039, std: 0.00920, params: {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 25, 'n_jobs': -1},\n",
       " mean: 0.98179, std: 0.01206, params: {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 30, 'n_jobs': -1},\n",
       " mean: 0.97899, std: 0.00621, params: {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 10, 'n_jobs': -1},\n",
       " mean: 0.97899, std: 0.00754, params: {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 15, 'n_jobs': -1},\n",
       " mean: 0.98459, std: 0.00522, params: {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 20, 'n_jobs': -1},\n",
       " mean: 0.98179, std: 0.00553, params: {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 25, 'n_jobs': -1},\n",
       " mean: 0.98459, std: 0.00522, params: {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 30, 'n_jobs': -1},\n",
       " mean: 0.98179, std: 0.00564, params: {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 10, 'n_jobs': -1},\n",
       " mean: 0.98179, std: 0.00711, params: {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 15, 'n_jobs': -1},\n",
       " mean: 0.98179, std: 0.00345, params: {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 20, 'n_jobs': -1},\n",
       " mean: 0.98459, std: 0.00524, params: {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 25, 'n_jobs': -1},\n",
       " mean: 0.98459, std: 0.00524, params: {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 30, 'n_jobs': -1},\n",
       " mean: 0.98179, std: 0.01206, params: {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 10, 'n_jobs': -1},\n",
       " mean: 0.98319, std: 0.00563, params: {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 15, 'n_jobs': -1},\n",
       " mean: 0.98599, std: 0.00626, params: {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 20, 'n_jobs': -1},\n",
       " mean: 0.98459, std: 0.00524, params: {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 25, 'n_jobs': -1},\n",
       " mean: 0.98459, std: 0.00524, params: {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 30, 'n_jobs': -1},\n",
       " mean: 0.98179, std: 0.00940, params: {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 6, 'n_estimators': 10, 'n_jobs': -1},\n",
       " mean: 0.98319, std: 0.00563, params: {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 6, 'n_estimators': 15, 'n_jobs': -1},\n",
       " mean: 0.98599, std: 0.00626, params: {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 6, 'n_estimators': 20, 'n_jobs': -1},\n",
       " mean: 0.98319, std: 0.00708, params: {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 6, 'n_estimators': 25, 'n_jobs': -1},\n",
       " mean: 0.98599, std: 0.00439, params: {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 6, 'n_estimators': 30, 'n_jobs': -1},\n",
       " mean: 0.98039, std: 0.00513, params: {'criterion': 'entropy', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 10, 'n_jobs': -1},\n",
       " mean: 0.97759, std: 0.00525, params: {'criterion': 'entropy', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 15, 'n_jobs': -1},\n",
       " mean: 0.98039, std: 0.00530, params: {'criterion': 'entropy', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 20, 'n_jobs': -1},\n",
       " mean: 0.98319, std: 0.00563, params: {'criterion': 'entropy', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 25, 'n_jobs': -1},\n",
       " mean: 0.97899, std: 0.00985, params: {'criterion': 'entropy', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 30, 'n_jobs': -1},\n",
       " mean: 0.98039, std: 0.00513, params: {'criterion': 'entropy', 'min_samples_leaf': 2, 'min_samples_split': 3, 'n_estimators': 10, 'n_jobs': -1},\n",
       " mean: 0.97759, std: 0.00525, params: {'criterion': 'entropy', 'min_samples_leaf': 2, 'min_samples_split': 3, 'n_estimators': 15, 'n_jobs': -1},\n",
       " mean: 0.98039, std: 0.00530, params: {'criterion': 'entropy', 'min_samples_leaf': 2, 'min_samples_split': 3, 'n_estimators': 20, 'n_jobs': -1},\n",
       " mean: 0.98319, std: 0.00563, params: {'criterion': 'entropy', 'min_samples_leaf': 2, 'min_samples_split': 3, 'n_estimators': 25, 'n_jobs': -1},\n",
       " mean: 0.97899, std: 0.00985, params: {'criterion': 'entropy', 'min_samples_leaf': 2, 'min_samples_split': 3, 'n_estimators': 30, 'n_jobs': -1},\n",
       " mean: 0.98039, std: 0.00513, params: {'criterion': 'entropy', 'min_samples_leaf': 2, 'min_samples_split': 4, 'n_estimators': 10, 'n_jobs': -1},\n",
       " mean: 0.97759, std: 0.00525, params: {'criterion': 'entropy', 'min_samples_leaf': 2, 'min_samples_split': 4, 'n_estimators': 15, 'n_jobs': -1},\n",
       " mean: 0.98039, std: 0.00530, params: {'criterion': 'entropy', 'min_samples_leaf': 2, 'min_samples_split': 4, 'n_estimators': 20, 'n_jobs': -1},\n",
       " mean: 0.98319, std: 0.00563, params: {'criterion': 'entropy', 'min_samples_leaf': 2, 'min_samples_split': 4, 'n_estimators': 25, 'n_jobs': -1},\n",
       " mean: 0.97899, std: 0.00985, params: {'criterion': 'entropy', 'min_samples_leaf': 2, 'min_samples_split': 4, 'n_estimators': 30, 'n_jobs': -1},\n",
       " mean: 0.97899, std: 0.01071, params: {'criterion': 'entropy', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 10, 'n_jobs': -1},\n",
       " mean: 0.98179, std: 0.00564, params: {'criterion': 'entropy', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 15, 'n_jobs': -1},\n",
       " mean: 0.98179, std: 0.00940, params: {'criterion': 'entropy', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 20, 'n_jobs': -1},\n",
       " mean: 0.98039, std: 0.01192, params: {'criterion': 'entropy', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 25, 'n_jobs': -1},\n",
       " mean: 0.98179, std: 0.00940, params: {'criterion': 'entropy', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 30, 'n_jobs': -1},\n",
       " mean: 0.98179, std: 0.00711, params: {'criterion': 'entropy', 'min_samples_leaf': 2, 'min_samples_split': 6, 'n_estimators': 10, 'n_jobs': -1},\n",
       " mean: 0.97899, std: 0.00879, params: {'criterion': 'entropy', 'min_samples_leaf': 2, 'min_samples_split': 6, 'n_estimators': 15, 'n_jobs': -1},\n",
       " mean: 0.98039, std: 0.00816, params: {'criterion': 'entropy', 'min_samples_leaf': 2, 'min_samples_split': 6, 'n_estimators': 20, 'n_jobs': -1},\n",
       " mean: 0.98039, std: 0.01192, params: {'criterion': 'entropy', 'min_samples_leaf': 2, 'min_samples_split': 6, 'n_estimators': 25, 'n_jobs': -1},\n",
       " mean: 0.98319, std: 0.00939, params: {'criterion': 'entropy', 'min_samples_leaf': 2, 'min_samples_split': 6, 'n_estimators': 30, 'n_jobs': -1},\n",
       " mean: 0.97059, std: 0.01735, params: {'criterion': 'entropy', 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 10, 'n_jobs': -1},\n",
       " mean: 0.97619, std: 0.00947, params: {'criterion': 'entropy', 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 15, 'n_jobs': -1},\n",
       " mean: 0.97899, std: 0.01160, params: {'criterion': 'entropy', 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 20, 'n_jobs': -1},\n",
       " mean: 0.97899, std: 0.01160, params: {'criterion': 'entropy', 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 25, 'n_jobs': -1},\n",
       " mean: 0.98179, std: 0.00940, params: {'criterion': 'entropy', 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 30, 'n_jobs': -1},\n",
       " mean: 0.97059, std: 0.01735, params: {'criterion': 'entropy', 'min_samples_leaf': 3, 'min_samples_split': 3, 'n_estimators': 10, 'n_jobs': -1},\n",
       " mean: 0.97619, std: 0.00947, params: {'criterion': 'entropy', 'min_samples_leaf': 3, 'min_samples_split': 3, 'n_estimators': 15, 'n_jobs': -1},\n",
       " mean: 0.97899, std: 0.01160, params: {'criterion': 'entropy', 'min_samples_leaf': 3, 'min_samples_split': 3, 'n_estimators': 20, 'n_jobs': -1},\n",
       " mean: 0.97899, std: 0.01160, params: {'criterion': 'entropy', 'min_samples_leaf': 3, 'min_samples_split': 3, 'n_estimators': 25, 'n_jobs': -1},\n",
       " mean: 0.98179, std: 0.00940, params: {'criterion': 'entropy', 'min_samples_leaf': 3, 'min_samples_split': 3, 'n_estimators': 30, 'n_jobs': -1},\n",
       " mean: 0.97059, std: 0.01735, params: {'criterion': 'entropy', 'min_samples_leaf': 3, 'min_samples_split': 4, 'n_estimators': 10, 'n_jobs': -1},\n",
       " mean: 0.97619, std: 0.00947, params: {'criterion': 'entropy', 'min_samples_leaf': 3, 'min_samples_split': 4, 'n_estimators': 15, 'n_jobs': -1},\n",
       " mean: 0.97899, std: 0.01160, params: {'criterion': 'entropy', 'min_samples_leaf': 3, 'min_samples_split': 4, 'n_estimators': 20, 'n_jobs': -1},\n",
       " mean: 0.97899, std: 0.01160, params: {'criterion': 'entropy', 'min_samples_leaf': 3, 'min_samples_split': 4, 'n_estimators': 25, 'n_jobs': -1},\n",
       " mean: 0.98179, std: 0.00940, params: {'criterion': 'entropy', 'min_samples_leaf': 3, 'min_samples_split': 4, 'n_estimators': 30, 'n_jobs': -1},\n",
       " mean: 0.97059, std: 0.01735, params: {'criterion': 'entropy', 'min_samples_leaf': 3, 'min_samples_split': 5, 'n_estimators': 10, 'n_jobs': -1},\n",
       " mean: 0.97619, std: 0.00947, params: {'criterion': 'entropy', 'min_samples_leaf': 3, 'min_samples_split': 5, 'n_estimators': 15, 'n_jobs': -1},\n",
       " mean: 0.97899, std: 0.01160, params: {'criterion': 'entropy', 'min_samples_leaf': 3, 'min_samples_split': 5, 'n_estimators': 20, 'n_jobs': -1},\n",
       " mean: 0.97899, std: 0.01160, params: {'criterion': 'entropy', 'min_samples_leaf': 3, 'min_samples_split': 5, 'n_estimators': 25, 'n_jobs': -1},\n",
       " mean: 0.98179, std: 0.00940, params: {'criterion': 'entropy', 'min_samples_leaf': 3, 'min_samples_split': 5, 'n_estimators': 30, 'n_jobs': -1},\n",
       " mean: 0.97059, std: 0.01735, params: {'criterion': 'entropy', 'min_samples_leaf': 3, 'min_samples_split': 6, 'n_estimators': 10, 'n_jobs': -1},\n",
       " mean: 0.97619, std: 0.00947, params: {'criterion': 'entropy', 'min_samples_leaf': 3, 'min_samples_split': 6, 'n_estimators': 15, 'n_jobs': -1},\n",
       " mean: 0.97899, std: 0.01160, params: {'criterion': 'entropy', 'min_samples_leaf': 3, 'min_samples_split': 6, 'n_estimators': 20, 'n_jobs': -1},\n",
       " mean: 0.97899, std: 0.01160, params: {'criterion': 'entropy', 'min_samples_leaf': 3, 'min_samples_split': 6, 'n_estimators': 25, 'n_jobs': -1},\n",
       " mean: 0.98179, std: 0.00940, params: {'criterion': 'entropy', 'min_samples_leaf': 3, 'min_samples_split': 6, 'n_estimators': 30, 'n_jobs': -1},\n",
       " mean: 0.97059, std: 0.01934, params: {'criterion': 'entropy', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 10, 'n_jobs': -1},\n",
       " mean: 0.97199, std: 0.01168, params: {'criterion': 'entropy', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 15, 'n_jobs': -1},\n",
       " mean: 0.97199, std: 0.00877, params: {'criterion': 'entropy', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 20, 'n_jobs': -1},\n",
       " mean: 0.97059, std: 0.01014, params: {'criterion': 'entropy', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 25, 'n_jobs': -1},\n",
       " mean: 0.97619, std: 0.00708, params: {'criterion': 'entropy', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 30, 'n_jobs': -1},\n",
       " mean: 0.97059, std: 0.01934, params: {'criterion': 'entropy', 'min_samples_leaf': 4, 'min_samples_split': 3, 'n_estimators': 10, 'n_jobs': -1},\n",
       " mean: 0.97199, std: 0.01168, params: {'criterion': 'entropy', 'min_samples_leaf': 4, 'min_samples_split': 3, 'n_estimators': 15, 'n_jobs': -1},\n",
       " mean: 0.97199, std: 0.00877, params: {'criterion': 'entropy', 'min_samples_leaf': 4, 'min_samples_split': 3, 'n_estimators': 20, 'n_jobs': -1},\n",
       " mean: 0.97059, std: 0.01014, params: {'criterion': 'entropy', 'min_samples_leaf': 4, 'min_samples_split': 3, 'n_estimators': 25, 'n_jobs': -1},\n",
       " mean: 0.97619, std: 0.00708, params: {'criterion': 'entropy', 'min_samples_leaf': 4, 'min_samples_split': 3, 'n_estimators': 30, 'n_jobs': -1},\n",
       " mean: 0.97059, std: 0.01934, params: {'criterion': 'entropy', 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 10, 'n_jobs': -1},\n",
       " mean: 0.97199, std: 0.01168, params: {'criterion': 'entropy', 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 15, 'n_jobs': -1},\n",
       " mean: 0.97199, std: 0.00877, params: {'criterion': 'entropy', 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 20, 'n_jobs': -1},\n",
       " mean: 0.97059, std: 0.01014, params: {'criterion': 'entropy', 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 25, 'n_jobs': -1},\n",
       " mean: 0.97619, std: 0.00708, params: {'criterion': 'entropy', 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 30, 'n_jobs': -1},\n",
       " mean: 0.97059, std: 0.01934, params: {'criterion': 'entropy', 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 10, 'n_jobs': -1},\n",
       " mean: 0.97199, std: 0.01168, params: {'criterion': 'entropy', 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 15, 'n_jobs': -1},\n",
       " mean: 0.97199, std: 0.00877, params: {'criterion': 'entropy', 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 20, 'n_jobs': -1},\n",
       " mean: 0.97059, std: 0.01014, params: {'criterion': 'entropy', 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 25, 'n_jobs': -1},\n",
       " mean: 0.97619, std: 0.00708, params: {'criterion': 'entropy', 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 30, 'n_jobs': -1},\n",
       " mean: 0.97059, std: 0.01934, params: {'criterion': 'entropy', 'min_samples_leaf': 4, 'min_samples_split': 6, 'n_estimators': 10, 'n_jobs': -1},\n",
       " mean: 0.97199, std: 0.01168, params: {'criterion': 'entropy', 'min_samples_leaf': 4, 'min_samples_split': 6, 'n_estimators': 15, 'n_jobs': -1},\n",
       " mean: 0.97199, std: 0.00877, params: {'criterion': 'entropy', 'min_samples_leaf': 4, 'min_samples_split': 6, 'n_estimators': 20, 'n_jobs': -1},\n",
       " mean: 0.97059, std: 0.01014, params: {'criterion': 'entropy', 'min_samples_leaf': 4, 'min_samples_split': 6, 'n_estimators': 25, 'n_jobs': -1},\n",
       " mean: 0.97619, std: 0.00708, params: {'criterion': 'entropy', 'min_samples_leaf': 4, 'min_samples_split': 6, 'n_estimators': 30, 'n_jobs': -1},\n",
       " mean: 0.96359, std: 0.01038, params: {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 10, 'n_jobs': -1},\n",
       " mean: 0.97059, std: 0.00526, params: {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 15, 'n_jobs': -1},\n",
       " mean: 0.96499, std: 0.00985, params: {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 20, 'n_jobs': -1},\n",
       " mean: 0.96639, std: 0.01189, params: {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 25, 'n_jobs': -1},\n",
       " mean: 0.96919, std: 0.01280, params: {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 30, 'n_jobs': -1},\n",
       " mean: 0.96359, std: 0.01038, params: {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 10, 'n_jobs': -1},\n",
       " mean: 0.97059, std: 0.00526, params: {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 15, 'n_jobs': -1},\n",
       " mean: 0.96499, std: 0.00985, params: {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 20, 'n_jobs': -1},\n",
       " mean: 0.96639, std: 0.01189, params: {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 25, 'n_jobs': -1},\n",
       " mean: 0.96919, std: 0.01280, params: {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 30, 'n_jobs': -1},\n",
       " mean: 0.96359, std: 0.01038, params: {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 10, 'n_jobs': -1},\n",
       " mean: 0.97059, std: 0.00526, params: {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 15, 'n_jobs': -1},\n",
       " mean: 0.96499, std: 0.00985, params: {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 20, 'n_jobs': -1},\n",
       " mean: 0.96639, std: 0.01189, params: {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 25, 'n_jobs': -1},\n",
       " mean: 0.96919, std: 0.01280, params: {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 30, 'n_jobs': -1},\n",
       " mean: 0.96359, std: 0.01038, params: {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 10, 'n_jobs': -1},\n",
       " mean: 0.97059, std: 0.00526, params: {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 15, 'n_jobs': -1},\n",
       " mean: 0.96499, std: 0.00985, params: {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 20, 'n_jobs': -1},\n",
       " mean: 0.96639, std: 0.01189, params: {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 25, 'n_jobs': -1},\n",
       " mean: 0.96919, std: 0.01280, params: {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 30, 'n_jobs': -1},\n",
       " mean: 0.96359, std: 0.01038, params: {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 6, 'n_estimators': 10, 'n_jobs': -1},\n",
       " mean: 0.97059, std: 0.00526, params: {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 6, 'n_estimators': 15, 'n_jobs': -1},\n",
       " mean: 0.96499, std: 0.00985, params: {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 6, 'n_estimators': 20, 'n_jobs': -1},\n",
       " mean: 0.96639, std: 0.01189, params: {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 6, 'n_estimators': 25, 'n_jobs': -1},\n",
       " mean: 0.96919, std: 0.01280, params: {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 6, 'n_estimators': 30, 'n_jobs': -1}]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sathish kumar\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\sathish kumar\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\sathish kumar\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\sathish kumar\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\sathish kumar\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\sathish kumar\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\sathish kumar\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.16825395, 0.18940096, 0.17656417, 0.17619772, 0.17529898,\n",
       "        0.1355279 , 0.13749714, 0.14141583, 0.17839446, 0.18682938,\n",
       "        0.12978072, 0.14351158, 0.16276507, 0.1713243 , 0.1729279 ,\n",
       "        0.1282094 , 0.14346814, 0.13505797, 0.14316349, 0.15879121,\n",
       "        0.13064175, 0.12464738, 0.14740472, 0.16420455, 0.19868245,\n",
       "        0.13792467, 0.15695443, 0.13711581, 0.21384878, 0.1774106 ,\n",
       "        0.13266411, 0.1358706 , 0.14993992, 0.16853795, 0.18280597,\n",
       "        0.14021912, 0.15341687, 0.13866515, 0.14959779, 0.24226627,\n",
       "        0.14135709, 0.13856091, 0.13904233, 0.14364972, 0.17422085,\n",
       "        0.12966809, 0.13538523, 0.14624443, 0.14886694, 0.1687149 ,\n",
       "        0.12307386, 0.12579565, 0.14470038, 0.15595717, 0.17128034,\n",
       "        0.13372693, 0.13708715, 0.15898623, 0.17484369, 0.16523352,\n",
       "        0.12566295, 0.13138075, 0.15601926, 0.15273213, 0.16925445,\n",
       "        0.12300544, 0.1387085 , 0.15344911, 0.16221986, 0.16562772,\n",
       "        0.13424253, 0.14922972, 0.20123377, 0.20461397, 0.24694877,\n",
       "        0.13963957, 0.17911229, 0.17146893, 0.17067118, 0.22591252,\n",
       "        0.1291573 , 0.16818004, 0.14425793, 0.19451208, 0.18259001,\n",
       "        0.12425303, 0.16539783, 0.15811477, 0.16779804, 0.18284793,\n",
       "        0.13151212, 0.13068414, 0.15032144, 0.15245395, 0.17316561,\n",
       "        0.13734207, 0.14740758, 0.14722934, 0.17037435, 0.16213174,\n",
       "        0.13565278, 0.14709678, 0.15371156, 0.1527545 , 0.18355637,\n",
       "        0.13097396, 0.13859787, 0.19941068, 0.17838044, 0.18458376,\n",
       "        0.13130612, 0.14027643, 0.16679063, 0.16169839, 0.17561831,\n",
       "        0.13096681, 0.13835378, 0.15850267, 0.15270605, 0.17286801,\n",
       "        0.14570432, 0.14350553, 0.15194049, 0.16922512, 0.15529509,\n",
       "        0.13531332, 0.14031138, 0.14913273, 0.18227625, 0.18366385,\n",
       "        0.12967653, 0.14732118, 0.15998206, 0.15759449, 0.18228359,\n",
       "        0.12533097, 0.13979254, 0.14634962, 0.16591516, 0.16645207,\n",
       "        0.12659431, 0.12912483, 0.16636648, 0.17517552, 0.22777696,\n",
       "        0.13472142, 0.13756146, 0.15553269, 0.1579072 , 0.16664162,\n",
       "        0.14033813, 0.14931073, 0.16978292, 0.19163718, 0.17297096,\n",
       "        0.12796254, 0.15719233, 0.14516654, 0.1585948 , 0.19114728,\n",
       "        0.13161516, 0.14661942, 0.18798256, 0.18055596, 0.21230206,\n",
       "        0.13371253, 0.14068246, 0.15781078, 0.21299381, 0.22126627,\n",
       "        0.13047199, 0.15460181, 0.21053929, 0.1749258 , 0.18284698,\n",
       "        0.13943052, 0.2072329 , 0.14681935, 0.16670637, 0.1587152 ,\n",
       "        0.1320847 , 0.13564172, 0.13855362, 0.15426593, 0.16533585,\n",
       "        0.12721777, 0.13773918, 0.15307083, 0.15856972, 0.16866913,\n",
       "        0.13232398, 0.12886224, 0.15484247, 0.24601746, 0.30269818,\n",
       "        0.15462527, 0.14574294, 0.14908433, 0.166641  , 0.18427525,\n",
       "        0.12715144, 0.12986693, 0.1376595 , 0.14159908, 0.17538023,\n",
       "        0.13399634, 0.14331789, 0.14406934, 0.18036394, 0.18470249,\n",
       "        0.13278785, 0.15628133, 0.1385273 , 0.16704655, 0.18045125,\n",
       "        0.12930317, 0.14039092, 0.13903151, 0.2458693 , 0.32025552,\n",
       "        0.1572762 , 0.21054869, 0.17477131, 0.16374249, 0.18609281,\n",
       "        0.13199959, 0.13364482, 0.14391379, 0.1977324 , 0.23001919,\n",
       "        0.12960863, 0.13942857, 0.14637756, 0.16180768, 0.30687394,\n",
       "        0.14574099, 0.20188503, 0.20293822, 0.2993166 , 0.27140293,\n",
       "        0.13080282, 0.16440282, 0.1419919 , 0.15129514, 0.19510422,\n",
       "        0.15984693, 0.1694531 , 0.15549974, 0.17735524, 0.18554502]),\n",
       " 'mean_score_time': array([0.11597285, 0.11593637, 0.10796533, 0.11892295, 0.1133172 ,\n",
       "        0.11279311, 0.10731401, 0.11596904, 0.11779723, 0.1197938 ,\n",
       "        0.10932984, 0.11596789, 0.11552505, 0.11017365, 0.10607076,\n",
       "        0.11559877, 0.11106482, 0.10958858, 0.11586742, 0.10641632,\n",
       "        0.11596313, 0.10716   , 0.11420965, 0.11173058, 0.12030487,\n",
       "        0.11674037, 0.1185884 , 0.11304245, 0.12159963, 0.1089828 ,\n",
       "        0.11514845, 0.11075253, 0.1202745 , 0.10932417, 0.11732349,\n",
       "        0.10801201, 0.11644311, 0.1156889 , 0.11598058, 0.12077956,\n",
       "        0.11593027, 0.11284742, 0.10735235, 0.11625896, 0.11432462,\n",
       "        0.11483698, 0.10888228, 0.11847196, 0.10620008, 0.11587052,\n",
       "        0.10697112, 0.1159904 , 0.11339817, 0.11853986, 0.11508255,\n",
       "        0.11943755, 0.11428695, 0.12191339, 0.10905976, 0.11219625,\n",
       "        0.11636128, 0.10982714, 0.11593642, 0.11092029, 0.11406569,\n",
       "        0.1097239 , 0.11326451, 0.11175232, 0.11715407, 0.11769519,\n",
       "        0.11084776, 0.11941638, 0.11931443, 0.13130436, 0.11565437,\n",
       "        0.10870657, 0.1165041 , 0.11106591, 0.12032871, 0.13224916,\n",
       "        0.11917114, 0.11957211, 0.11898866, 0.11797361, 0.12863955,\n",
       "        0.11283503, 0.11831064, 0.11706033, 0.11359544, 0.10709443,\n",
       "        0.11546464, 0.1073575 , 0.10937142, 0.10627837, 0.11754231,\n",
       "        0.11388865, 0.11664577, 0.11503215, 0.11589522, 0.10877657,\n",
       "        0.11479411, 0.10888724, 0.11909251, 0.11637163, 0.11172004,\n",
       "        0.11333494, 0.1114718 , 0.10672159, 0.1074049 , 0.11218247,\n",
       "        0.1134748 , 0.10638494, 0.11273904, 0.11416717, 0.11154895,\n",
       "        0.11588793, 0.11136832, 0.11717348, 0.11187625, 0.11745791,\n",
       "        0.11202173, 0.11468167, 0.11309023, 0.11410389, 0.11223984,\n",
       "        0.1170125 , 0.10900545, 0.11156383, 0.11227412, 0.11439772,\n",
       "        0.11240029, 0.11274829, 0.11351194, 0.1091291 , 0.1158287 ,\n",
       "        0.1113462 , 0.1162344 , 0.10778961, 0.11661425, 0.11606703,\n",
       "        0.11723161, 0.1139863 , 0.11717205, 0.11727476, 0.13014727,\n",
       "        0.11119943, 0.11779704, 0.10763755, 0.12472916, 0.12159128,\n",
       "        0.11586857, 0.12291741, 0.12786417, 0.1199677 , 0.12292295,\n",
       "        0.11514335, 0.11581173, 0.10834432, 0.11587753, 0.1143816 ,\n",
       "        0.11531577, 0.13954439, 0.11753273, 0.12493649, 0.12947807,\n",
       "        0.10816174, 0.1199017 , 0.1175478 , 0.13466339, 0.12011614,\n",
       "        0.1100184 , 0.14725137, 0.13246841, 0.11374397, 0.11138721,\n",
       "        0.16129622, 0.17298436, 0.11200871, 0.11204538, 0.11740942,\n",
       "        0.11825614, 0.11586599, 0.11556463, 0.11850157, 0.11456647,\n",
       "        0.11336045, 0.11963115, 0.11505251, 0.11716957, 0.12031894,\n",
       "        0.11854358, 0.10594778, 0.13184605, 0.19182262, 0.15691795,\n",
       "        0.12436643, 0.11008015, 0.12064829, 0.12528968, 0.12141724,\n",
       "        0.11234665, 0.11746168, 0.1104166 , 0.1150806 , 0.11490111,\n",
       "        0.11128478, 0.11639557, 0.11764212, 0.12039933, 0.1244163 ,\n",
       "        0.11308732, 0.12048712, 0.1175561 , 0.11919217, 0.11795216,\n",
       "        0.11183872, 0.11731091, 0.10823131, 0.14414678, 0.12766781,\n",
       "        0.13211279, 0.12653003, 0.12525134, 0.1065989 , 0.11207047,\n",
       "        0.11119924, 0.10552902, 0.11338067, 0.15589361, 0.13102603,\n",
       "        0.10730257, 0.11587048, 0.10770187, 0.11586528, 0.14791508,\n",
       "        0.14935751, 0.1361516 , 0.1191185 , 0.14240227, 0.1659524 ,\n",
       "        0.10882268, 0.12053785, 0.11008902, 0.11723161, 0.11792889,\n",
       "        0.11507907, 0.11703844, 0.11784587, 0.11806622, 0.1172852 ]),\n",
       " 'mean_test_score': array([0.9789916 , 0.98459384, 0.98459384, 0.98319328, 0.98459384,\n",
       "        0.98179272, 0.98739496, 0.98739496, 0.98739496, 0.9859944 ,\n",
       "        0.98179272, 0.9859944 , 0.98459384, 0.9859944 , 0.9859944 ,\n",
       "        0.98179272, 0.98179272, 0.9859944 , 0.98179272, 0.98179272,\n",
       "        0.9789916 , 0.98319328, 0.98319328, 0.9789916 , 0.98179272,\n",
       "        0.98039216, 0.98179272, 0.98319328, 0.9789916 , 0.9789916 ,\n",
       "        0.98039216, 0.98179272, 0.98319328, 0.9789916 , 0.9789916 ,\n",
       "        0.98039216, 0.98179272, 0.98319328, 0.9789916 , 0.9789916 ,\n",
       "        0.98319328, 0.98039216, 0.97759104, 0.97759104, 0.98039216,\n",
       "        0.9789916 , 0.98179272, 0.97759104, 0.97759104, 0.9789916 ,\n",
       "        0.97338936, 0.9789916 , 0.97759104, 0.9789916 , 0.9789916 ,\n",
       "        0.97338936, 0.9789916 , 0.97759104, 0.9789916 , 0.9789916 ,\n",
       "        0.97338936, 0.9789916 , 0.97759104, 0.9789916 , 0.9789916 ,\n",
       "        0.97338936, 0.9789916 , 0.97759104, 0.9789916 , 0.9789916 ,\n",
       "        0.97338936, 0.9789916 , 0.97759104, 0.9789916 , 0.9789916 ,\n",
       "        0.96498599, 0.97058824, 0.96918768, 0.97058824, 0.97058824,\n",
       "        0.96498599, 0.97058824, 0.96918768, 0.97058824, 0.97058824,\n",
       "        0.96498599, 0.97058824, 0.96918768, 0.97058824, 0.97058824,\n",
       "        0.96498599, 0.97058824, 0.96918768, 0.97058824, 0.97058824,\n",
       "        0.96498599, 0.97058824, 0.96918768, 0.97058824, 0.97058824,\n",
       "        0.96778711, 0.96638655, 0.96498599, 0.96498599, 0.96638655,\n",
       "        0.96778711, 0.96638655, 0.96498599, 0.96498599, 0.96638655,\n",
       "        0.96778711, 0.96638655, 0.96498599, 0.96498599, 0.96638655,\n",
       "        0.96778711, 0.96638655, 0.96498599, 0.96498599, 0.96638655,\n",
       "        0.96778711, 0.96638655, 0.96498599, 0.96498599, 0.96638655,\n",
       "        0.9789916 , 0.97619048, 0.98039216, 0.98039216, 0.98179272,\n",
       "        0.9789916 , 0.9789916 , 0.98459384, 0.98179272, 0.98459384,\n",
       "        0.98179272, 0.98179272, 0.98179272, 0.98459384, 0.98459384,\n",
       "        0.98179272, 0.98319328, 0.9859944 , 0.98459384, 0.98459384,\n",
       "        0.98179272, 0.98319328, 0.9859944 , 0.98319328, 0.9859944 ,\n",
       "        0.98039216, 0.97759104, 0.98039216, 0.98319328, 0.9789916 ,\n",
       "        0.98039216, 0.97759104, 0.98039216, 0.98319328, 0.9789916 ,\n",
       "        0.98039216, 0.97759104, 0.98039216, 0.98319328, 0.9789916 ,\n",
       "        0.9789916 , 0.98179272, 0.98179272, 0.98039216, 0.98179272,\n",
       "        0.98179272, 0.9789916 , 0.98039216, 0.98039216, 0.98319328,\n",
       "        0.97058824, 0.97619048, 0.9789916 , 0.9789916 , 0.98179272,\n",
       "        0.97058824, 0.97619048, 0.9789916 , 0.9789916 , 0.98179272,\n",
       "        0.97058824, 0.97619048, 0.9789916 , 0.9789916 , 0.98179272,\n",
       "        0.97058824, 0.97619048, 0.9789916 , 0.9789916 , 0.98179272,\n",
       "        0.97058824, 0.97619048, 0.9789916 , 0.9789916 , 0.98179272,\n",
       "        0.97058824, 0.9719888 , 0.9719888 , 0.97058824, 0.97619048,\n",
       "        0.97058824, 0.9719888 , 0.9719888 , 0.97058824, 0.97619048,\n",
       "        0.97058824, 0.9719888 , 0.9719888 , 0.97058824, 0.97619048,\n",
       "        0.97058824, 0.9719888 , 0.9719888 , 0.97058824, 0.97619048,\n",
       "        0.97058824, 0.9719888 , 0.9719888 , 0.97058824, 0.97619048,\n",
       "        0.96358543, 0.97058824, 0.96498599, 0.96638655, 0.96918768,\n",
       "        0.96358543, 0.97058824, 0.96498599, 0.96638655, 0.96918768,\n",
       "        0.96358543, 0.97058824, 0.96498599, 0.96638655, 0.96918768,\n",
       "        0.96358543, 0.97058824, 0.96498599, 0.96638655, 0.96918768,\n",
       "        0.96358543, 0.97058824, 0.96498599, 0.96638655, 0.96918768]),\n",
       " 'mean_train_score': array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.99965035, 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.99964912, 1.        , 0.99965035, 0.99965035, 1.        ,\n",
       "        0.99929947, 0.99964912, 0.99929947, 0.99965035, 0.99965035,\n",
       "        0.99929947, 0.99964912, 0.99929947, 0.99965035, 0.99965035,\n",
       "        0.99929947, 0.99964912, 0.99929947, 0.99965035, 0.99965035,\n",
       "        0.99929947, 0.99929947, 0.9993007 , 0.99965035, 0.9993007 ,\n",
       "        0.99929947, 0.99860017, 0.99825052, 0.99894982, 0.99860017,\n",
       "        0.99685069, 0.99615139, 0.99615139, 0.99650227, 0.99720157,\n",
       "        0.99685069, 0.99615139, 0.99615139, 0.99650227, 0.99720157,\n",
       "        0.99685069, 0.99580174, 0.99615139, 0.99650227, 0.99720157,\n",
       "        0.99685069, 0.99615139, 0.99615139, 0.99650227, 0.99720157,\n",
       "        0.99685069, 0.99615139, 0.99615139, 0.99650227, 0.99720157,\n",
       "        0.99089805, 0.9915949 , 0.99194332, 0.99264507, 0.99404736,\n",
       "        0.99089805, 0.9915949 , 0.99194332, 0.99264507, 0.99404736,\n",
       "        0.99089805, 0.9915949 , 0.99194332, 0.99264507, 0.99404736,\n",
       "        0.99089805, 0.9915949 , 0.99194332, 0.99264507, 0.99404736,\n",
       "        0.99089805, 0.9915949 , 0.99194332, 0.99264507, 0.99404736,\n",
       "        0.98774138, 0.98879401, 0.98984542, 0.99054349, 0.99124647,\n",
       "        0.98774138, 0.98879401, 0.98984542, 0.99054349, 0.99124647,\n",
       "        0.98774138, 0.98879401, 0.98984542, 0.99054349, 0.99124647,\n",
       "        0.98774138, 0.98879401, 0.98984542, 0.99054349, 0.99124647,\n",
       "        0.98774138, 0.98879401, 0.98984542, 0.99054349, 0.99124647,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.99964912, 0.99964912, 0.99929947, 1.        , 1.        ,\n",
       "        0.99929825, 0.99929947, 0.99964912, 1.        , 1.        ,\n",
       "        0.9989486 , 0.99929825, 0.99964912, 1.        , 1.        ,\n",
       "        0.99964912, 0.99964912, 0.99964912, 1.        , 1.        ,\n",
       "        0.99964912, 0.99964912, 0.99964912, 1.        , 1.        ,\n",
       "        0.99964912, 0.99964912, 0.99964912, 1.        , 1.        ,\n",
       "        0.99894737, 0.9989486 , 0.9989486 , 0.99964912, 1.        ,\n",
       "        0.99824684, 0.99824807, 0.99859772, 0.99929825, 0.99964912,\n",
       "        0.99439701, 0.99649859, 0.99684824, 0.99824929, 0.99860017,\n",
       "        0.99439701, 0.99649859, 0.99684824, 0.99824929, 0.99860017,\n",
       "        0.99439701, 0.99649859, 0.99684824, 0.99824929, 0.99860017,\n",
       "        0.99439701, 0.99649859, 0.99684824, 0.99824929, 0.99860017,\n",
       "        0.99439701, 0.99649859, 0.99684824, 0.99824929, 0.99860017,\n",
       "        0.99334806, 0.99089437, 0.99159367, 0.99334806, 0.99439946,\n",
       "        0.99334806, 0.99089437, 0.99159367, 0.99334806, 0.99439946,\n",
       "        0.99334806, 0.99089437, 0.99159367, 0.99334806, 0.99439946,\n",
       "        0.99334806, 0.99089437, 0.99159367, 0.99334806, 0.99439946,\n",
       "        0.99334806, 0.99089437, 0.99159367, 0.99334806, 0.99439946,\n",
       "        0.98985033, 0.99019875, 0.98879524, 0.9926463 , 0.99405104,\n",
       "        0.98985033, 0.99019875, 0.98879524, 0.9926463 , 0.99405104,\n",
       "        0.98985033, 0.99019875, 0.98879524, 0.9926463 , 0.99405104,\n",
       "        0.98985033, 0.99019875, 0.98879524, 0.9926463 , 0.99405104,\n",
       "        0.98985033, 0.99019875, 0.98879524, 0.9926463 , 0.99405104]),\n",
       " 'param_criterion': masked_array(data=['gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_leaf': masked_array(data=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "                    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3,\n",
       "                    3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "                    3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "                    4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "                    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3,\n",
       "                    3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "                    3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "                    4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_split': masked_array(data=[2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5,\n",
       "                    5, 5, 6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4,\n",
       "                    4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 2, 2, 2, 2,\n",
       "                    2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6,\n",
       "                    6, 6, 6, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
       "                    5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 3, 3, 3,\n",
       "                    3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 2,\n",
       "                    2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5,\n",
       "                    5, 6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4,\n",
       "                    4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 2, 2, 2, 2, 2,\n",
       "                    3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6,\n",
       "                    6, 6, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5,\n",
       "                    5, 5, 5, 5, 6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 3, 3, 3, 3,\n",
       "                    3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[10, 15, 20, 25, 30, 10, 15, 20, 25, 30, 10, 15, 20, 25,\n",
       "                    30, 10, 15, 20, 25, 30, 10, 15, 20, 25, 30, 10, 15, 20,\n",
       "                    25, 30, 10, 15, 20, 25, 30, 10, 15, 20, 25, 30, 10, 15,\n",
       "                    20, 25, 30, 10, 15, 20, 25, 30, 10, 15, 20, 25, 30, 10,\n",
       "                    15, 20, 25, 30, 10, 15, 20, 25, 30, 10, 15, 20, 25, 30,\n",
       "                    10, 15, 20, 25, 30, 10, 15, 20, 25, 30, 10, 15, 20, 25,\n",
       "                    30, 10, 15, 20, 25, 30, 10, 15, 20, 25, 30, 10, 15, 20,\n",
       "                    25, 30, 10, 15, 20, 25, 30, 10, 15, 20, 25, 30, 10, 15,\n",
       "                    20, 25, 30, 10, 15, 20, 25, 30, 10, 15, 20, 25, 30, 10,\n",
       "                    15, 20, 25, 30, 10, 15, 20, 25, 30, 10, 15, 20, 25, 30,\n",
       "                    10, 15, 20, 25, 30, 10, 15, 20, 25, 30, 10, 15, 20, 25,\n",
       "                    30, 10, 15, 20, 25, 30, 10, 15, 20, 25, 30, 10, 15, 20,\n",
       "                    25, 30, 10, 15, 20, 25, 30, 10, 15, 20, 25, 30, 10, 15,\n",
       "                    20, 25, 30, 10, 15, 20, 25, 30, 10, 15, 20, 25, 30, 10,\n",
       "                    15, 20, 25, 30, 10, 15, 20, 25, 30, 10, 15, 20, 25, 30,\n",
       "                    10, 15, 20, 25, 30, 10, 15, 20, 25, 30, 10, 15, 20, 25,\n",
       "                    30, 10, 15, 20, 25, 30, 10, 15, 20, 25, 30, 10, 15, 20,\n",
       "                    25, 30, 10, 15, 20, 25, 30, 10, 15, 20, 25, 30],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_jobs': masked_array(data=[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "                    -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "                    -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "                    -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "                    -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "                    -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "                    -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "                    -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "                    -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "                    -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "                    -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "                    -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "                    -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "                    -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "                    -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "                    -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "                    -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "                    -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'criterion': 'gini',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 15,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 25,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 30,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 10,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 15,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 20,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 25,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 30,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 10,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 15,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 20,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 25,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 30,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 15,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 25,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 30,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 10,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 15,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 20,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 25,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 30,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 15,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 25,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 30,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 10,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 15,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 20,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 25,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 30,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 10,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 15,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 20,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 25,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 30,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 15,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 25,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 30,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 10,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 15,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 20,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 25,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 30,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 15,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 25,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 30,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 10,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 15,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 20,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 25,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 30,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 10,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 15,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 20,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 25,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 30,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 15,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 25,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 30,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 10,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 15,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 20,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 25,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 30,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 15,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 25,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 30,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 10,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 15,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 20,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 25,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 30,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 10,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 15,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 20,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 25,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 30,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 15,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 25,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 30,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 10,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 15,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 20,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 25,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 30,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 15,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 25,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 30,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 10,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 15,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 20,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 25,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 30,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 10,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 15,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 20,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 25,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 30,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 15,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 25,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 30,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 10,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 15,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 20,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 25,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'gini',\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 30,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 15,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 25,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 30,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 10,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 15,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 20,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 25,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 30,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 10,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 15,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 20,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 25,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 30,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 15,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 25,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 30,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 10,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 15,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 20,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 25,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 30,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 15,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 25,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 30,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 10,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 15,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 20,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 25,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 30,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 10,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 15,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 20,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 25,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 30,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 15,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 25,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 30,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 10,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 15,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 20,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 25,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 30,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 15,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 25,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 30,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 10,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 15,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 20,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 25,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 30,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 10,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 15,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 20,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 25,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 30,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 15,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 25,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 30,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 10,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 15,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 20,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 25,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 30,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 15,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 25,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 30,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 10,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 15,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 20,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 25,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 30,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 10,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 15,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 20,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 25,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 30,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 15,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 25,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 30,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 10,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 15,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 20,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 25,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 4,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 30,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 15,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 25,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 30,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 10,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 15,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 20,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 25,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 30,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 10,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 15,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 20,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 25,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 30,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 15,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 25,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 30,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 10,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 15,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 20,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 25,\n",
       "   'n_jobs': -1},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 6,\n",
       "   'n_estimators': 30,\n",
       "   'n_jobs': -1}],\n",
       " 'rank_test_score': array([ 79,  12,  12,  22,  12,  36,   1,   1,   1,   4,  36,   4,  12,\n",
       "          4,   4,  36,  36,   4,  36,  36,  79,  22,  22,  79,  36,  63,\n",
       "         36,  22,  79,  79,  63,  36,  22,  79,  79,  63,  36,  22,  79,\n",
       "         79,  22,  63, 123, 123,  63,  79,  36, 123, 123,  79, 146,  79,\n",
       "        123,  79,  79, 146,  79, 123,  79,  79, 146,  79, 123,  79,  79,\n",
       "        146,  79, 123,  79,  79, 146,  79, 123,  79,  79, 226, 161, 196,\n",
       "        161, 161, 226, 161, 196, 161, 161, 226, 161, 196, 161, 161, 226,\n",
       "        161, 196, 161, 161, 226, 161, 196, 161, 161, 206, 211, 226, 226,\n",
       "        211, 206, 211, 226, 226, 211, 206, 211, 226, 226, 211, 206, 211,\n",
       "        226, 226, 211, 206, 211, 226, 226, 211,  79, 135,  63,  63,  36,\n",
       "         79,  79,  12,  36,  12,  36,  36,  36,  12,  12,  36,  22,   4,\n",
       "         12,  12,  36,  22,   4,  22,   4,  63, 123,  63,  22,  79,  63,\n",
       "        123,  63,  22,  79,  63, 123,  63,  22,  79,  79,  36,  36,  63,\n",
       "         36,  36,  79,  63,  63,  22, 161, 135,  79,  79,  36, 161, 135,\n",
       "         79,  79,  36, 161, 135,  79,  79,  36, 161, 135,  79,  79,  36,\n",
       "        161, 135,  79,  79,  36, 161, 151, 151, 161, 135, 161, 151, 151,\n",
       "        161, 135, 161, 151, 151, 161, 135, 161, 151, 151, 161, 135, 161,\n",
       "        151, 151, 161, 135, 246, 161, 226, 211, 196, 246, 161, 226, 211,\n",
       "        196, 246, 161, 226, 211, 196, 246, 161, 226, 211, 196, 246, 161,\n",
       "        226, 211, 196]),\n",
       " 'split0_test_score': array([0.96527778, 0.97222222, 0.97222222, 0.96527778, 0.96527778,\n",
       "        0.97222222, 0.97916667, 0.97222222, 0.97222222, 0.96527778,\n",
       "        0.97222222, 0.97916667, 0.96527778, 0.97222222, 0.96527778,\n",
       "        0.97222222, 0.97916667, 0.97916667, 0.96527778, 0.95833333,\n",
       "        0.96527778, 0.97916667, 0.96527778, 0.95833333, 0.96527778,\n",
       "        0.96527778, 0.97222222, 0.97222222, 0.95833333, 0.95833333,\n",
       "        0.96527778, 0.97222222, 0.97222222, 0.95833333, 0.95833333,\n",
       "        0.96527778, 0.97222222, 0.97222222, 0.95833333, 0.95833333,\n",
       "        0.97222222, 0.96527778, 0.95138889, 0.95138889, 0.95138889,\n",
       "        0.95833333, 0.97222222, 0.95833333, 0.95833333, 0.95833333,\n",
       "        0.94444444, 0.96527778, 0.96527778, 0.97222222, 0.97222222,\n",
       "        0.94444444, 0.96527778, 0.96527778, 0.97222222, 0.97222222,\n",
       "        0.94444444, 0.96527778, 0.96527778, 0.97222222, 0.97222222,\n",
       "        0.94444444, 0.96527778, 0.96527778, 0.97222222, 0.97222222,\n",
       "        0.94444444, 0.96527778, 0.96527778, 0.97222222, 0.97222222,\n",
       "        0.94444444, 0.95833333, 0.95138889, 0.95138889, 0.94444444,\n",
       "        0.94444444, 0.95833333, 0.95138889, 0.95138889, 0.94444444,\n",
       "        0.94444444, 0.95833333, 0.95138889, 0.95138889, 0.94444444,\n",
       "        0.94444444, 0.95833333, 0.95138889, 0.95138889, 0.94444444,\n",
       "        0.94444444, 0.95833333, 0.95138889, 0.95138889, 0.94444444,\n",
       "        0.94444444, 0.9375    , 0.9375    , 0.94444444, 0.9375    ,\n",
       "        0.94444444, 0.9375    , 0.9375    , 0.94444444, 0.9375    ,\n",
       "        0.94444444, 0.9375    , 0.9375    , 0.94444444, 0.9375    ,\n",
       "        0.94444444, 0.9375    , 0.9375    , 0.94444444, 0.9375    ,\n",
       "        0.94444444, 0.9375    , 0.9375    , 0.94444444, 0.9375    ,\n",
       "        0.96527778, 0.96527778, 0.96527778, 0.96527778, 0.95833333,\n",
       "        0.97916667, 0.96527778, 0.97916667, 0.97222222, 0.97916667,\n",
       "        0.97916667, 0.97222222, 0.97916667, 0.97916667, 0.97916667,\n",
       "        0.95833333, 0.97916667, 0.97916667, 0.97916667, 0.97916667,\n",
       "        0.96527778, 0.97916667, 0.97916667, 0.97222222, 0.97916667,\n",
       "        0.97222222, 0.97222222, 0.97916667, 0.97916667, 0.96527778,\n",
       "        0.97222222, 0.97222222, 0.97916667, 0.97916667, 0.96527778,\n",
       "        0.97222222, 0.97222222, 0.97916667, 0.97916667, 0.96527778,\n",
       "        0.95833333, 0.97916667, 0.96527778, 0.95833333, 0.96527778,\n",
       "        0.97222222, 0.96527778, 0.97222222, 0.95833333, 0.96527778,\n",
       "        0.95138889, 0.96527778, 0.95833333, 0.95833333, 0.96527778,\n",
       "        0.95138889, 0.96527778, 0.95833333, 0.95833333, 0.96527778,\n",
       "        0.95138889, 0.96527778, 0.95833333, 0.95833333, 0.96527778,\n",
       "        0.95138889, 0.96527778, 0.95833333, 0.95833333, 0.96527778,\n",
       "        0.95138889, 0.96527778, 0.95833333, 0.95833333, 0.96527778,\n",
       "        0.9375    , 0.95833333, 0.95833333, 0.95138889, 0.96527778,\n",
       "        0.9375    , 0.95833333, 0.95833333, 0.95138889, 0.96527778,\n",
       "        0.9375    , 0.95833333, 0.95833333, 0.95138889, 0.96527778,\n",
       "        0.9375    , 0.95833333, 0.95833333, 0.95138889, 0.96527778,\n",
       "        0.9375    , 0.95833333, 0.95833333, 0.95138889, 0.96527778,\n",
       "        0.95833333, 0.96527778, 0.95138889, 0.94444444, 0.94444444,\n",
       "        0.95833333, 0.96527778, 0.95138889, 0.94444444, 0.94444444,\n",
       "        0.95833333, 0.96527778, 0.95138889, 0.94444444, 0.94444444,\n",
       "        0.95833333, 0.96527778, 0.95138889, 0.94444444, 0.94444444,\n",
       "        0.95833333, 0.96527778, 0.95138889, 0.94444444, 0.94444444]),\n",
       " 'split0_train_score': array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.99824561, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.99824561, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.99824561, 0.99824561, 1.        , 1.        , 1.        ,\n",
       "        0.99824561, 0.99824561, 1.        , 1.        , 1.        ,\n",
       "        0.99824561, 0.99824561, 1.        , 1.        , 1.        ,\n",
       "        0.99824561, 0.99824561, 1.        , 1.        , 1.        ,\n",
       "        0.99824561, 0.99824561, 1.        , 1.        , 1.        ,\n",
       "        0.99122807, 0.9877193 , 0.98596491, 0.98947368, 0.99473684,\n",
       "        0.99122807, 0.9877193 , 0.98596491, 0.98947368, 0.99473684,\n",
       "        0.99122807, 0.9877193 , 0.98596491, 0.98947368, 0.99473684,\n",
       "        0.99122807, 0.9877193 , 0.98596491, 0.98947368, 0.99473684,\n",
       "        0.99122807, 0.9877193 , 0.98596491, 0.98947368, 0.99473684,\n",
       "        0.98070175, 0.98421053, 0.98596491, 0.98421053, 0.98947368,\n",
       "        0.98070175, 0.98421053, 0.98596491, 0.98421053, 0.98947368,\n",
       "        0.98070175, 0.98421053, 0.98596491, 0.98421053, 0.98947368,\n",
       "        0.98070175, 0.98421053, 0.98596491, 0.98421053, 0.98947368,\n",
       "        0.98070175, 0.98421053, 0.98596491, 0.98421053, 0.98947368,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.99824561, 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.99824561, 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.99824561, 0.99824561, 0.99824561, 1.        , 1.        ,\n",
       "        0.99824561, 0.99824561, 0.99824561, 1.        , 1.        ,\n",
       "        0.99824561, 0.99824561, 0.99824561, 1.        , 1.        ,\n",
       "        0.99824561, 0.99824561, 0.99824561, 0.99824561, 1.        ,\n",
       "        0.99824561, 0.99824561, 0.99824561, 0.99824561, 0.99824561,\n",
       "        0.99298246, 0.99824561, 0.99649123, 0.99824561, 0.99824561,\n",
       "        0.99298246, 0.99824561, 0.99649123, 0.99824561, 0.99824561,\n",
       "        0.99298246, 0.99824561, 0.99649123, 0.99824561, 0.99824561,\n",
       "        0.99298246, 0.99824561, 0.99649123, 0.99824561, 0.99824561,\n",
       "        0.99298246, 0.99824561, 0.99649123, 0.99824561, 0.99824561,\n",
       "        0.99298246, 0.9877193 , 0.98947368, 0.99649123, 0.99473684,\n",
       "        0.99298246, 0.9877193 , 0.98947368, 0.99649123, 0.99473684,\n",
       "        0.99298246, 0.9877193 , 0.98947368, 0.99649123, 0.99473684,\n",
       "        0.99298246, 0.9877193 , 0.98947368, 0.99649123, 0.99473684,\n",
       "        0.99298246, 0.9877193 , 0.98947368, 0.99649123, 0.99473684,\n",
       "        0.99473684, 0.99473684, 0.9877193 , 0.99298246, 0.99824561,\n",
       "        0.99473684, 0.99473684, 0.9877193 , 0.99298246, 0.99824561,\n",
       "        0.99473684, 0.99473684, 0.9877193 , 0.99298246, 0.99824561,\n",
       "        0.99473684, 0.99473684, 0.9877193 , 0.99298246, 0.99824561,\n",
       "        0.99473684, 0.99473684, 0.9877193 , 0.99298246, 0.99824561]),\n",
       " 'split1_test_score': array([0.99305556, 0.98611111, 0.98611111, 0.98611111, 0.98611111,\n",
       "        0.98611111, 0.98611111, 0.98611111, 0.98611111, 0.98611111,\n",
       "        0.98611111, 0.98611111, 0.98611111, 0.98611111, 0.98611111,\n",
       "        0.98611111, 0.97916667, 0.98611111, 0.98611111, 0.98611111,\n",
       "        0.97916667, 0.98611111, 0.98611111, 0.98611111, 0.98611111,\n",
       "        0.98611111, 0.98611111, 0.98611111, 0.98611111, 0.98611111,\n",
       "        0.98611111, 0.98611111, 0.98611111, 0.98611111, 0.98611111,\n",
       "        0.98611111, 0.98611111, 0.98611111, 0.98611111, 0.98611111,\n",
       "        0.98611111, 0.98611111, 0.98611111, 0.98611111, 0.99305556,\n",
       "        0.99305556, 0.98611111, 0.98611111, 0.98611111, 0.99305556,\n",
       "        0.99305556, 0.98611111, 0.98611111, 0.98611111, 0.98611111,\n",
       "        0.99305556, 0.98611111, 0.98611111, 0.98611111, 0.98611111,\n",
       "        0.99305556, 0.98611111, 0.98611111, 0.98611111, 0.98611111,\n",
       "        0.99305556, 0.98611111, 0.98611111, 0.98611111, 0.98611111,\n",
       "        0.99305556, 0.98611111, 0.98611111, 0.98611111, 0.98611111,\n",
       "        0.97222222, 0.97222222, 0.97916667, 0.97916667, 0.97916667,\n",
       "        0.97222222, 0.97222222, 0.97916667, 0.97916667, 0.97916667,\n",
       "        0.97222222, 0.97222222, 0.97916667, 0.97916667, 0.97916667,\n",
       "        0.97222222, 0.97222222, 0.97916667, 0.97916667, 0.97916667,\n",
       "        0.97222222, 0.97222222, 0.97916667, 0.97916667, 0.97916667,\n",
       "        0.97916667, 0.97916667, 0.97916667, 0.97916667, 0.97916667,\n",
       "        0.97916667, 0.97916667, 0.97916667, 0.97916667, 0.97916667,\n",
       "        0.97916667, 0.97916667, 0.97916667, 0.97916667, 0.97916667,\n",
       "        0.97916667, 0.97916667, 0.97916667, 0.97916667, 0.97916667,\n",
       "        0.97916667, 0.97916667, 0.97916667, 0.97916667, 0.97916667,\n",
       "        0.98611111, 0.97916667, 0.98611111, 0.98611111, 0.98611111,\n",
       "        0.97222222, 0.97916667, 0.98611111, 0.98611111, 0.98611111,\n",
       "        0.98611111, 0.99305556, 0.98611111, 0.99305556, 0.99305556,\n",
       "        0.98611111, 0.99305556, 0.99305556, 0.99305556, 0.99305556,\n",
       "        0.99305556, 0.99305556, 0.99305556, 0.98611111, 0.99305556,\n",
       "        0.97916667, 0.98611111, 0.98611111, 0.99305556, 0.99305556,\n",
       "        0.97916667, 0.98611111, 0.98611111, 0.99305556, 0.99305556,\n",
       "        0.97916667, 0.98611111, 0.98611111, 0.99305556, 0.99305556,\n",
       "        0.98611111, 0.99305556, 0.99305556, 0.99305556, 0.99305556,\n",
       "        0.99305556, 0.99305556, 0.99305556, 0.99305556, 0.99305556,\n",
       "        0.99305556, 0.99305556, 0.99305556, 0.99305556, 0.99305556,\n",
       "        0.99305556, 0.99305556, 0.99305556, 0.99305556, 0.99305556,\n",
       "        0.99305556, 0.99305556, 0.99305556, 0.99305556, 0.99305556,\n",
       "        0.99305556, 0.99305556, 0.99305556, 0.99305556, 0.99305556,\n",
       "        0.99305556, 0.99305556, 0.99305556, 0.99305556, 0.99305556,\n",
       "        0.99305556, 0.97916667, 0.97916667, 0.97916667, 0.98611111,\n",
       "        0.99305556, 0.97916667, 0.97916667, 0.97916667, 0.98611111,\n",
       "        0.99305556, 0.97916667, 0.97916667, 0.97916667, 0.98611111,\n",
       "        0.99305556, 0.97916667, 0.97916667, 0.97916667, 0.98611111,\n",
       "        0.99305556, 0.97916667, 0.97916667, 0.97916667, 0.98611111,\n",
       "        0.97916667, 0.97916667, 0.97916667, 0.97916667, 0.97916667,\n",
       "        0.97916667, 0.97916667, 0.97916667, 0.97916667, 0.97916667,\n",
       "        0.97916667, 0.97916667, 0.97916667, 0.97916667, 0.97916667,\n",
       "        0.97916667, 0.97916667, 0.97916667, 0.97916667, 0.97916667,\n",
       "        0.97916667, 0.97916667, 0.97916667, 0.97916667, 0.97916667]),\n",
       " 'split1_train_score': array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.99824561, 0.99824561, 0.99824561, 1.        , 1.        ,\n",
       "        0.99824561, 0.99824561, 0.99824561, 1.        , 1.        ,\n",
       "        0.99824561, 0.99824561, 0.99824561, 1.        , 1.        ,\n",
       "        1.        , 0.99824561, 1.        , 1.        , 1.        ,\n",
       "        0.99824561, 0.99824561, 0.99824561, 0.99824561, 0.99824561,\n",
       "        0.99824561, 0.99824561, 0.99649123, 0.99824561, 0.99824561,\n",
       "        0.99824561, 0.99824561, 0.99649123, 0.99824561, 0.99824561,\n",
       "        0.99824561, 0.99824561, 0.99649123, 0.99824561, 0.99824561,\n",
       "        0.99824561, 0.99824561, 0.99649123, 0.99824561, 0.99824561,\n",
       "        0.99824561, 0.99824561, 0.99649123, 0.99824561, 0.99824561,\n",
       "        0.99298246, 0.99298246, 0.99298246, 0.99298246, 0.99298246,\n",
       "        0.99298246, 0.99298246, 0.99298246, 0.99298246, 0.99298246,\n",
       "        0.99298246, 0.99298246, 0.99298246, 0.99298246, 0.99298246,\n",
       "        0.99298246, 0.99298246, 0.99298246, 0.99298246, 0.99298246,\n",
       "        0.99298246, 0.99298246, 0.99298246, 0.99298246, 0.99298246,\n",
       "        0.98947368, 0.99122807, 0.99298246, 0.99298246, 0.99298246,\n",
       "        0.98947368, 0.99122807, 0.99298246, 0.99298246, 0.99298246,\n",
       "        0.98947368, 0.99122807, 0.99298246, 0.99298246, 0.99298246,\n",
       "        0.98947368, 0.99122807, 0.99298246, 0.99298246, 0.99298246,\n",
       "        0.98947368, 0.99122807, 0.99298246, 0.99298246, 0.99298246,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.99824561, 0.99824561, 0.99824561, 1.        , 1.        ,\n",
       "        0.99824561, 0.99824561, 0.99824561, 1.        , 1.        ,\n",
       "        0.99824561, 0.99649123, 0.99824561, 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.99649123, 0.99824561, 0.99824561, 1.        , 1.        ,\n",
       "        0.99473684, 0.99649123, 0.99649123, 0.99824561, 1.        ,\n",
       "        0.99473684, 0.99473684, 0.99649123, 0.99824561, 1.        ,\n",
       "        0.99473684, 0.99473684, 0.99649123, 0.99824561, 1.        ,\n",
       "        0.99473684, 0.99473684, 0.99649123, 0.99824561, 1.        ,\n",
       "        0.99473684, 0.99473684, 0.99649123, 0.99824561, 1.        ,\n",
       "        0.99473684, 0.99473684, 0.99649123, 0.99824561, 1.        ,\n",
       "        0.99473684, 0.99122807, 0.98947368, 0.99122807, 0.99649123,\n",
       "        0.99473684, 0.99122807, 0.98947368, 0.99122807, 0.99649123,\n",
       "        0.99473684, 0.99122807, 0.98947368, 0.99122807, 0.99649123,\n",
       "        0.99473684, 0.99122807, 0.98947368, 0.99122807, 0.99649123,\n",
       "        0.99473684, 0.99122807, 0.98947368, 0.99122807, 0.99649123,\n",
       "        0.99122807, 0.98947368, 0.98947368, 0.99122807, 0.99473684,\n",
       "        0.99122807, 0.98947368, 0.98947368, 0.99122807, 0.99473684,\n",
       "        0.99122807, 0.98947368, 0.98947368, 0.99122807, 0.99473684,\n",
       "        0.99122807, 0.98947368, 0.98947368, 0.99122807, 0.99473684,\n",
       "        0.99122807, 0.98947368, 0.98947368, 0.99122807, 0.99473684]),\n",
       " 'split2_test_score': array([0.97887324, 0.97887324, 0.98591549, 0.98591549, 0.98591549,\n",
       "        0.97887324, 0.98591549, 0.99295775, 0.99295775, 0.99295775,\n",
       "        0.97887324, 0.98591549, 0.98591549, 0.99295775, 0.99295775,\n",
       "        0.97183099, 0.97183099, 0.97887324, 0.97183099, 0.97887324,\n",
       "        0.97183099, 0.97183099, 0.97887324, 0.97183099, 0.97887324,\n",
       "        0.97887324, 0.97183099, 0.97183099, 0.97183099, 0.97183099,\n",
       "        0.97887324, 0.97183099, 0.97183099, 0.97183099, 0.97183099,\n",
       "        0.97887324, 0.97183099, 0.97183099, 0.97183099, 0.97183099,\n",
       "        0.97887324, 0.97183099, 0.97183099, 0.97183099, 0.97183099,\n",
       "        0.97887324, 0.97887324, 0.97183099, 0.97183099, 0.97183099,\n",
       "        0.97183099, 0.98591549, 0.97887324, 0.97887324, 0.97887324,\n",
       "        0.97183099, 0.98591549, 0.97887324, 0.97887324, 0.97887324,\n",
       "        0.97183099, 0.98591549, 0.97887324, 0.97887324, 0.97887324,\n",
       "        0.97183099, 0.98591549, 0.97887324, 0.97887324, 0.97887324,\n",
       "        0.97183099, 0.98591549, 0.97887324, 0.97887324, 0.97887324,\n",
       "        0.97183099, 0.97887324, 0.97887324, 0.97887324, 0.97887324,\n",
       "        0.97183099, 0.97887324, 0.97887324, 0.97887324, 0.97887324,\n",
       "        0.97183099, 0.97887324, 0.97887324, 0.97887324, 0.97887324,\n",
       "        0.97183099, 0.97887324, 0.97887324, 0.97887324, 0.97887324,\n",
       "        0.97183099, 0.97887324, 0.97887324, 0.97887324, 0.97887324,\n",
       "        0.97887324, 0.97887324, 0.97887324, 0.97887324, 0.97887324,\n",
       "        0.97887324, 0.97887324, 0.97887324, 0.97887324, 0.97887324,\n",
       "        0.97887324, 0.97887324, 0.97887324, 0.97887324, 0.97887324,\n",
       "        0.97887324, 0.97887324, 0.97887324, 0.97887324, 0.97887324,\n",
       "        0.97887324, 0.97887324, 0.97887324, 0.97887324, 0.97887324,\n",
       "        0.97183099, 0.97183099, 0.97887324, 0.97887324, 0.98591549,\n",
       "        0.97183099, 0.98591549, 0.98591549, 0.98591549, 0.98591549,\n",
       "        0.97183099, 0.98591549, 0.97887324, 0.98591549, 0.98591549,\n",
       "        0.99295775, 0.98591549, 0.98591549, 0.98591549, 0.98591549,\n",
       "        0.98591549, 0.97887324, 0.98591549, 0.98591549, 0.98591549,\n",
       "        0.97887324, 0.97183099, 0.97183099, 0.97887324, 0.97887324,\n",
       "        0.97887324, 0.97183099, 0.97183099, 0.97887324, 0.97887324,\n",
       "        0.97887324, 0.97183099, 0.97183099, 0.97887324, 0.97887324,\n",
       "        0.98591549, 0.97887324, 0.98591549, 0.98591549, 0.98591549,\n",
       "        0.98591549, 0.97887324, 0.97887324, 0.98591549, 0.98591549,\n",
       "        0.98591549, 0.97183099, 0.97887324, 0.97887324, 0.98591549,\n",
       "        0.98591549, 0.97183099, 0.97887324, 0.97887324, 0.98591549,\n",
       "        0.98591549, 0.97183099, 0.97887324, 0.97887324, 0.98591549,\n",
       "        0.98591549, 0.97183099, 0.97887324, 0.97887324, 0.98591549,\n",
       "        0.98591549, 0.97183099, 0.97887324, 0.97887324, 0.98591549,\n",
       "        0.98591549, 0.97887324, 0.97887324, 0.97183099, 0.97887324,\n",
       "        0.98591549, 0.97887324, 0.97887324, 0.97183099, 0.97887324,\n",
       "        0.98591549, 0.97887324, 0.97887324, 0.97183099, 0.97887324,\n",
       "        0.98591549, 0.97887324, 0.97887324, 0.97183099, 0.97887324,\n",
       "        0.98591549, 0.97887324, 0.97887324, 0.97183099, 0.97887324,\n",
       "        0.95774648, 0.97183099, 0.96478873, 0.97183099, 0.97183099,\n",
       "        0.95774648, 0.97183099, 0.96478873, 0.97183099, 0.97183099,\n",
       "        0.95774648, 0.97183099, 0.96478873, 0.97183099, 0.97183099,\n",
       "        0.95774648, 0.97183099, 0.96478873, 0.97183099, 0.97183099,\n",
       "        0.95774648, 0.97183099, 0.96478873, 0.97183099, 0.97183099]),\n",
       " 'split2_train_score': array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.99825175, 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.99825175, 0.99825175, 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.99825175, 0.99825175, 0.99825175,\n",
       "        1.        , 1.        , 0.99825175, 1.        , 1.        ,\n",
       "        0.99300699, 0.99475524, 0.99300699, 0.99300699, 0.99300699,\n",
       "        0.99300699, 0.99475524, 0.99300699, 0.99300699, 0.99300699,\n",
       "        0.99300699, 0.99300699, 0.99300699, 0.99300699, 0.99300699,\n",
       "        0.99300699, 0.99475524, 0.99300699, 0.99300699, 0.99300699,\n",
       "        0.99300699, 0.99475524, 0.99300699, 0.99300699, 0.99300699,\n",
       "        0.98776224, 0.98951049, 0.99125874, 0.99125874, 0.99300699,\n",
       "        0.98776224, 0.98951049, 0.99125874, 0.99125874, 0.99300699,\n",
       "        0.98776224, 0.98951049, 0.99125874, 0.99125874, 0.99300699,\n",
       "        0.98776224, 0.98951049, 0.99125874, 0.99125874, 0.99300699,\n",
       "        0.98776224, 0.98951049, 0.99125874, 0.99125874, 0.99300699,\n",
       "        0.98776224, 0.98776224, 0.98951049, 0.99125874, 0.99125874,\n",
       "        0.98776224, 0.98776224, 0.98951049, 0.99125874, 0.99125874,\n",
       "        0.98776224, 0.98776224, 0.98951049, 0.99125874, 0.99125874,\n",
       "        0.98776224, 0.98776224, 0.98951049, 0.99125874, 0.99125874,\n",
       "        0.98776224, 0.98776224, 0.98951049, 0.99125874, 0.99125874,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.99825175, 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.99825175, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.99825175, 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.99300699, 0.99475524, 0.99825175, 1.        , 0.99825175,\n",
       "        0.99300699, 0.99475524, 0.99825175, 1.        , 0.99825175,\n",
       "        0.99300699, 0.99475524, 0.99825175, 1.        , 0.99825175,\n",
       "        0.99300699, 0.99475524, 0.99825175, 1.        , 0.99825175,\n",
       "        0.99300699, 0.99475524, 0.99825175, 1.        , 0.99825175,\n",
       "        0.98951049, 0.99125874, 0.98951049, 0.99300699, 0.99300699,\n",
       "        0.98951049, 0.99125874, 0.98951049, 0.99300699, 0.99300699,\n",
       "        0.98951049, 0.99125874, 0.98951049, 0.99300699, 0.99300699,\n",
       "        0.98951049, 0.99125874, 0.98951049, 0.99300699, 0.99300699,\n",
       "        0.98951049, 0.99125874, 0.98951049, 0.99300699, 0.99300699,\n",
       "        0.98426573, 0.98951049, 0.99125874, 0.99475524, 0.99300699,\n",
       "        0.98426573, 0.98951049, 0.99125874, 0.99475524, 0.99300699,\n",
       "        0.98426573, 0.98951049, 0.99125874, 0.99475524, 0.99300699,\n",
       "        0.98426573, 0.98951049, 0.99125874, 0.99475524, 0.99300699,\n",
       "        0.98426573, 0.98951049, 0.99125874, 0.99475524, 0.99300699]),\n",
       " 'split3_test_score': array([0.97887324, 0.99295775, 0.99295775, 0.99295775, 0.99295775,\n",
       "        0.97887324, 0.99295775, 0.99295775, 0.99295775, 0.99295775,\n",
       "        0.97887324, 0.99295775, 0.99295775, 0.98591549, 0.99295775,\n",
       "        0.98591549, 0.98591549, 0.99295775, 0.99295775, 0.99295775,\n",
       "        0.98591549, 0.98591549, 0.99295775, 0.98591549, 0.98591549,\n",
       "        0.97887324, 0.99295775, 0.99295775, 0.98591549, 0.98591549,\n",
       "        0.97887324, 0.99295775, 0.99295775, 0.98591549, 0.98591549,\n",
       "        0.97887324, 0.99295775, 0.99295775, 0.98591549, 0.98591549,\n",
       "        0.98591549, 0.98591549, 0.98591549, 0.98591549, 0.99295775,\n",
       "        0.97183099, 0.97887324, 0.97887324, 0.98591549, 0.98591549,\n",
       "        0.96478873, 0.97887324, 0.97887324, 0.98591549, 0.98591549,\n",
       "        0.96478873, 0.97887324, 0.97887324, 0.98591549, 0.98591549,\n",
       "        0.96478873, 0.97887324, 0.97887324, 0.98591549, 0.98591549,\n",
       "        0.96478873, 0.97887324, 0.97887324, 0.98591549, 0.98591549,\n",
       "        0.96478873, 0.97887324, 0.97887324, 0.98591549, 0.98591549,\n",
       "        0.95774648, 0.96478873, 0.95774648, 0.96478873, 0.97887324,\n",
       "        0.95774648, 0.96478873, 0.95774648, 0.96478873, 0.97887324,\n",
       "        0.95774648, 0.96478873, 0.95774648, 0.96478873, 0.97887324,\n",
       "        0.95774648, 0.96478873, 0.95774648, 0.96478873, 0.97887324,\n",
       "        0.95774648, 0.96478873, 0.95774648, 0.96478873, 0.97887324,\n",
       "        0.95774648, 0.95774648, 0.95774648, 0.95070423, 0.95774648,\n",
       "        0.95774648, 0.95774648, 0.95774648, 0.95070423, 0.95774648,\n",
       "        0.95774648, 0.95774648, 0.95774648, 0.95070423, 0.95774648,\n",
       "        0.95774648, 0.95774648, 0.95774648, 0.95070423, 0.95774648,\n",
       "        0.95774648, 0.95774648, 0.95774648, 0.95070423, 0.95774648,\n",
       "        0.98591549, 0.98591549, 0.99295775, 0.99295775, 0.99295775,\n",
       "        0.98591549, 0.98591549, 0.99295775, 0.98591549, 0.99295775,\n",
       "        0.98591549, 0.97887324, 0.98591549, 0.98591549, 0.98591549,\n",
       "        0.98591549, 0.97887324, 0.99295775, 0.98591549, 0.98591549,\n",
       "        0.98591549, 0.98591549, 0.99295775, 0.99295775, 0.98591549,\n",
       "        0.98591549, 0.97887324, 0.98591549, 0.98591549, 0.98591549,\n",
       "        0.98591549, 0.97887324, 0.98591549, 0.98591549, 0.98591549,\n",
       "        0.98591549, 0.97887324, 0.98591549, 0.98591549, 0.98591549,\n",
       "        0.97887324, 0.97887324, 0.98591549, 0.98591549, 0.98591549,\n",
       "        0.97887324, 0.97887324, 0.98591549, 0.98591549, 0.98591549,\n",
       "        0.95070423, 0.97887324, 0.98591549, 0.98591549, 0.98591549,\n",
       "        0.95070423, 0.97887324, 0.98591549, 0.98591549, 0.98591549,\n",
       "        0.95070423, 0.97887324, 0.98591549, 0.98591549, 0.98591549,\n",
       "        0.95070423, 0.97887324, 0.98591549, 0.98591549, 0.98591549,\n",
       "        0.95070423, 0.97887324, 0.98591549, 0.98591549, 0.98591549,\n",
       "        0.96478873, 0.95774648, 0.96478873, 0.97887324, 0.97887324,\n",
       "        0.96478873, 0.95774648, 0.96478873, 0.97887324, 0.97887324,\n",
       "        0.96478873, 0.95774648, 0.96478873, 0.97887324, 0.97887324,\n",
       "        0.96478873, 0.95774648, 0.96478873, 0.97887324, 0.97887324,\n",
       "        0.96478873, 0.95774648, 0.96478873, 0.97887324, 0.97887324,\n",
       "        0.95070423, 0.96478873, 0.95774648, 0.96478873, 0.97887324,\n",
       "        0.95070423, 0.96478873, 0.95774648, 0.96478873, 0.97887324,\n",
       "        0.95070423, 0.96478873, 0.95774648, 0.96478873, 0.97887324,\n",
       "        0.95070423, 0.96478873, 0.95774648, 0.96478873, 0.97887324,\n",
       "        0.95070423, 0.96478873, 0.95774648, 0.96478873, 0.97887324]),\n",
       " 'split3_train_score': array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.99825175, 1.        , 1.        , 0.99825175, 0.99825175,\n",
       "        0.99825175, 1.        , 1.        , 0.99825175, 0.99825175,\n",
       "        0.99825175, 1.        , 1.        , 0.99825175, 0.99825175,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 0.9965035 , 0.9965035 , 1.        , 1.        ,\n",
       "        0.9965035 , 0.99475524, 0.9965035 , 0.9965035 , 1.        ,\n",
       "        0.9965035 , 0.99475524, 0.9965035 , 0.9965035 , 1.        ,\n",
       "        0.9965035 , 0.99475524, 0.9965035 , 0.9965035 , 1.        ,\n",
       "        0.9965035 , 0.99475524, 0.9965035 , 0.9965035 , 1.        ,\n",
       "        0.9965035 , 0.99475524, 0.9965035 , 0.9965035 , 1.        ,\n",
       "        0.99125874, 0.99475524, 0.99475524, 0.99475524, 0.99475524,\n",
       "        0.99125874, 0.99475524, 0.99475524, 0.99475524, 0.99475524,\n",
       "        0.99125874, 0.99475524, 0.99475524, 0.99475524, 0.99475524,\n",
       "        0.99125874, 0.99475524, 0.99475524, 0.99475524, 0.99475524,\n",
       "        0.99125874, 0.99475524, 0.99475524, 0.99475524, 0.99475524,\n",
       "        0.99125874, 0.98951049, 0.98776224, 0.99125874, 0.98951049,\n",
       "        0.99125874, 0.98951049, 0.98776224, 0.99125874, 0.98951049,\n",
       "        0.99125874, 0.98951049, 0.98776224, 0.99125874, 0.98951049,\n",
       "        0.99125874, 0.98951049, 0.98776224, 0.99125874, 0.98951049,\n",
       "        0.99125874, 0.98951049, 0.98776224, 0.99125874, 0.98951049,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 0.99825175, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 0.99825175, 0.99825175, 1.        , 1.        ,\n",
       "        1.        , 0.9965035 , 0.99825175, 1.        , 1.        ,\n",
       "        0.99475524, 0.9965035 , 0.9965035 , 0.9965035 , 0.99825175,\n",
       "        0.99475524, 0.9965035 , 0.9965035 , 0.9965035 , 0.99825175,\n",
       "        0.99475524, 0.9965035 , 0.9965035 , 0.9965035 , 0.99825175,\n",
       "        0.99475524, 0.9965035 , 0.9965035 , 0.9965035 , 0.99825175,\n",
       "        0.99475524, 0.9965035 , 0.9965035 , 0.9965035 , 0.99825175,\n",
       "        0.99475524, 0.98951049, 0.99125874, 0.99125874, 0.99300699,\n",
       "        0.99475524, 0.98951049, 0.99125874, 0.99125874, 0.99300699,\n",
       "        0.99475524, 0.98951049, 0.99125874, 0.99125874, 0.99300699,\n",
       "        0.99475524, 0.98951049, 0.99125874, 0.99125874, 0.99300699,\n",
       "        0.99475524, 0.98951049, 0.99125874, 0.99125874, 0.99300699,\n",
       "        0.99300699, 0.98776224, 0.98601399, 0.99125874, 0.99125874,\n",
       "        0.99300699, 0.98776224, 0.98601399, 0.99125874, 0.99125874,\n",
       "        0.99300699, 0.98776224, 0.98601399, 0.99125874, 0.99125874,\n",
       "        0.99300699, 0.98776224, 0.98601399, 0.99125874, 0.99125874,\n",
       "        0.99300699, 0.98776224, 0.98601399, 0.99125874, 0.99125874]),\n",
       " 'split4_test_score': array([0.97887324, 0.99295775, 0.98591549, 0.98591549, 0.99295775,\n",
       "        0.99295775, 0.99295775, 0.99295775, 0.99295775, 0.99295775,\n",
       "        0.99295775, 0.98591549, 0.99295775, 0.99295775, 0.99295775,\n",
       "        0.99295775, 0.99295775, 0.99295775, 0.99295775, 0.99295775,\n",
       "        0.99295775, 0.99295775, 0.99295775, 0.99295775, 0.99295775,\n",
       "        0.99295775, 0.98591549, 0.99295775, 0.99295775, 0.99295775,\n",
       "        0.99295775, 0.98591549, 0.99295775, 0.99295775, 0.99295775,\n",
       "        0.99295775, 0.98591549, 0.99295775, 0.99295775, 0.99295775,\n",
       "        0.99295775, 0.99295775, 0.99295775, 0.99295775, 0.99295775,\n",
       "        0.99295775, 0.99295775, 0.99295775, 0.98591549, 0.98591549,\n",
       "        0.99295775, 0.97887324, 0.97887324, 0.97183099, 0.97183099,\n",
       "        0.99295775, 0.97887324, 0.97887324, 0.97183099, 0.97183099,\n",
       "        0.99295775, 0.97887324, 0.97887324, 0.97183099, 0.97183099,\n",
       "        0.99295775, 0.97887324, 0.97887324, 0.97183099, 0.97183099,\n",
       "        0.99295775, 0.97887324, 0.97887324, 0.97183099, 0.97183099,\n",
       "        0.97887324, 0.97887324, 0.97887324, 0.97887324, 0.97183099,\n",
       "        0.97887324, 0.97887324, 0.97887324, 0.97887324, 0.97183099,\n",
       "        0.97887324, 0.97887324, 0.97887324, 0.97887324, 0.97183099,\n",
       "        0.97887324, 0.97887324, 0.97887324, 0.97887324, 0.97183099,\n",
       "        0.97887324, 0.97887324, 0.97887324, 0.97887324, 0.97183099,\n",
       "        0.97887324, 0.97887324, 0.97183099, 0.97183099, 0.97887324,\n",
       "        0.97887324, 0.97887324, 0.97183099, 0.97183099, 0.97887324,\n",
       "        0.97887324, 0.97887324, 0.97183099, 0.97183099, 0.97887324,\n",
       "        0.97887324, 0.97887324, 0.97183099, 0.97183099, 0.97887324,\n",
       "        0.97887324, 0.97887324, 0.97183099, 0.97183099, 0.97887324,\n",
       "        0.98591549, 0.97887324, 0.97887324, 0.97887324, 0.98591549,\n",
       "        0.98591549, 0.97887324, 0.97887324, 0.97887324, 0.97887324,\n",
       "        0.98591549, 0.97887324, 0.97887324, 0.97887324, 0.97887324,\n",
       "        0.98591549, 0.97887324, 0.97887324, 0.97887324, 0.97887324,\n",
       "        0.97887324, 0.97887324, 0.97887324, 0.97887324, 0.98591549,\n",
       "        0.98591549, 0.97887324, 0.97887324, 0.97887324, 0.97183099,\n",
       "        0.98591549, 0.97887324, 0.97887324, 0.97887324, 0.97183099,\n",
       "        0.98591549, 0.97887324, 0.97887324, 0.97887324, 0.97183099,\n",
       "        0.98591549, 0.97887324, 0.97887324, 0.97887324, 0.97887324,\n",
       "        0.97887324, 0.97887324, 0.97183099, 0.97887324, 0.98591549,\n",
       "        0.97183099, 0.97183099, 0.97887324, 0.97887324, 0.97887324,\n",
       "        0.97183099, 0.97183099, 0.97887324, 0.97887324, 0.97887324,\n",
       "        0.97183099, 0.97183099, 0.97887324, 0.97887324, 0.97887324,\n",
       "        0.97183099, 0.97183099, 0.97887324, 0.97887324, 0.97887324,\n",
       "        0.97183099, 0.97183099, 0.97887324, 0.97887324, 0.97887324,\n",
       "        0.97183099, 0.98591549, 0.97887324, 0.97183099, 0.97183099,\n",
       "        0.97183099, 0.98591549, 0.97887324, 0.97183099, 0.97183099,\n",
       "        0.97183099, 0.98591549, 0.97887324, 0.97183099, 0.97183099,\n",
       "        0.97183099, 0.98591549, 0.97887324, 0.97183099, 0.97183099,\n",
       "        0.97183099, 0.98591549, 0.97887324, 0.97183099, 0.97183099,\n",
       "        0.97183099, 0.97183099, 0.97183099, 0.97183099, 0.97183099,\n",
       "        0.97183099, 0.97183099, 0.97183099, 0.97183099, 0.97183099,\n",
       "        0.97183099, 0.97183099, 0.97183099, 0.97183099, 0.97183099,\n",
       "        0.97183099, 0.97183099, 0.97183099, 0.97183099, 0.97183099,\n",
       "        0.97183099, 0.97183099, 0.97183099, 0.97183099, 0.97183099]),\n",
       " 'split4_train_score': array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.99825175, 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.99825175, 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.99825175, 1.        , 1.        ,\n",
       "        0.99825175, 0.99825175, 0.99825175, 1.        , 0.99825175,\n",
       "        0.99825175, 0.99825175, 0.99825175, 0.9965035 , 0.99475524,\n",
       "        0.99825175, 0.99475524, 0.99475524, 0.99475524, 0.99475524,\n",
       "        0.99825175, 0.99475524, 0.99475524, 0.99475524, 0.99475524,\n",
       "        0.99825175, 0.99475524, 0.99475524, 0.99475524, 0.99475524,\n",
       "        0.99825175, 0.99475524, 0.99475524, 0.99475524, 0.99475524,\n",
       "        0.99825175, 0.99475524, 0.99475524, 0.99475524, 0.99475524,\n",
       "        0.99125874, 0.99300699, 0.99475524, 0.99475524, 0.99475524,\n",
       "        0.99125874, 0.99300699, 0.99475524, 0.99475524, 0.99475524,\n",
       "        0.99125874, 0.99300699, 0.99475524, 0.99475524, 0.99475524,\n",
       "        0.99125874, 0.99300699, 0.99475524, 0.99475524, 0.99475524,\n",
       "        0.99125874, 0.99300699, 0.99475524, 0.99475524, 0.99475524,\n",
       "        0.98951049, 0.99125874, 0.99300699, 0.99300699, 0.99300699,\n",
       "        0.98951049, 0.99125874, 0.99300699, 0.99300699, 0.99300699,\n",
       "        0.98951049, 0.99125874, 0.99300699, 0.99300699, 0.99300699,\n",
       "        0.98951049, 0.99125874, 0.99300699, 0.99300699, 0.99300699,\n",
       "        0.98951049, 0.99125874, 0.99300699, 0.99300699, 0.99300699,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.9965035 , 0.99825175, 0.9965035 , 0.99825175, 0.99825175,\n",
       "        0.9965035 , 0.99825175, 0.9965035 , 0.99825175, 0.99825175,\n",
       "        0.9965035 , 0.99825175, 0.9965035 , 0.99825175, 0.99825175,\n",
       "        0.9965035 , 0.99825175, 0.9965035 , 0.99825175, 0.99825175,\n",
       "        0.9965035 , 0.99825175, 0.9965035 , 0.99825175, 0.99825175,\n",
       "        0.99475524, 0.99475524, 0.99825175, 0.99475524, 0.99475524,\n",
       "        0.99475524, 0.99475524, 0.99825175, 0.99475524, 0.99475524,\n",
       "        0.99475524, 0.99475524, 0.99825175, 0.99475524, 0.99475524,\n",
       "        0.99475524, 0.99475524, 0.99825175, 0.99475524, 0.99475524,\n",
       "        0.99475524, 0.99475524, 0.99825175, 0.99475524, 0.99475524,\n",
       "        0.98601399, 0.98951049, 0.98951049, 0.99300699, 0.99300699,\n",
       "        0.98601399, 0.98951049, 0.98951049, 0.99300699, 0.99300699,\n",
       "        0.98601399, 0.98951049, 0.98951049, 0.99300699, 0.99300699,\n",
       "        0.98601399, 0.98951049, 0.98951049, 0.99300699, 0.99300699,\n",
       "        0.98601399, 0.98951049, 0.98951049, 0.99300699, 0.99300699]),\n",
       " 'std_fit_time': array([0.03315516, 0.00610604, 0.01879025, 0.01519697, 0.03554712,\n",
       "        0.01094046, 0.00295004, 0.00874765, 0.01891078, 0.02219938,\n",
       "        0.00934918, 0.00441434, 0.0184076 , 0.02194473, 0.00722593,\n",
       "        0.00739221, 0.0077721 , 0.00607513, 0.00768117, 0.01281058,\n",
       "        0.0057351 , 0.00573434, 0.01823189, 0.02567176, 0.03247452,\n",
       "        0.01043847, 0.00730861, 0.01253471, 0.03070717, 0.03859827,\n",
       "        0.00268167, 0.00737217, 0.01357339, 0.03950694, 0.03060494,\n",
       "        0.01756396, 0.01314018, 0.00738714, 0.00810154, 0.05788178,\n",
       "        0.01311914, 0.01102865, 0.0124638 , 0.003034  , 0.02048514,\n",
       "        0.00735178, 0.00399397, 0.00874246, 0.01158811, 0.00548817,\n",
       "        0.0053325 , 0.00472155, 0.0107563 , 0.00601442, 0.0076915 ,\n",
       "        0.00691945, 0.01191755, 0.00790332, 0.02392117, 0.00676848,\n",
       "        0.0131827 , 0.0095577 , 0.01462137, 0.00890464, 0.0086092 ,\n",
       "        0.00650371, 0.01344951, 0.01229492, 0.00815546, 0.01447055,\n",
       "        0.00664307, 0.0099778 , 0.02672993, 0.06847477, 0.04174774,\n",
       "        0.00999123, 0.00572281, 0.02211435, 0.00913939, 0.05898183,\n",
       "        0.01320326, 0.01867954, 0.00764897, 0.03456957, 0.02196197,\n",
       "        0.00409436, 0.01042598, 0.01781195, 0.01819866, 0.02812739,\n",
       "        0.00473298, 0.00582605, 0.01028138, 0.00707024, 0.01435578,\n",
       "        0.01000181, 0.0086407 , 0.0050866 , 0.01190098, 0.01172649,\n",
       "        0.01634459, 0.01362299, 0.00964482, 0.0057244 , 0.00791431,\n",
       "        0.00803688, 0.01274349, 0.03284485, 0.01364434, 0.02500418,\n",
       "        0.00401878, 0.00977738, 0.01460251, 0.00700432, 0.01285066,\n",
       "        0.00497056, 0.00656089, 0.01608516, 0.00392278, 0.01053765,\n",
       "        0.01420294, 0.00312934, 0.00738203, 0.01298514, 0.00327375,\n",
       "        0.00617598, 0.01163316, 0.00721006, 0.0132874 , 0.02532077,\n",
       "        0.01236274, 0.01414114, 0.01262051, 0.00765483, 0.018532  ,\n",
       "        0.00663866, 0.00739067, 0.00800753, 0.01142449, 0.01457001,\n",
       "        0.00902221, 0.00479293, 0.0313995 , 0.0225119 , 0.04286984,\n",
       "        0.00996203, 0.00543246, 0.02248027, 0.0075923 , 0.01038153,\n",
       "        0.01466524, 0.01397479, 0.00809415, 0.01481491, 0.03337727,\n",
       "        0.00988421, 0.0107518 , 0.02050546, 0.016638  , 0.03256996,\n",
       "        0.00524379, 0.01276025, 0.03342591, 0.02728921, 0.02610388,\n",
       "        0.01443348, 0.01063696, 0.0130147 , 0.05640048, 0.04988654,\n",
       "        0.009215  , 0.01347486, 0.04365545, 0.00953533, 0.01493145,\n",
       "        0.01033137, 0.0870241 , 0.01464799, 0.01967373, 0.01114118,\n",
       "        0.00326077, 0.00989574, 0.00495761, 0.01741742, 0.01960708,\n",
       "        0.00788188, 0.00765772, 0.0162581 , 0.01537012, 0.01860993,\n",
       "        0.00174465, 0.01036083, 0.00496197, 0.10049665, 0.07484583,\n",
       "        0.01901144, 0.00887192, 0.01053179, 0.00941682, 0.00896379,\n",
       "        0.00782428, 0.00464552, 0.00878093, 0.00635633, 0.03578196,\n",
       "        0.01545891, 0.00772828, 0.00970029, 0.02266758, 0.01902576,\n",
       "        0.00260597, 0.02215376, 0.00498126, 0.01391995, 0.019264  ,\n",
       "        0.00470711, 0.00877665, 0.00456664, 0.08426366, 0.07683022,\n",
       "        0.02977663, 0.04777221, 0.0155803 , 0.01358675, 0.01960947,\n",
       "        0.00565533, 0.00493633, 0.01428944, 0.04014148, 0.05594085,\n",
       "        0.00919716, 0.00519779, 0.00593475, 0.01027122, 0.09103854,\n",
       "        0.02336392, 0.05380495, 0.05753565, 0.07550917, 0.09277852,\n",
       "        0.0094983 , 0.03035644, 0.00720612, 0.01664675, 0.05622793,\n",
       "        0.04152554, 0.02117406, 0.01269042, 0.02386485, 0.03095684]),\n",
       " 'std_score_time': array([8.82118585e-05, 7.94784131e-05, 7.34864750e-03, 2.94652822e-03,\n",
       "        4.49674342e-03, 3.50204586e-03, 4.47514797e-03, 7.78316025e-03,\n",
       "        2.59529690e-03, 3.19953538e-03, 3.66853419e-03, 4.30564679e-05,\n",
       "        6.38737441e-03, 5.58086417e-03, 4.44896426e-03, 1.09637204e-03,\n",
       "        5.92600972e-03, 5.29662368e-03, 3.59028299e-05, 4.98736433e-03,\n",
       "        2.86406514e-05, 4.71887033e-03, 3.29636871e-03, 3.94045511e-03,\n",
       "        6.13556698e-03, 1.57641393e-03, 3.33224347e-03, 1.01752594e-02,\n",
       "        5.74004000e-03, 4.36183513e-03, 5.32855938e-03, 7.12946487e-03,\n",
       "        1.24184441e-02, 5.06548110e-03, 1.08738458e-02, 4.02540102e-03,\n",
       "        5.67590814e-03, 5.07444427e-03, 2.53169252e-04, 1.96912975e-02,\n",
       "        8.31223596e-05, 6.98497555e-03, 3.16120269e-03, 6.52889594e-03,\n",
       "        8.13042292e-03, 5.90216013e-03, 4.26257409e-03, 3.19432904e-03,\n",
       "        2.55599975e-03, 8.75927925e-06, 4.70596869e-03, 6.29670941e-03,\n",
       "        6.22434727e-03, 3.21734848e-03, 5.03124809e-03, 4.52792862e-03,\n",
       "        3.24530006e-03, 3.30501221e-03, 5.71984986e-03, 4.55434107e-03,\n",
       "        6.47094328e-03, 5.14097741e-03, 3.20179730e-05, 5.26925611e-03,\n",
       "        3.65712662e-03, 3.58970043e-03, 3.88708696e-03, 5.60818755e-03,\n",
       "        2.68500879e-03, 1.01587360e-02, 5.94511246e-03, 1.20349632e-02,\n",
       "        4.37302784e-03, 1.99132961e-02, 1.52591971e-03, 6.78544927e-03,\n",
       "        6.43177647e-03, 6.60118254e-03, 6.12375911e-03, 1.38336494e-02,\n",
       "        6.52162512e-03, 4.91141906e-03, 6.24899888e-03, 4.17874858e-03,\n",
       "        2.51307370e-02, 5.02635523e-03, 8.09585141e-03, 5.92789060e-03,\n",
       "        4.53763732e-03, 6.14814040e-03, 6.41661350e-03, 4.29319247e-03,\n",
       "        6.88548598e-03, 8.55508912e-04, 5.74917763e-03, 2.94000864e-03,\n",
       "        1.43128869e-03, 6.58795427e-03, 2.54366591e-05, 3.75522325e-03,\n",
       "        6.11500074e-03, 1.95783413e-03, 6.53456671e-03, 3.17795653e-03,\n",
       "        4.40406522e-03, 6.30634252e-03, 4.90983573e-03, 4.61701116e-03,\n",
       "        4.39634377e-03, 4.89047952e-03, 6.40514628e-03, 4.83920374e-03,\n",
       "        2.70092060e-03, 3.38576040e-03, 5.37126455e-03, 3.69653072e-05,\n",
       "        1.03837087e-02, 2.62319993e-03, 4.74639640e-03, 2.15998900e-03,\n",
       "        3.18671951e-03, 6.73057429e-03, 3.12652784e-03, 5.42882958e-03,\n",
       "        4.30302601e-03, 2.55215570e-03, 5.60138704e-03, 4.40532935e-03,\n",
       "        4.92655149e-03, 2.65056570e-03, 7.31805921e-03, 3.88629778e-03,\n",
       "        4.36404309e-03, 5.70275916e-03, 5.32482246e-03, 6.04591108e-03,\n",
       "        6.37046084e-04, 4.48175298e-03, 8.76563364e-03, 3.36153781e-04,\n",
       "        2.66483298e-03, 7.75171621e-03, 2.62566478e-03, 4.56940222e-03,\n",
       "        1.45772600e-02, 4.75835740e-03, 2.58880800e-03, 5.88327251e-03,\n",
       "        1.08332788e-02, 8.57563232e-03, 3.90308035e-06, 7.06733667e-03,\n",
       "        1.40994363e-02, 3.35370079e-03, 8.09391682e-03, 6.03892203e-03,\n",
       "        1.68332067e-04, 3.93632136e-03, 9.55294187e-06, 1.15675393e-02,\n",
       "        7.63559769e-04, 2.13916293e-02, 5.78625026e-03, 2.04100092e-02,\n",
       "        7.17990234e-03, 4.13378661e-03, 6.57837368e-03, 9.89788964e-03,\n",
       "        5.69894997e-03, 7.93031205e-03, 4.38515742e-03, 4.28710837e-02,\n",
       "        1.81810081e-02, 7.31547897e-03, 6.83571257e-03, 9.06104013e-02,\n",
       "        9.36867095e-02, 5.05102959e-03, 6.57504207e-03, 2.44608755e-03,\n",
       "        5.05097216e-03, 2.08612851e-06, 3.87784785e-03, 3.17351374e-03,\n",
       "        7.40742382e-03, 6.52770723e-03, 3.24992290e-03, 8.40686805e-03,\n",
       "        2.60488075e-03, 1.49366930e-02, 3.21897182e-03, 2.26531482e-03,\n",
       "        1.99767916e-02, 8.42206903e-02, 3.56910992e-02, 6.63264230e-03,\n",
       "        6.79035249e-03, 8.68829199e-03, 9.45244113e-03, 8.31890879e-03,\n",
       "        5.37934686e-03, 3.89755182e-03, 5.66683555e-03, 5.52173684e-03,\n",
       "        5.76861242e-03, 6.47547899e-03, 6.21716023e-03, 3.46972811e-03,\n",
       "        9.06927606e-03, 8.32057493e-03, 6.67821337e-03, 1.26475461e-02,\n",
       "        3.38036160e-03, 9.44967854e-03, 8.99514174e-03, 4.93230368e-03,\n",
       "        2.58089673e-03, 8.17728430e-03, 3.17356337e-02, 1.96748952e-02,\n",
       "        3.51970476e-02, 1.57756236e-02, 1.21306202e-02, 1.74459829e-03,\n",
       "        3.86778573e-03, 2.99295645e-03, 1.19194208e-03, 1.12949656e-02,\n",
       "        5.27523759e-02, 1.88982735e-02, 3.78994379e-03, 1.05530861e-05,\n",
       "        2.93879107e-03, 2.85863777e-06, 5.74357645e-02, 3.45520558e-02,\n",
       "        2.98091941e-02, 9.84766533e-03, 3.69575071e-02, 4.76794434e-02,\n",
       "        5.80278213e-03, 8.77756328e-03, 7.68660748e-03, 4.68082769e-03,\n",
       "        9.37636295e-03, 9.68511152e-03, 1.55472189e-02, 8.61676686e-03,\n",
       "        4.13946747e-03, 2.38709355e-03]),\n",
       " 'std_test_score': array([0.00882211, 0.00810349, 0.00677793, 0.00939996, 0.01019245,\n",
       "        0.00710042, 0.0051702 , 0.00807617, 0.00807617, 0.01074661,\n",
       "        0.00710042, 0.00436468, 0.01019245, 0.00758577, 0.01074661,\n",
       "        0.00837509, 0.00711969, 0.00622709, 0.01131759, 0.0128854 ,\n",
       "        0.0098214 , 0.00714833, 0.01039641, 0.01244253, 0.00941464,\n",
       "        0.00921893, 0.00837509, 0.00946531, 0.01244253, 0.01244253,\n",
       "        0.00921893, 0.00837509, 0.00946531, 0.01244253, 0.01244253,\n",
       "        0.00921893, 0.00837509, 0.00946531, 0.01244253, 0.01244253,\n",
       "        0.00708094, 0.01023303, 0.01484747, 0.01484747, 0.01671448,\n",
       "        0.01322701, 0.00710042, 0.01197178, 0.01111743, 0.01245904,\n",
       "        0.01839351, 0.00759556, 0.00679701, 0.00626092, 0.00626092,\n",
       "        0.01839351, 0.00759556, 0.00679701, 0.00626092, 0.00626092,\n",
       "        0.01839351, 0.00759556, 0.00679701, 0.00626092, 0.00626092,\n",
       "        0.01839351, 0.00759556, 0.00679701, 0.00626092, 0.00626092,\n",
       "        0.01839351, 0.00759556, 0.00679701, 0.00626092, 0.00626092,\n",
       "        0.0123999 , 0.00805104, 0.01213765, 0.01109847, 0.01342757,\n",
       "        0.0123999 , 0.00805104, 0.01213765, 0.01109847, 0.01342757,\n",
       "        0.0123999 , 0.00805104, 0.01213765, 0.01109847, 0.01342757,\n",
       "        0.0123999 , 0.00805104, 0.01213765, 0.01109847, 0.01342757,\n",
       "        0.0123999 , 0.00805104, 0.01213765, 0.01109847, 0.01342757,\n",
       "        0.01431585, 0.01667615, 0.01584357, 0.01462515, 0.01667615,\n",
       "        0.01431585, 0.01667615, 0.01584357, 0.01462515, 0.01667615,\n",
       "        0.01431585, 0.01667615, 0.01584357, 0.01462515, 0.01667615,\n",
       "        0.01431585, 0.01667615, 0.01584357, 0.01462515, 0.01667615,\n",
       "        0.01431585, 0.01667615, 0.01584357, 0.01462515, 0.01667615,\n",
       "        0.00879879, 0.00705863, 0.00921893, 0.00921893, 0.01209575,\n",
       "        0.00620598, 0.00755033, 0.00521278, 0.00553984, 0.00521278,\n",
       "        0.00562572, 0.0071293 , 0.0034529 , 0.00525205, 0.00525205,\n",
       "        0.01209575, 0.00563768, 0.00626   , 0.00525205, 0.00525205,\n",
       "        0.00943644, 0.00563768, 0.00626   , 0.00708094, 0.00441151,\n",
       "        0.005134  , 0.00526365, 0.00529168, 0.00563768, 0.00987704,\n",
       "        0.005134  , 0.00526365, 0.00529168, 0.00563768, 0.00987704,\n",
       "        0.005134  , 0.00526365, 0.00529168, 0.00563768, 0.00987704,\n",
       "        0.01074077, 0.00566213, 0.00943644, 0.01196124, 0.00943644,\n",
       "        0.0071293 , 0.00882211, 0.00817963, 0.01196124, 0.00942179,\n",
       "        0.01737261, 0.00950645, 0.01164051, 0.01164051, 0.00943644,\n",
       "        0.01737261, 0.00950645, 0.01164051, 0.01164051, 0.00943644,\n",
       "        0.01737261, 0.00950645, 0.01164051, 0.01164051, 0.00943644,\n",
       "        0.01737261, 0.00950645, 0.01164051, 0.01164051, 0.00943644,\n",
       "        0.01737261, 0.00950645, 0.01164051, 0.01164051, 0.00943644,\n",
       "        0.0193992 , 0.01167645, 0.00878412, 0.01017102, 0.00710699,\n",
       "        0.0193992 , 0.01167645, 0.00878412, 0.01017102, 0.00710699,\n",
       "        0.0193992 , 0.01167645, 0.00878412, 0.01017102, 0.00710699,\n",
       "        0.0193992 , 0.01167645, 0.00878412, 0.01017102, 0.00710699,\n",
       "        0.0193992 , 0.01167645, 0.00878412, 0.01017102, 0.00710699,\n",
       "        0.01038401, 0.00527566, 0.0098789 , 0.0119306 , 0.012845  ,\n",
       "        0.01038401, 0.00527566, 0.0098789 , 0.0119306 , 0.012845  ,\n",
       "        0.01038401, 0.00527566, 0.0098789 , 0.0119306 , 0.012845  ,\n",
       "        0.01038401, 0.00527566, 0.0098789 , 0.0119306 , 0.012845  ,\n",
       "        0.01038401, 0.00527566, 0.0098789 , 0.0119306 , 0.012845  ]),\n",
       " 'std_train_score': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.0006993 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00070175, 0.        , 0.0006993 , 0.0006993 , 0.        ,\n",
       "        0.00085797, 0.00070175, 0.00085797, 0.0006993 , 0.0006993 ,\n",
       "        0.00085797, 0.00070175, 0.00085797, 0.0006993 , 0.0006993 ,\n",
       "        0.00085797, 0.00070175, 0.00085797, 0.0006993 , 0.0006993 ,\n",
       "        0.00085797, 0.00085797, 0.00085646, 0.0006993 , 0.00085646,\n",
       "        0.00085797, 0.0013086 , 0.00110569, 0.00139922, 0.00203901,\n",
       "        0.00203711, 0.00170992, 0.00231895, 0.00247153, 0.00284012,\n",
       "        0.00203711, 0.00170992, 0.00231895, 0.00247153, 0.00284012,\n",
       "        0.00203711, 0.00209504, 0.00231895, 0.00247153, 0.00284012,\n",
       "        0.00203711, 0.00170992, 0.00231895, 0.00247153, 0.00284012,\n",
       "        0.00203711, 0.00170992, 0.00231895, 0.00247153, 0.00284012,\n",
       "        0.00170571, 0.00257962, 0.00325895, 0.00204935, 0.00085953,\n",
       "        0.00170571, 0.00257962, 0.00325895, 0.00204935, 0.00085953,\n",
       "        0.00170571, 0.00257962, 0.00325895, 0.00204935, 0.00085953,\n",
       "        0.00170571, 0.00257962, 0.00325895, 0.00204935, 0.00085953,\n",
       "        0.00170571, 0.00257962, 0.00325895, 0.00204935, 0.00085953,\n",
       "        0.00368942, 0.00263005, 0.00280523, 0.00326028, 0.0015665 ,\n",
       "        0.00368942, 0.00263005, 0.00280523, 0.00326028, 0.0015665 ,\n",
       "        0.00368942, 0.00263005, 0.00280523, 0.00326028, 0.0015665 ,\n",
       "        0.00368942, 0.00263005, 0.00280523, 0.00326028, 0.0015665 ,\n",
       "        0.00368942, 0.00263005, 0.00280523, 0.00326028, 0.0015665 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00070175, 0.00070175, 0.00085797, 0.        , 0.        ,\n",
       "        0.00085947, 0.00085797, 0.00070175, 0.        , 0.        ,\n",
       "        0.00085847, 0.00140351, 0.00070175, 0.        , 0.        ,\n",
       "        0.00070175, 0.00070175, 0.00070175, 0.        , 0.        ,\n",
       "        0.00070175, 0.00070175, 0.00070175, 0.        , 0.        ,\n",
       "        0.00070175, 0.00070175, 0.00070175, 0.        , 0.        ,\n",
       "        0.00140351, 0.00085847, 0.00085847, 0.00070175, 0.        ,\n",
       "        0.00192184, 0.00156643, 0.00131254, 0.00085947, 0.00070175,\n",
       "        0.00131257, 0.00156644, 0.00070178, 0.0011057 , 0.00069992,\n",
       "        0.00131257, 0.00156644, 0.00070178, 0.0011057 , 0.00069992,\n",
       "        0.00131257, 0.00156644, 0.00070178, 0.0011057 , 0.00069992,\n",
       "        0.00131257, 0.00156644, 0.00070178, 0.0011057 , 0.00069992,\n",
       "        0.00131257, 0.00156644, 0.00070178, 0.0011057 , 0.00069992,\n",
       "        0.00203714, 0.00233009, 0.00339913, 0.00204135, 0.00130337,\n",
       "        0.00203714, 0.00233009, 0.00339913, 0.00204135, 0.00130337,\n",
       "        0.00203714, 0.00233009, 0.00339913, 0.00204135, 0.00130337,\n",
       "        0.00203714, 0.00233009, 0.00339913, 0.00204135, 0.00130337,\n",
       "        0.00203714, 0.00233009, 0.00339913, 0.00204135, 0.00130337,\n",
       "        0.00404094, 0.0023666 , 0.00178515, 0.00131358, 0.0023682 ,\n",
       "        0.00404094, 0.0023666 , 0.00178515, 0.00131358, 0.0023682 ,\n",
       "        0.00404094, 0.0023666 , 0.00178515, 0.00131358, 0.0023682 ,\n",
       "        0.00404094, 0.0023666 , 0.00178515, 0.00131358, 0.0023682 ,\n",
       "        0.00404094, 0.0023666 , 0.00178515, 0.00131358, 0.0023682 ])}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import KFold\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#kfold_model=model4.fit(x_train,y_train)\n",
    "#kfold = KFold(n_splits=3, random_state=7)\n",
    "#result = cross_val_score(kfold_model, x_train, y_train, cv=kfold, scoring='accuracy')\n",
    "#print(result.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the trained model\n",
    "with open('trained_model','wb') as file:\n",
    "    pickle.dump(model4,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the trained model\n",
    "with open('trained_model','rb') as file:\n",
    "    trained_model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_model=model4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction=trained_model.predict(x_test)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.321894</td>\n",
       "      <td>-1.277660</td>\n",
       "      <td>-0.346314</td>\n",
       "      <td>-0.389320</td>\n",
       "      <td>-0.010120</td>\n",
       "      <td>-0.577099</td>\n",
       "      <td>-0.447952</td>\n",
       "      <td>-0.230917</td>\n",
       "      <td>0.165181</td>\n",
       "      <td>-0.681058</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.410276</td>\n",
       "      <td>-1.165488</td>\n",
       "      <td>-0.403305</td>\n",
       "      <td>-0.442960</td>\n",
       "      <td>0.347717</td>\n",
       "      <td>-0.599768</td>\n",
       "      <td>-0.330357</td>\n",
       "      <td>-0.013812</td>\n",
       "      <td>-0.000465</td>\n",
       "      <td>-0.653024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.444969</td>\n",
       "      <td>-0.961916</td>\n",
       "      <td>-0.417508</td>\n",
       "      <td>-0.509618</td>\n",
       "      <td>0.665798</td>\n",
       "      <td>0.219010</td>\n",
       "      <td>-0.696819</td>\n",
       "      <td>-0.640762</td>\n",
       "      <td>0.462603</td>\n",
       "      <td>0.650606</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.528934</td>\n",
       "      <td>-0.968553</td>\n",
       "      <td>-0.504294</td>\n",
       "      <td>-0.571976</td>\n",
       "      <td>-0.172664</td>\n",
       "      <td>-0.044818</td>\n",
       "      <td>-0.553059</td>\n",
       "      <td>-0.827573</td>\n",
       "      <td>0.293294</td>\n",
       "      <td>-0.208503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.401746</td>\n",
       "      <td>-1.726718</td>\n",
       "      <td>-1.401378</td>\n",
       "      <td>-1.149042</td>\n",
       "      <td>0.310785</td>\n",
       "      <td>-0.862207</td>\n",
       "      <td>-0.888219</td>\n",
       "      <td>-0.894371</td>\n",
       "      <td>-0.088717</td>\n",
       "      <td>0.770393</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.359545</td>\n",
       "      <td>-1.741884</td>\n",
       "      <td>-1.370391</td>\n",
       "      <td>-1.076530</td>\n",
       "      <td>-0.123879</td>\n",
       "      <td>-0.945575</td>\n",
       "      <td>-0.999933</td>\n",
       "      <td>-0.981108</td>\n",
       "      <td>-0.748346</td>\n",
       "      <td>-0.405747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.458347</td>\n",
       "      <td>-0.328090</td>\n",
       "      <td>-0.534997</td>\n",
       "      <td>-0.499745</td>\n",
       "      <td>-0.564220</td>\n",
       "      <td>-1.336981</td>\n",
       "      <td>-0.935000</td>\n",
       "      <td>-0.686628</td>\n",
       "      <td>-1.350949</td>\n",
       "      <td>-0.557449</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.762361</td>\n",
       "      <td>-0.597098</td>\n",
       "      <td>-0.829640</td>\n",
       "      <td>-0.707227</td>\n",
       "      <td>-1.562651</td>\n",
       "      <td>-1.325188</td>\n",
       "      <td>-1.179608</td>\n",
       "      <td>-1.157614</td>\n",
       "      <td>-1.405402</td>\n",
       "      <td>-1.177406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.751708</td>\n",
       "      <td>-0.697627</td>\n",
       "      <td>-1.737116</td>\n",
       "      <td>-1.336114</td>\n",
       "      <td>-0.830828</td>\n",
       "      <td>-0.957824</td>\n",
       "      <td>-1.050647</td>\n",
       "      <td>-1.258424</td>\n",
       "      <td>-0.255563</td>\n",
       "      <td>0.258116</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.605810</td>\n",
       "      <td>-0.733191</td>\n",
       "      <td>-1.590552</td>\n",
       "      <td>-1.192756</td>\n",
       "      <td>-0.233647</td>\n",
       "      <td>-0.829937</td>\n",
       "      <td>-1.088434</td>\n",
       "      <td>-1.513681</td>\n",
       "      <td>0.181183</td>\n",
       "      <td>-0.580862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0 -0.321894 -1.277660 -0.346314 -0.389320 -0.010120 -0.577099 -0.447952   \n",
       "1 -0.444969 -0.961916 -0.417508 -0.509618  0.665798  0.219010 -0.696819   \n",
       "2 -1.401746 -1.726718 -1.401378 -1.149042  0.310785 -0.862207 -0.888219   \n",
       "3 -0.458347 -0.328090 -0.534997 -0.499745 -0.564220 -1.336981 -0.935000   \n",
       "4 -1.751708 -0.697627 -1.737116 -1.336114 -0.830828 -0.957824 -1.050647   \n",
       "\n",
       "         7         8         9     ...           20        21        22  \\\n",
       "0 -0.230917  0.165181 -0.681058    ...    -0.410276 -1.165488 -0.403305   \n",
       "1 -0.640762  0.462603  0.650606    ...    -0.528934 -0.968553 -0.504294   \n",
       "2 -0.894371 -0.088717  0.770393    ...    -1.359545 -1.741884 -1.370391   \n",
       "3 -0.686628 -1.350949 -0.557449    ...    -0.762361 -0.597098 -0.829640   \n",
       "4 -1.258424 -0.255563  0.258116    ...    -1.605810 -0.733191 -1.590552   \n",
       "\n",
       "         23        24        25        26        27        28        29  \n",
       "0 -0.442960  0.347717 -0.599768 -0.330357 -0.013812 -0.000465 -0.653024  \n",
       "1 -0.571976 -0.172664 -0.044818 -0.553059 -0.827573  0.293294 -0.208503  \n",
       "2 -1.076530 -0.123879 -0.945575 -0.999933 -0.981108 -0.748346 -0.405747  \n",
       "3 -0.707227 -1.562651 -1.325188 -1.179608 -1.157614 -1.405402 -1.177406  \n",
       "4 -1.192756 -0.233647 -0.829937 -1.088434 -1.513681  0.181183 -0.580862  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame(x_test)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.321894</td>\n",
       "      <td>-1.277660</td>\n",
       "      <td>-0.346314</td>\n",
       "      <td>-0.389320</td>\n",
       "      <td>-0.010120</td>\n",
       "      <td>-0.577099</td>\n",
       "      <td>-0.447952</td>\n",
       "      <td>-0.230917</td>\n",
       "      <td>0.165181</td>\n",
       "      <td>-0.681058</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.410276</td>\n",
       "      <td>-1.165488</td>\n",
       "      <td>-0.403305</td>\n",
       "      <td>-0.442960</td>\n",
       "      <td>0.347717</td>\n",
       "      <td>-0.599768</td>\n",
       "      <td>-0.330357</td>\n",
       "      <td>-0.013812</td>\n",
       "      <td>-0.000465</td>\n",
       "      <td>-0.653024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.444969</td>\n",
       "      <td>-0.961916</td>\n",
       "      <td>-0.417508</td>\n",
       "      <td>-0.509618</td>\n",
       "      <td>0.665798</td>\n",
       "      <td>0.219010</td>\n",
       "      <td>-0.696819</td>\n",
       "      <td>-0.640762</td>\n",
       "      <td>0.462603</td>\n",
       "      <td>0.650606</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.528934</td>\n",
       "      <td>-0.968553</td>\n",
       "      <td>-0.504294</td>\n",
       "      <td>-0.571976</td>\n",
       "      <td>-0.172664</td>\n",
       "      <td>-0.044818</td>\n",
       "      <td>-0.553059</td>\n",
       "      <td>-0.827573</td>\n",
       "      <td>0.293294</td>\n",
       "      <td>-0.208503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.401746</td>\n",
       "      <td>-1.726718</td>\n",
       "      <td>-1.401378</td>\n",
       "      <td>-1.149042</td>\n",
       "      <td>0.310785</td>\n",
       "      <td>-0.862207</td>\n",
       "      <td>-0.888219</td>\n",
       "      <td>-0.894371</td>\n",
       "      <td>-0.088717</td>\n",
       "      <td>0.770393</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.359545</td>\n",
       "      <td>-1.741884</td>\n",
       "      <td>-1.370391</td>\n",
       "      <td>-1.076530</td>\n",
       "      <td>-0.123879</td>\n",
       "      <td>-0.945575</td>\n",
       "      <td>-0.999933</td>\n",
       "      <td>-0.981108</td>\n",
       "      <td>-0.748346</td>\n",
       "      <td>-0.405747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.458347</td>\n",
       "      <td>-0.328090</td>\n",
       "      <td>-0.534997</td>\n",
       "      <td>-0.499745</td>\n",
       "      <td>-0.564220</td>\n",
       "      <td>-1.336981</td>\n",
       "      <td>-0.935000</td>\n",
       "      <td>-0.686628</td>\n",
       "      <td>-1.350949</td>\n",
       "      <td>-0.557449</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.762361</td>\n",
       "      <td>-0.597098</td>\n",
       "      <td>-0.829640</td>\n",
       "      <td>-0.707227</td>\n",
       "      <td>-1.562651</td>\n",
       "      <td>-1.325188</td>\n",
       "      <td>-1.179608</td>\n",
       "      <td>-1.157614</td>\n",
       "      <td>-1.405402</td>\n",
       "      <td>-1.177406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.751708</td>\n",
       "      <td>-0.697627</td>\n",
       "      <td>-1.737116</td>\n",
       "      <td>-1.336114</td>\n",
       "      <td>-0.830828</td>\n",
       "      <td>-0.957824</td>\n",
       "      <td>-1.050647</td>\n",
       "      <td>-1.258424</td>\n",
       "      <td>-0.255563</td>\n",
       "      <td>0.258116</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.605810</td>\n",
       "      <td>-0.733191</td>\n",
       "      <td>-1.590552</td>\n",
       "      <td>-1.192756</td>\n",
       "      <td>-0.233647</td>\n",
       "      <td>-0.829937</td>\n",
       "      <td>-1.088434</td>\n",
       "      <td>-1.513681</td>\n",
       "      <td>0.181183</td>\n",
       "      <td>-0.580862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0    -0.321894     -1.277660       -0.346314  -0.389320        -0.010120   \n",
       "1    -0.444969     -0.961916       -0.417508  -0.509618         0.665798   \n",
       "2    -1.401746     -1.726718       -1.401378  -1.149042         0.310785   \n",
       "3    -0.458347     -0.328090       -0.534997  -0.499745        -0.564220   \n",
       "4    -1.751708     -0.697627       -1.737116  -1.336114        -0.830828   \n",
       "\n",
       "   compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "0         -0.577099       -0.447952            -0.230917       0.165181   \n",
       "1          0.219010       -0.696819            -0.640762       0.462603   \n",
       "2         -0.862207       -0.888219            -0.894371      -0.088717   \n",
       "3         -1.336981       -0.935000            -0.686628      -1.350949   \n",
       "4         -0.957824       -1.050647            -1.258424      -0.255563   \n",
       "\n",
       "   fractal_dimension_mean           ...             radius_worst  \\\n",
       "0               -0.681058           ...                -0.410276   \n",
       "1                0.650606           ...                -0.528934   \n",
       "2                0.770393           ...                -1.359545   \n",
       "3               -0.557449           ...                -0.762361   \n",
       "4                0.258116           ...                -1.605810   \n",
       "\n",
       "   texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0      -1.165488        -0.403305   -0.442960          0.347717   \n",
       "1      -0.968553        -0.504294   -0.571976         -0.172664   \n",
       "2      -1.741884        -1.370391   -1.076530         -0.123879   \n",
       "3      -0.597098        -0.829640   -0.707227         -1.562651   \n",
       "4      -0.733191        -1.590552   -1.192756         -0.233647   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0          -0.599768        -0.330357             -0.013812       -0.000465   \n",
       "1          -0.044818        -0.553059             -0.827573        0.293294   \n",
       "2          -0.945575        -0.999933             -0.981108       -0.748346   \n",
       "3          -1.325188        -1.179608             -1.157614       -1.405402   \n",
       "4          -0.829937        -1.088434             -1.513681        0.181183   \n",
       "\n",
       "   fractal_dimension_worst  \n",
       "0                -0.653024  \n",
       "1                -0.208503  \n",
       "2                -0.405747  \n",
       "3                -1.177406  \n",
       "4                -0.580862  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns=['radius_mean', 'texture_mean', 'perimeter_mean',\n",
    "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
    "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
    "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
    "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
    "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
    "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
    "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
    "       'symmetry_worst', 'fractal_dimension_worst']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Actual  Predicted\n",
       "0       0          0\n",
       "1       0          0\n",
       "2       0          0\n",
       "3       0          0\n",
       "4       0          0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame({'Actual': y_test, 'Predicted': prediction})  \n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Actual Predicted\n",
      "0    Benign    Benign\n",
      "1    Benign    Benign\n",
      "2    Benign    Benign\n",
      "3    Benign    Benign\n",
      "4    Benign    Benign\n",
      "5    Benign    Benign\n",
      "6    Benign    Benign\n",
      "7    Benign    Benign\n",
      "8    Benign    Benign\n",
      "9    Benign    Benign\n",
      "10   Benign    Benign\n",
      "11   Benign    Benign\n",
      "12   Benign    Benign\n",
      "13   Benign    Benign\n",
      "14   Benign    Benign\n",
      "15   Benign    Benign\n",
      "16   Benign    Benign\n",
      "17   Benign    Benign\n",
      "18   Benign    Benign\n",
      "19   Benign    Benign\n",
      "20   Benign    Benign\n",
      "21   Benign    Benign\n",
      "22   Benign    Benign\n",
      "23   Benign    Benign\n",
      "24   Benign    Benign\n",
      "25   Benign    Benign\n",
      "26   Benign    Benign\n",
      "27   Benign    Benign\n",
      "28   Benign    Benign\n",
      "29   Benign    Benign\n",
      "..      ...       ...\n",
      "684  Malign    Malign\n",
      "685  Malign    Malign\n",
      "686  Malign    Malign\n",
      "687  Malign    Malign\n",
      "688  Malign    Malign\n",
      "689  Malign    Malign\n",
      "690  Malign    Malign\n",
      "691  Malign    Malign\n",
      "692  Malign    Malign\n",
      "693  Malign    Malign\n",
      "694  Malign    Malign\n",
      "695  Malign    Malign\n",
      "696  Malign    Malign\n",
      "697  Malign    Malign\n",
      "698  Malign    Malign\n",
      "699  Malign    Malign\n",
      "700  Malign    Malign\n",
      "701  Malign    Malign\n",
      "702  Malign    Malign\n",
      "703  Malign    Malign\n",
      "704  Malign    Malign\n",
      "705  Malign    Malign\n",
      "706  Malign    Malign\n",
      "707  Malign    Malign\n",
      "708  Malign    Malign\n",
      "709  Malign    Malign\n",
      "710  Malign    Malign\n",
      "711  Malign    Malign\n",
      "712  Malign    Malign\n",
      "713  Malign    Malign\n",
      "\n",
      "[714 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df1['Actual']=df1['Actual'].map({1:\"Malign\",0:\"Benign\"})\n",
    "df1['Predicted']=df1['Predicted'].map({1:\"Malign\",0:\"Benign\"})\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
      "500     0.681437      0.539621        0.701747   0.601903        -0.553082   \n",
      "501     1.698146      1.578067        1.802717   1.545578         1.125228   \n",
      "502     1.144308      1.114976        0.997414   0.934995        -0.532199   \n",
      "503    -0.303165      1.206191       -0.323361  -0.346710        -0.212686   \n",
      "504     0.269403      0.099918        0.242685   0.117334         0.317746   \n",
      "505     1.553667      0.242588        1.612089   1.537783         0.463928   \n",
      "506     2.013861     -0.035735        2.195642   2.060027         2.413023   \n",
      "507     0.095492      0.513893        0.034940  -0.008680        -0.513404   \n",
      "508     0.657358      1.098604        0.693966   0.554095         0.637954   \n",
      "509     0.681437      0.539621        0.701747   0.601903        -0.553082   \n",
      "510     0.729597      1.136026        0.767883   0.697517         0.484811   \n",
      "511    -0.359351      0.163067       -0.300408  -0.414263         0.881591   \n",
      "512     1.088121      0.036770        0.954620   1.002549        -0.605986   \n",
      "513     2.345630      1.040133        2.285121   2.678404         0.624032   \n",
      "514     0.606522      0.102257        0.518900   0.488880        -0.711098   \n",
      "515     1.476076      0.750117        1.402010   1.423462        -0.498090   \n",
      "516     1.189792     -0.908123        1.164699   1.145451        -0.765394   \n",
      "517     1.944297      0.485827        1.977783   1.989875         0.582266   \n",
      "518     1.542965      1.868083        1.479817   1.566364        -0.441705   \n",
      "519     1.534938      0.382918        1.405901   1.532587        -1.001374   \n",
      "520    -0.980079     -0.232197       -0.897188  -0.921177         1.647307   \n",
      "521     0.269403      0.099918        0.242685   0.117334         0.317746   \n",
      "522     0.520904      0.088224        0.417751   0.367543        -1.598632   \n",
      "523     0.994477     -0.304701        0.962400   0.932397         0.056010   \n",
      "524     0.379100      0.401629        0.382738   0.243347         0.199408   \n",
      "525    -0.466373      0.467117       -0.344758  -0.510138         2.044087   \n",
      "526     0.127599      2.525298        0.273808   0.001972         0.477850   \n",
      "527     0.697491      0.757133        0.569475   0.563709        -0.787669   \n",
      "528    -0.303165      1.206191       -0.323361  -0.346710        -0.212686   \n",
      "529    -0.359351      0.163067       -0.300408  -0.414263         0.881591   \n",
      "..           ...           ...             ...        ...              ...   \n",
      "670     0.496825      1.931232        0.464435   0.368842        -0.931763   \n",
      "671    -0.078419      0.092902       -0.072823  -0.190816         0.054618   \n",
      "672     0.191812     -1.855354        0.238795   0.053937         1.932710   \n",
      "673    -0.078419      0.092902       -0.072823  -0.190816         0.054618   \n",
      "674     1.864031     -0.601734        1.732690   2.156161        -0.285081   \n",
      "675     0.994477     -0.304701        0.962400   0.932397         0.056010   \n",
      "676     1.773062     -1.104586        1.748252   1.740445         0.150680   \n",
      "677     1.559018     -0.480115        1.421462   1.584551        -0.918537   \n",
      "678    -0.204170     -0.047429       -0.203928  -0.303059         0.561383   \n",
      "679    -0.798142     -0.393577       -0.831052  -0.740601         0.121444   \n",
      "680     0.847322      0.280009        1.090782   0.721941         1.744762   \n",
      "681     0.641304     -0.800536        0.763992   0.510705         1.438475   \n",
      "682     0.355020     -0.040412        0.301040   0.263873        -0.435440   \n",
      "683     1.138957     -0.213487        1.051879   1.096085        -1.097436   \n",
      "684    -0.209521     -0.648511       -0.191867  -0.295524         0.811981   \n",
      "685    -0.337947      0.233232       -0.309745  -0.407768         0.255096   \n",
      "686    -0.236276     -0.676577       -0.210152  -0.356583         0.324707   \n",
      "687     0.785784      0.214522        0.818457   0.643214         0.944241   \n",
      "688     0.256025      0.113951        0.188220   0.131104        -0.136811   \n",
      "689     1.047988     -0.632139        0.974071   0.937593         0.519616   \n",
      "690    -0.391458      0.106935       -0.351761  -0.444143         0.429123   \n",
      "691     0.544984     -0.239214        0.503339   0.442112        -0.646360   \n",
      "692     0.785784      0.214522        0.818457   0.643214         0.944241   \n",
      "693     0.617224     -0.173726        0.662843   0.464716         1.125228   \n",
      "694     0.991801      0.488166        0.927387   0.932397        -0.253061   \n",
      "695     0.609198      0.972307        0.639501   0.475889         1.515047   \n",
      "696     0.159705     -1.301048        0.238795  -0.030505         0.651876   \n",
      "697    -1.014861      0.357191       -0.951653  -0.896494         1.723878   \n",
      "698     1.559018     -0.480115        1.421462   1.584551        -0.918537   \n",
      "699     1.489454      1.692670        1.421462   1.485819         0.143719   \n",
      "\n",
      "     compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
      "500          0.224235       -0.087831             0.437687       0.974025   \n",
      "501          2.939470        1.713724             2.265679       2.015003   \n",
      "502          0.107544        0.503822             0.625072       0.411824   \n",
      "503         -0.510568       -0.215114            -0.302536      -0.835900   \n",
      "504          0.104061        0.122685             0.181380       0.346536   \n",
      "505          1.035845        1.236413             1.838910       1.042940   \n",
      "506          2.828004        3.823633             3.067709       2.598967   \n",
      "507         -0.759624       -0.615486            -0.585822      -0.810510   \n",
      "508          1.194335        0.769787             0.544869       0.317519   \n",
      "509          0.224235       -0.087831             0.437687       0.974025   \n",
      "510          0.798980        1.324276             1.154609      -1.093424   \n",
      "511          0.565599        0.476513             0.600791       1.003041   \n",
      "512         -0.968100       -0.286948             0.029559      -1.049899   \n",
      "513          0.241651        1.501190             2.054747      -0.154005   \n",
      "514         -0.720785       -0.413994            -0.081548       0.676602   \n",
      "515          0.293901        0.500260             0.726123       0.926872   \n",
      "516          0.070970        0.177303             0.967468      -0.357122   \n",
      "517          1.410300        1.667418             2.277942      -0.056073   \n",
      "518         -0.122354        0.605933             0.641996      -1.419864   \n",
      "519         -0.538957       -0.165602             0.073462      -1.350949   \n",
      "520          1.758630        0.766225             0.158080       1.293210   \n",
      "521          0.104061        0.122685             0.181380       0.346536   \n",
      "522         -0.754225       -0.805936            -0.837714       0.023723   \n",
      "523         -0.158928        0.345905             0.753593       1.061075   \n",
      "524          0.243393       -0.000799            -0.026853       1.162634   \n",
      "525          1.371983        0.968073             0.890454       1.851784   \n",
      "526          1.641939        1.788527             0.909094       1.046567   \n",
      "527         -0.897389       -0.895936            -0.707721      -0.999120   \n",
      "528         -0.510568       -0.215114            -0.302536      -0.835900   \n",
      "529          0.565599        0.476513             0.600791       1.003041   \n",
      "..                ...             ...                  ...            ...   \n",
      "670         -0.211178       -0.140786            -0.103132      -0.904815   \n",
      "671          0.107544        0.161867             0.063160       0.400942   \n",
      "672          0.715381        1.173483             1.287054       0.458976   \n",
      "673          0.107544        0.161867             0.063160       0.400942   \n",
      "674         -0.501685        0.147619             0.672655      -0.444173   \n",
      "675         -0.158928        0.345905             0.753593       1.061075   \n",
      "676          0.645715        1.054749             1.674580       0.484366   \n",
      "677         -0.623253       -0.207396             0.317505      -0.099598   \n",
      "678         -0.019596        0.097751             0.181626      -0.618274   \n",
      "679         -0.962875       -0.920396            -0.541428      -0.799629   \n",
      "680          2.493607        2.547239             1.534776       0.992160   \n",
      "681          1.971111        1.407390             2.032673       4.354485   \n",
      "682         -0.525720       -0.079282             0.224548      -0.150377   \n",
      "683         -0.594690       -0.138412            -0.023420       0.386434   \n",
      "684          0.234685       -0.076907            -0.116867       0.248604   \n",
      "685          0.192885        0.022948            -0.069530      -0.433292   \n",
      "686          0.649198       -0.063609            -0.029551       0.966770   \n",
      "687          0.906962        0.963324             1.181588       0.477111   \n",
      "688         -0.460408       -0.456382            -0.130848      -0.803256   \n",
      "689         -0.077071        0.490761             0.721708       0.458976   \n",
      "690          0.508124       -0.070021             0.106818       0.487993   \n",
      "691         -0.393703       -0.239217             0.209341       0.194197   \n",
      "692          0.906962        0.963324             1.181588       0.477111   \n",
      "693          0.744989        1.028628             1.269885       1.057448   \n",
      "694         -0.301918        0.129809             0.275809      -0.534850   \n",
      "695          0.612623        1.630610             1.547040       1.481819   \n",
      "696          1.725539        1.226914             0.989297       2.472018   \n",
      "697          0.128444        0.000389            -0.013118       0.201452   \n",
      "698         -0.623253       -0.207396             0.317505      -0.099598   \n",
      "699         -0.097971        0.564376             0.885548      -0.092344   \n",
      "\n",
      "     fractal_dimension_mean    ...      perimeter_worst  area_worst  \\\n",
      "500               -1.065903    ...             0.665330    0.490369   \n",
      "501                1.398632    ...             1.745155    1.759747   \n",
      "502               -0.855640    ...             1.084951    1.014747   \n",
      "503               -0.547254    ...            -0.154330   -0.130731   \n",
      "504                0.003252    ...             0.329633    0.159435   \n",
      "505               -0.063013    ...             1.289167    1.312107   \n",
      "506                0.941151    ...             2.592789    2.192998   \n",
      "507               -0.785552    ...             0.100240    0.066710   \n",
      "508                0.237727    ...             1.048584    1.107472   \n",
      "509               -1.065903    ...             0.665330    0.490369   \n",
      "510                0.082260    ...             1.152090    1.073899   \n",
      "511                1.305607    ...            -0.022848   -0.230011   \n",
      "512               -1.662285    ...             0.416355    0.396045   \n",
      "513               -1.012381    ...             2.469700    3.065895   \n",
      "514               -1.373014    ...             0.444330    0.354478   \n",
      "515               -0.830154    ...             1.174470    1.217783   \n",
      "516               -1.432907    ...             0.908710    0.810111   \n",
      "517               -0.204462    ...             2.262687    1.980369   \n",
      "518               -0.902790    ...             1.359103    1.412826   \n",
      "519               -1.431633    ...             1.331129    1.217783   \n",
      "520                2.102057    ...            -0.625424   -0.767658   \n",
      "521                0.003252    ...             0.329633    0.159435   \n",
      "522               -1.243033    ...             0.368798    0.153040   \n",
      "523               -0.354832    ...             1.065369    0.982772   \n",
      "524               -0.521768    ...             0.435937    0.298523   \n",
      "525                1.387164    ...            -0.221469   -0.398036   \n",
      "526                1.085150    ...             0.407963   -0.117142   \n",
      "527               -1.265971    ...             0.393975    0.367268   \n",
      "528               -0.547254    ...            -0.154330   -0.130731   \n",
      "529                1.305607    ...            -0.022848   -0.230011   \n",
      "..                      ...    ...                  ...         ...   \n",
      "670               -0.831428    ...             0.352013    0.216989   \n",
      "671                0.210966    ...             0.105835    0.089092   \n",
      "672                0.979381    ...             0.304456    0.181817   \n",
      "673                0.210966    ...             0.105835    0.089092   \n",
      "674               -1.588374    ...             2.388574    3.444790   \n",
      "675               -0.354832    ...             1.065369    0.982772   \n",
      "676               -0.149667    ...             1.062571    0.874060   \n",
      "677               -0.807216    ...             1.250002    1.547118   \n",
      "678                0.310363    ...            -0.006064   -0.190203   \n",
      "679               -0.017137    ...            -0.811736   -0.694917   \n",
      "680                1.038000    ...             0.992634    0.504757   \n",
      "681                1.417747    ...             1.070964    0.755755   \n",
      "682               -1.158928    ...             0.410760    0.375261   \n",
      "683               -1.601117    ...             0.953470    0.878856   \n",
      "684               -0.217206    ...            -0.168317   -0.259428   \n",
      "685                0.151073    ...            -0.190697   -0.396277   \n",
      "686                0.784410    ...            -0.271824   -0.380770   \n",
      "687               -0.171330    ...             0.525456    0.501560   \n",
      "688               -0.957586    ...             0.424747    0.448802   \n",
      "689               -0.111437    ...             0.875141    0.896442   \n",
      "690                0.613651    ...            -0.028443   -0.129612   \n",
      "691               -0.976700    ...             0.463912    0.434414   \n",
      "692               -0.171330    ...             0.525456    0.501560   \n",
      "693                0.031287    ...             0.542241    0.320905   \n",
      "694               -0.730757    ...             0.880736    0.961989   \n",
      "695                0.103923    ...             0.614976    0.568706   \n",
      "696                0.932231    ...             0.307253   -0.011787   \n",
      "697                0.725791    ...            -0.752429   -0.758226   \n",
      "698               -0.807216    ...             1.250002    1.547118   \n",
      "699               -0.928276    ...             1.347914    1.368062   \n",
      "\n",
      "     smoothness_worst  compactness_worst  concavity_worst  \\\n",
      "500         -0.896319           0.005532        -0.371334   \n",
      "501          0.555056           2.615405         1.624964   \n",
      "502         -0.428790           0.193097         1.168426   \n",
      "503         -0.363742          -0.505709         0.016612   \n",
      "504          0.803050           0.897990         0.376053   \n",
      "505         -0.351545           0.153814         0.579602   \n",
      "506          1.408807           2.290623         2.884565   \n",
      "507          0.140377          -0.442634        -0.186937   \n",
      "508          0.937211           2.510279         1.529648   \n",
      "509         -0.896319           0.005532        -0.371334   \n",
      "510          0.087526           0.538351         0.783152   \n",
      "511          0.892491           0.552736         0.879359   \n",
      "512         -0.453182          -0.938936        -0.410530   \n",
      "513          0.652628          -0.099040         0.751528   \n",
      "514         -0.989825          -0.758563        -0.534352   \n",
      "515         -0.668653           0.377343         0.430392   \n",
      "516         -0.936974          -0.465319        -0.386478   \n",
      "517         -0.245843           0.568782         0.723467   \n",
      "518         -0.534492          -0.053117         0.451771   \n",
      "519         -0.514165          -0.302098         0.011713   \n",
      "520          3.372433           3.608562         2.347409   \n",
      "521          0.803050           0.897990         0.376053   \n",
      "522         -1.404504           0.034856        -0.291607   \n",
      "523          0.176967          -0.424928         0.011267   \n",
      "524          0.164770           0.109550        -0.062224   \n",
      "525          1.416938           1.407571         1.005853   \n",
      "526          0.254211           2.799650         3.816350   \n",
      "527         -0.465379          -0.758563        -0.855488   \n",
      "528         -0.363742          -0.505709         0.016612   \n",
      "529          0.892491           0.552736         0.879359   \n",
      "..                ...                ...              ...   \n",
      "670         -0.875992           0.131129         0.120836   \n",
      "671          0.803050           0.663395         0.817448   \n",
      "672          0.717675           0.401688         1.201831   \n",
      "673          0.803050           0.663395         0.817448   \n",
      "674          0.034675          -0.679995        -0.120572   \n",
      "675          0.176967          -0.424928         0.011267   \n",
      "676         -0.660522          -0.009407         0.397432   \n",
      "677         -0.473510          -0.548312        -0.318777   \n",
      "678          1.051045           0.393389         0.417475   \n",
      "679         -0.884123          -1.139559        -1.122285   \n",
      "680          2.108069           1.693069         2.628904   \n",
      "681          0.774592           0.604192         0.321268   \n",
      "682          0.591645          -0.449273        -0.134825   \n",
      "683         -1.355719          -0.328103         0.033537   \n",
      "684          0.640431           0.224082         0.034428   \n",
      "685          1.038848           0.756901         0.845508   \n",
      "686          0.429026           0.837128         0.670019   \n",
      "687          0.258276           0.354658         0.201009   \n",
      "688          0.242014           0.381770        -0.102311   \n",
      "689          0.603842          -0.313164         0.062489   \n",
      "690          0.713610           0.479702         0.237087   \n",
      "691         -0.758093          -0.408330        -0.362426   \n",
      "692          0.258276           0.354658         0.201009   \n",
      "693          1.416938           0.595893         0.840163   \n",
      "694          0.449354          -0.322016         0.371153   \n",
      "695          1.136420           0.388409         1.094043   \n",
      "696          0.144443           1.713541         1.413398   \n",
      "697          2.254426          -0.087974         0.396987   \n",
      "698         -0.473510          -0.548312        -0.318777   \n",
      "699          0.681086           0.048689         0.292317   \n",
      "\n",
      "     concave points_worst  symmetry_worst  fractal_dimension_worst  Actual  \\\n",
      "500              0.335130        0.127256                -0.544781  Malign   \n",
      "501              2.334276        1.590377                 2.031903  Malign   \n",
      "502              0.957410        1.388861                 0.323094  Malign   \n",
      "503             -0.165020       -0.463101                -0.586635  Malign   \n",
      "504              0.263888        1.441369                 0.973519  Malign   \n",
      "505              1.236563        0.141448                -0.503889  Malign   \n",
      "506              2.344454        1.529355                 0.564117  Malign   \n",
      "507              0.338038       -0.429042                -0.357639  Malign   \n",
      "508              0.874536        0.476362                 2.296499  Malign   \n",
      "509              0.335130        0.127256                -0.544781  Malign   \n",
      "510              0.615737       -1.159893                 0.328867  Malign   \n",
      "511              1.095533        0.862365                 1.190007  Malign   \n",
      "512             -0.005088       -0.582308                -1.385234  Malign   \n",
      "513              1.150782       -0.545410                -0.422585  Malign   \n",
      "514             -0.292965        0.422435                -1.033080  Malign   \n",
      "515              0.400557        1.009954                -0.119503  Malign   \n",
      "516              0.697157       -0.758279                -1.137957  Malign   \n",
      "517              1.649478       -0.335379                -0.020400  Malign   \n",
      "518              0.386017       -0.766794                -0.138746  Malign   \n",
      "519              0.214454       -1.049201                -0.716527  Malign   \n",
      "520              1.783239        1.669848                 2.604392  Malign   \n",
      "521              0.263888        1.441369                 0.973519  Malign   \n",
      "522             -0.616173        2.412052                -0.477910  Malign   \n",
      "523              0.500877        1.018469                -0.017994  Malign   \n",
      "524              0.021082        0.713356                -0.479834  Malign   \n",
      "525              1.108618        1.987733                 1.012006  Malign   \n",
      "526              1.538980        1.577605                 2.633257  Malign   \n",
      "527             -0.689160       -0.745507                -1.010951  Malign   \n",
      "528             -0.165020       -0.463101                -0.586635  Malign   \n",
      "529              1.095533        0.862365                 1.190007  Malign   \n",
      "..                    ...             ...                      ...     ...   \n",
      "670              0.175198       -1.077583                -0.383137  Malign   \n",
      "671              0.785847        2.519906                 0.728166  Malign   \n",
      "672              0.769853        0.338706                 0.713734  Malign   \n",
      "673              0.785847        2.519906                 0.728166  Malign   \n",
      "674              0.759676       -0.663198                -1.021053  Malign   \n",
      "675              0.500877        1.018469                -0.017994  Malign   \n",
      "676              0.971949       -0.350990                 0.023860  Malign   \n",
      "677              0.817833       -0.322607                 0.137396  Malign   \n",
      "678              0.769853        0.286199                 0.930222  Malign   \n",
      "679             -0.845457       -1.418174                -0.818517  Malign   \n",
      "680              0.969041        0.379861                 1.618171  Malign   \n",
      "681              1.821041        1.544965                 0.949465  Malign   \n",
      "682              0.323499       -0.464520                -1.072529  Malign   \n",
      "683             -0.115587       -0.193466                -0.998442  Malign   \n",
      "684              0.111226        0.128676                -0.317228  Malign   \n",
      "685              1.396495       -0.241717                 1.007195  Malign   \n",
      "686              0.518325        0.926225                 0.949465  Malign   \n",
      "687              0.316229       -0.729897                -0.422585  Malign   \n",
      "688              0.354031        0.652334                 0.007022  Malign   \n",
      "689              0.547403       -0.118253                -0.077167  Malign   \n",
      "690              0.282789        1.080910                 0.795518  Malign   \n",
      "691              0.256618       -0.237459                -0.667938  Malign   \n",
      "692              0.316229       -0.729897                -0.422585  Malign   \n",
      "693              1.810863        0.186860                 0.213888  Malign   \n",
      "694              0.118495        0.186860                -0.484164  Malign   \n",
      "695              0.798932        0.784313                -0.064659  Malign   \n",
      "696              1.592775        2.397861                 0.639647  Malign   \n",
      "697              0.183922       -0.018914                 0.476079  Malign   \n",
      "698              0.817833       -0.322607                 0.137396  Malign   \n",
      "699              0.580843        0.246463                -0.297023  Malign   \n",
      "\n",
      "     Predicted  \n",
      "500     Malign  \n",
      "501     Malign  \n",
      "502     Malign  \n",
      "503     Malign  \n",
      "504     Malign  \n",
      "505     Malign  \n",
      "506     Malign  \n",
      "507     Malign  \n",
      "508     Malign  \n",
      "509     Malign  \n",
      "510     Malign  \n",
      "511     Malign  \n",
      "512     Malign  \n",
      "513     Malign  \n",
      "514     Malign  \n",
      "515     Malign  \n",
      "516     Malign  \n",
      "517     Malign  \n",
      "518     Malign  \n",
      "519     Malign  \n",
      "520     Malign  \n",
      "521     Malign  \n",
      "522     Malign  \n",
      "523     Malign  \n",
      "524     Malign  \n",
      "525     Malign  \n",
      "526     Malign  \n",
      "527     Malign  \n",
      "528     Malign  \n",
      "529     Malign  \n",
      "..         ...  \n",
      "670     Malign  \n",
      "671     Malign  \n",
      "672     Malign  \n",
      "673     Malign  \n",
      "674     Malign  \n",
      "675     Malign  \n",
      "676     Malign  \n",
      "677     Malign  \n",
      "678     Malign  \n",
      "679     Malign  \n",
      "680     Malign  \n",
      "681     Malign  \n",
      "682     Malign  \n",
      "683     Malign  \n",
      "684     Malign  \n",
      "685     Malign  \n",
      "686     Malign  \n",
      "687     Malign  \n",
      "688     Malign  \n",
      "689     Malign  \n",
      "690     Malign  \n",
      "691     Malign  \n",
      "692     Malign  \n",
      "693     Malign  \n",
      "694     Malign  \n",
      "695     Malign  \n",
      "696     Malign  \n",
      "697     Malign  \n",
      "698     Malign  \n",
      "699     Malign  \n",
      "\n",
      "[200 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "data=pd.concat([df,df1],axis=1)\n",
    "print(data.iloc[500:700,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.321894</td>\n",
       "      <td>-1.277660</td>\n",
       "      <td>-0.346314</td>\n",
       "      <td>-0.389320</td>\n",
       "      <td>-0.010120</td>\n",
       "      <td>-0.577099</td>\n",
       "      <td>-0.447952</td>\n",
       "      <td>-0.230917</td>\n",
       "      <td>0.165181</td>\n",
       "      <td>-0.681058</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.403305</td>\n",
       "      <td>-0.442960</td>\n",
       "      <td>0.347717</td>\n",
       "      <td>-0.599768</td>\n",
       "      <td>-0.330357</td>\n",
       "      <td>-0.013812</td>\n",
       "      <td>-0.000465</td>\n",
       "      <td>-0.653024</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.444969</td>\n",
       "      <td>-0.961916</td>\n",
       "      <td>-0.417508</td>\n",
       "      <td>-0.509618</td>\n",
       "      <td>0.665798</td>\n",
       "      <td>0.219010</td>\n",
       "      <td>-0.696819</td>\n",
       "      <td>-0.640762</td>\n",
       "      <td>0.462603</td>\n",
       "      <td>0.650606</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.504294</td>\n",
       "      <td>-0.571976</td>\n",
       "      <td>-0.172664</td>\n",
       "      <td>-0.044818</td>\n",
       "      <td>-0.553059</td>\n",
       "      <td>-0.827573</td>\n",
       "      <td>0.293294</td>\n",
       "      <td>-0.208503</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.401746</td>\n",
       "      <td>-1.726718</td>\n",
       "      <td>-1.401378</td>\n",
       "      <td>-1.149042</td>\n",
       "      <td>0.310785</td>\n",
       "      <td>-0.862207</td>\n",
       "      <td>-0.888219</td>\n",
       "      <td>-0.894371</td>\n",
       "      <td>-0.088717</td>\n",
       "      <td>0.770393</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.370391</td>\n",
       "      <td>-1.076530</td>\n",
       "      <td>-0.123879</td>\n",
       "      <td>-0.945575</td>\n",
       "      <td>-0.999933</td>\n",
       "      <td>-0.981108</td>\n",
       "      <td>-0.748346</td>\n",
       "      <td>-0.405747</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.458347</td>\n",
       "      <td>-0.328090</td>\n",
       "      <td>-0.534997</td>\n",
       "      <td>-0.499745</td>\n",
       "      <td>-0.564220</td>\n",
       "      <td>-1.336981</td>\n",
       "      <td>-0.935000</td>\n",
       "      <td>-0.686628</td>\n",
       "      <td>-1.350949</td>\n",
       "      <td>-0.557449</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.829640</td>\n",
       "      <td>-0.707227</td>\n",
       "      <td>-1.562651</td>\n",
       "      <td>-1.325188</td>\n",
       "      <td>-1.179608</td>\n",
       "      <td>-1.157614</td>\n",
       "      <td>-1.405402</td>\n",
       "      <td>-1.177406</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.751708</td>\n",
       "      <td>-0.697627</td>\n",
       "      <td>-1.737116</td>\n",
       "      <td>-1.336114</td>\n",
       "      <td>-0.830828</td>\n",
       "      <td>-0.957824</td>\n",
       "      <td>-1.050647</td>\n",
       "      <td>-1.258424</td>\n",
       "      <td>-0.255563</td>\n",
       "      <td>0.258116</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.590552</td>\n",
       "      <td>-1.192756</td>\n",
       "      <td>-0.233647</td>\n",
       "      <td>-0.829937</td>\n",
       "      <td>-1.088434</td>\n",
       "      <td>-1.513681</td>\n",
       "      <td>0.181183</td>\n",
       "      <td>-0.580862</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.720551</td>\n",
       "      <td>-1.214511</td>\n",
       "      <td>-0.712786</td>\n",
       "      <td>-0.693313</td>\n",
       "      <td>0.359512</td>\n",
       "      <td>-0.409378</td>\n",
       "      <td>-0.456501</td>\n",
       "      <td>-0.729305</td>\n",
       "      <td>-0.596511</td>\n",
       "      <td>-0.328071</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.678017</td>\n",
       "      <td>-0.648554</td>\n",
       "      <td>0.567253</td>\n",
       "      <td>-0.387858</td>\n",
       "      <td>-0.036391</td>\n",
       "      <td>-0.934437</td>\n",
       "      <td>-0.326865</td>\n",
       "      <td>-0.151735</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.335272</td>\n",
       "      <td>0.579381</td>\n",
       "      <td>-0.367711</td>\n",
       "      <td>-0.403091</td>\n",
       "      <td>-0.725020</td>\n",
       "      <td>-0.652164</td>\n",
       "      <td>-0.675091</td>\n",
       "      <td>-0.573559</td>\n",
       "      <td>-0.110479</td>\n",
       "      <td>-0.742225</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.422887</td>\n",
       "      <td>-0.462784</td>\n",
       "      <td>-0.782486</td>\n",
       "      <td>-0.634072</td>\n",
       "      <td>-0.378461</td>\n",
       "      <td>-0.022535</td>\n",
       "      <td>-0.150893</td>\n",
       "      <td>-0.817555</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.798142</td>\n",
       "      <td>0.415662</td>\n",
       "      <td>-0.841945</td>\n",
       "      <td>-0.748915</td>\n",
       "      <td>-0.805072</td>\n",
       "      <td>-1.127983</td>\n",
       "      <td>-1.042455</td>\n",
       "      <td>-1.130075</td>\n",
       "      <td>-1.249390</td>\n",
       "      <td>-0.525591</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.871042</td>\n",
       "      <td>-0.754229</td>\n",
       "      <td>-1.095528</td>\n",
       "      <td>-1.104093</td>\n",
       "      <td>-1.148875</td>\n",
       "      <td>-1.346334</td>\n",
       "      <td>-0.772471</td>\n",
       "      <td>-0.987859</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.295138</td>\n",
       "      <td>-0.814569</td>\n",
       "      <td>-0.356040</td>\n",
       "      <td>-0.375030</td>\n",
       "      <td>-1.467764</td>\n",
       "      <td>-0.937621</td>\n",
       "      <td>-1.018708</td>\n",
       "      <td>-0.980951</td>\n",
       "      <td>-1.764438</td>\n",
       "      <td>-0.442760</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.504573</td>\n",
       "      <td>-0.530090</td>\n",
       "      <td>-1.079266</td>\n",
       "      <td>-0.705447</td>\n",
       "      <td>-0.927198</td>\n",
       "      <td>-0.638127</td>\n",
       "      <td>-0.895935</td>\n",
       "      <td>-0.284514</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.749982</td>\n",
       "      <td>-0.370189</td>\n",
       "      <td>-0.803431</td>\n",
       "      <td>-0.723712</td>\n",
       "      <td>-1.066808</td>\n",
       "      <td>-1.165429</td>\n",
       "      <td>-1.005053</td>\n",
       "      <td>-1.072682</td>\n",
       "      <td>0.103520</td>\n",
       "      <td>-0.242692</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.851740</td>\n",
       "      <td>-0.737123</td>\n",
       "      <td>-0.855665</td>\n",
       "      <td>-1.087992</td>\n",
       "      <td>-0.984967</td>\n",
       "      <td>-0.971076</td>\n",
       "      <td>-0.272938</td>\n",
       "      <td>-0.581343</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.862355</td>\n",
       "      <td>-0.250908</td>\n",
       "      <td>-0.895632</td>\n",
       "      <td>-0.798021</td>\n",
       "      <td>-0.187627</td>\n",
       "      <td>-1.039682</td>\n",
       "      <td>-0.878720</td>\n",
       "      <td>-0.844826</td>\n",
       "      <td>0.292129</td>\n",
       "      <td>-0.501379</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.903773</td>\n",
       "      <td>-0.770696</td>\n",
       "      <td>-0.428790</td>\n",
       "      <td>-1.098283</td>\n",
       "      <td>-0.990624</td>\n",
       "      <td>-0.968168</td>\n",
       "      <td>0.466428</td>\n",
       "      <td>-0.760306</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.452996</td>\n",
       "      <td>-0.119933</td>\n",
       "      <td>-0.534997</td>\n",
       "      <td>-0.490911</td>\n",
       "      <td>-1.206725</td>\n",
       "      <td>-1.332976</td>\n",
       "      <td>-1.230981</td>\n",
       "      <td>-1.301346</td>\n",
       "      <td>-0.074208</td>\n",
       "      <td>-1.018753</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.667946</td>\n",
       "      <td>-0.582208</td>\n",
       "      <td>-1.355719</td>\n",
       "      <td>-1.238211</td>\n",
       "      <td>-1.386654</td>\n",
       "      <td>-1.724936</td>\n",
       "      <td>-0.763956</td>\n",
       "      <td>-1.119675</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-1.638800</td>\n",
       "      <td>-1.878742</td>\n",
       "      <td>-1.634799</td>\n",
       "      <td>-1.277394</td>\n",
       "      <td>-0.028915</td>\n",
       "      <td>-1.074689</td>\n",
       "      <td>-0.994486</td>\n",
       "      <td>-1.212264</td>\n",
       "      <td>-0.567494</td>\n",
       "      <td>1.129751</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.516699</td>\n",
       "      <td>-1.140478</td>\n",
       "      <td>1.538902</td>\n",
       "      <td>-0.895226</td>\n",
       "      <td>-0.874640</td>\n",
       "      <td>-1.243978</td>\n",
       "      <td>0.344383</td>\n",
       "      <td>0.197050</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-1.223554</td>\n",
       "      <td>-1.156040</td>\n",
       "      <td>-1.237594</td>\n",
       "      <td>-1.050309</td>\n",
       "      <td>1.076501</td>\n",
       "      <td>-0.588942</td>\n",
       "      <td>-1.110489</td>\n",
       "      <td>-1.087152</td>\n",
       "      <td>3.277235</td>\n",
       "      <td>0.840480</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.238071</td>\n",
       "      <td>-0.990679</td>\n",
       "      <td>-0.323087</td>\n",
       "      <td>-1.034876</td>\n",
       "      <td>-1.298308</td>\n",
       "      <td>-1.511500</td>\n",
       "      <td>0.822629</td>\n",
       "      <td>-0.286920</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-1.644151</td>\n",
       "      <td>0.270654</td>\n",
       "      <td>-1.622350</td>\n",
       "      <td>-1.284409</td>\n",
       "      <td>1.835255</td>\n",
       "      <td>-0.431845</td>\n",
       "      <td>-0.882994</td>\n",
       "      <td>-1.176455</td>\n",
       "      <td>-0.041564</td>\n",
       "      <td>0.581793</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.456274</td>\n",
       "      <td>-1.142077</td>\n",
       "      <td>1.156747</td>\n",
       "      <td>-0.641265</td>\n",
       "      <td>-0.993964</td>\n",
       "      <td>-1.482567</td>\n",
       "      <td>-0.007561</td>\n",
       "      <td>-0.435094</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-1.490306</td>\n",
       "      <td>-1.394602</td>\n",
       "      <td>-1.445728</td>\n",
       "      <td>-1.182819</td>\n",
       "      <td>-1.442705</td>\n",
       "      <td>-0.468768</td>\n",
       "      <td>-0.528216</td>\n",
       "      <td>-0.868863</td>\n",
       "      <td>1.819140</td>\n",
       "      <td>0.844303</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.357523</td>\n",
       "      <td>-1.084204</td>\n",
       "      <td>-1.507767</td>\n",
       "      <td>-0.652331</td>\n",
       "      <td>-0.772643</td>\n",
       "      <td>-1.146855</td>\n",
       "      <td>0.432369</td>\n",
       "      <td>-0.060811</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-1.412180</td>\n",
       "      <td>0.277670</td>\n",
       "      <td>-1.410326</td>\n",
       "      <td>-1.160734</td>\n",
       "      <td>0.450006</td>\n",
       "      <td>-0.639102</td>\n",
       "      <td>-0.981306</td>\n",
       "      <td>-1.034665</td>\n",
       "      <td>-0.444173</td>\n",
       "      <td>0.762747</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.317239</td>\n",
       "      <td>-1.051270</td>\n",
       "      <td>0.786788</td>\n",
       "      <td>-0.660077</td>\n",
       "      <td>-0.975658</td>\n",
       "      <td>-0.938944</td>\n",
       "      <td>-0.140959</td>\n",
       "      <td>0.286051</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.918541</td>\n",
       "      <td>-0.183082</td>\n",
       "      <td>-0.955544</td>\n",
       "      <td>-0.836735</td>\n",
       "      <td>-1.151733</td>\n",
       "      <td>-1.174137</td>\n",
       "      <td>-0.798812</td>\n",
       "      <td>-0.856599</td>\n",
       "      <td>-1.173221</td>\n",
       "      <td>-0.807216</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.010356</td>\n",
       "      <td>-0.833845</td>\n",
       "      <td>-0.262105</td>\n",
       "      <td>-1.074603</td>\n",
       "      <td>-0.751709</td>\n",
       "      <td>-0.874390</td>\n",
       "      <td>-0.819302</td>\n",
       "      <td>-0.950334</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-1.528834</td>\n",
       "      <td>-0.583024</td>\n",
       "      <td>-1.461679</td>\n",
       "      <td>-1.209840</td>\n",
       "      <td>0.603149</td>\n",
       "      <td>0.468066</td>\n",
       "      <td>2.477186</td>\n",
       "      <td>-0.330497</td>\n",
       "      <td>0.984906</td>\n",
       "      <td>2.224392</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.360041</td>\n",
       "      <td>-1.060862</td>\n",
       "      <td>0.518467</td>\n",
       "      <td>0.834361</td>\n",
       "      <td>4.181581</td>\n",
       "      <td>0.657901</td>\n",
       "      <td>1.774864</td>\n",
       "      <td>1.507522</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.525236</td>\n",
       "      <td>-0.779486</td>\n",
       "      <td>-0.583237</td>\n",
       "      <td>-0.555087</td>\n",
       "      <td>0.026078</td>\n",
       "      <td>-1.081307</td>\n",
       "      <td>-0.805461</td>\n",
       "      <td>-0.701099</td>\n",
       "      <td>-0.904815</td>\n",
       "      <td>-0.825056</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.795790</td>\n",
       "      <td>-0.692839</td>\n",
       "      <td>-0.237712</td>\n",
       "      <td>-1.190074</td>\n",
       "      <td>-0.932098</td>\n",
       "      <td>-1.031268</td>\n",
       "      <td>-0.843427</td>\n",
       "      <td>-1.061464</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-1.566560</td>\n",
       "      <td>-1.212172</td>\n",
       "      <td>-1.461679</td>\n",
       "      <td>-1.226729</td>\n",
       "      <td>-0.007335</td>\n",
       "      <td>0.673581</td>\n",
       "      <td>-0.217370</td>\n",
       "      <td>-0.699136</td>\n",
       "      <td>0.226841</td>\n",
       "      <td>3.414607</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.442286</td>\n",
       "      <td>-1.125291</td>\n",
       "      <td>-0.599540</td>\n",
       "      <td>-0.232937</td>\n",
       "      <td>-0.756163</td>\n",
       "      <td>-1.190618</td>\n",
       "      <td>-1.026495</td>\n",
       "      <td>1.069736</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.650986</td>\n",
       "      <td>-0.772470</td>\n",
       "      <td>-0.668047</td>\n",
       "      <td>-0.637191</td>\n",
       "      <td>-0.432656</td>\n",
       "      <td>-0.803514</td>\n",
       "      <td>-0.838825</td>\n",
       "      <td>-0.846298</td>\n",
       "      <td>-0.433292</td>\n",
       "      <td>-0.492459</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.682772</td>\n",
       "      <td>-0.602991</td>\n",
       "      <td>-0.725569</td>\n",
       "      <td>-0.561038</td>\n",
       "      <td>-0.636350</td>\n",
       "      <td>-0.627368</td>\n",
       "      <td>-0.509932</td>\n",
       "      <td>-0.484645</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.324569</td>\n",
       "      <td>-2.077544</td>\n",
       "      <td>-0.328808</td>\n",
       "      <td>-0.407768</td>\n",
       "      <td>2.169386</td>\n",
       "      <td>-0.169378</td>\n",
       "      <td>-0.422662</td>\n",
       "      <td>0.204436</td>\n",
       "      <td>2.044020</td>\n",
       "      <td>0.433972</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.636614</td>\n",
       "      <td>-0.611944</td>\n",
       "      <td>0.392437</td>\n",
       "      <td>-0.817765</td>\n",
       "      <td>-1.014542</td>\n",
       "      <td>-0.809545</td>\n",
       "      <td>-0.379372</td>\n",
       "      <td>-0.685738</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.503831</td>\n",
       "      <td>-0.426321</td>\n",
       "      <td>-0.512433</td>\n",
       "      <td>-0.545214</td>\n",
       "      <td>0.097776</td>\n",
       "      <td>-0.330307</td>\n",
       "      <td>-0.777440</td>\n",
       "      <td>-0.835751</td>\n",
       "      <td>-0.440546</td>\n",
       "      <td>-0.386690</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.622067</td>\n",
       "      <td>-0.585405</td>\n",
       "      <td>-0.266170</td>\n",
       "      <td>-0.396157</td>\n",
       "      <td>-0.623878</td>\n",
       "      <td>-0.734086</td>\n",
       "      <td>-0.281452</td>\n",
       "      <td>-0.335990</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.881084</td>\n",
       "      <td>0.268315</td>\n",
       "      <td>-0.877348</td>\n",
       "      <td>-0.817508</td>\n",
       "      <td>0.853747</td>\n",
       "      <td>-0.362353</td>\n",
       "      <td>-0.694088</td>\n",
       "      <td>-0.855863</td>\n",
       "      <td>0.009215</td>\n",
       "      <td>0.897825</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.827681</td>\n",
       "      <td>-0.740480</td>\n",
       "      <td>0.823378</td>\n",
       "      <td>-0.653438</td>\n",
       "      <td>-0.613189</td>\n",
       "      <td>-0.995647</td>\n",
       "      <td>-0.305578</td>\n",
       "      <td>0.112861</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.375405</td>\n",
       "      <td>-0.926834</td>\n",
       "      <td>-0.384051</td>\n",
       "      <td>-0.509618</td>\n",
       "      <td>0.686682</td>\n",
       "      <td>0.680548</td>\n",
       "      <td>0.148806</td>\n",
       "      <td>0.310147</td>\n",
       "      <td>0.371925</td>\n",
       "      <td>0.766570</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.488348</td>\n",
       "      <td>-0.596916</td>\n",
       "      <td>0.738003</td>\n",
       "      <td>1.070063</td>\n",
       "      <td>0.768899</td>\n",
       "      <td>0.596836</td>\n",
       "      <td>0.780055</td>\n",
       "      <td>0.742599</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.733928</td>\n",
       "      <td>-0.975949</td>\n",
       "      <td>-0.755191</td>\n",
       "      <td>-0.708902</td>\n",
       "      <td>-0.049102</td>\n",
       "      <td>-0.744994</td>\n",
       "      <td>-0.746331</td>\n",
       "      <td>-0.946613</td>\n",
       "      <td>0.868839</td>\n",
       "      <td>-0.423645</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.736764</td>\n",
       "      <td>-0.672055</td>\n",
       "      <td>0.091592</td>\n",
       "      <td>-0.472511</td>\n",
       "      <td>-0.385142</td>\n",
       "      <td>-0.776832</td>\n",
       "      <td>0.570024</td>\n",
       "      <td>-0.333104</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.637609</td>\n",
       "      <td>0.462439</td>\n",
       "      <td>-0.645094</td>\n",
       "      <td>-0.649663</td>\n",
       "      <td>-0.711098</td>\n",
       "      <td>-0.347898</td>\n",
       "      <td>-0.525011</td>\n",
       "      <td>-0.485016</td>\n",
       "      <td>0.328400</td>\n",
       "      <td>0.131958</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.633817</td>\n",
       "      <td>-0.661184</td>\n",
       "      <td>-0.205188</td>\n",
       "      <td>-0.217998</td>\n",
       "      <td>-0.310760</td>\n",
       "      <td>-0.134488</td>\n",
       "      <td>-0.007561</td>\n",
       "      <td>0.310105</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.027583</td>\n",
       "      <td>-1.071842</td>\n",
       "      <td>-0.023026</td>\n",
       "      <td>-0.166912</td>\n",
       "      <td>1.062578</td>\n",
       "      <td>0.339184</td>\n",
       "      <td>-0.055891</td>\n",
       "      <td>0.329032</td>\n",
       "      <td>1.003041</td>\n",
       "      <td>0.058048</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.131950</td>\n",
       "      <td>-0.295239</td>\n",
       "      <td>-0.314956</td>\n",
       "      <td>0.128362</td>\n",
       "      <td>-0.235041</td>\n",
       "      <td>0.144666</td>\n",
       "      <td>0.246463</td>\n",
       "      <td>-0.068989</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.032934</td>\n",
       "      <td>0.981662</td>\n",
       "      <td>-0.069710</td>\n",
       "      <td>-0.138852</td>\n",
       "      <td>-0.570485</td>\n",
       "      <td>-0.494022</td>\n",
       "      <td>-0.870884</td>\n",
       "      <td>-0.678289</td>\n",
       "      <td>-0.560240</td>\n",
       "      <td>-0.553626</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.313786</td>\n",
       "      <td>-0.295079</td>\n",
       "      <td>-0.973564</td>\n",
       "      <td>-0.603641</td>\n",
       "      <td>-0.985591</td>\n",
       "      <td>-0.876571</td>\n",
       "      <td>-0.646168</td>\n",
       "      <td>-0.659279</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-0.394134</td>\n",
       "      <td>-1.184106</td>\n",
       "      <td>-0.452132</td>\n",
       "      <td>-0.427255</td>\n",
       "      <td>-1.697479</td>\n",
       "      <td>-1.112483</td>\n",
       "      <td>-0.852005</td>\n",
       "      <td>-0.754077</td>\n",
       "      <td>-1.644744</td>\n",
       "      <td>-1.251954</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.269026</td>\n",
       "      <td>-0.252074</td>\n",
       "      <td>-1.416701</td>\n",
       "      <td>-0.895779</td>\n",
       "      <td>-0.793577</td>\n",
       "      <td>-0.431088</td>\n",
       "      <td>-1.348637</td>\n",
       "      <td>-1.159605</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>-0.345974</td>\n",
       "      <td>-0.356156</td>\n",
       "      <td>-0.379771</td>\n",
       "      <td>-0.418421</td>\n",
       "      <td>0.296863</td>\n",
       "      <td>-0.570829</td>\n",
       "      <td>-0.767347</td>\n",
       "      <td>-0.721701</td>\n",
       "      <td>-0.730714</td>\n",
       "      <td>-0.752420</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.462331</td>\n",
       "      <td>-0.461825</td>\n",
       "      <td>-0.062896</td>\n",
       "      <td>-0.611941</td>\n",
       "      <td>-0.779770</td>\n",
       "      <td>-0.736267</td>\n",
       "      <td>-0.424784</td>\n",
       "      <td>-0.968615</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>-0.685769</td>\n",
       "      <td>-0.463743</td>\n",
       "      <td>-0.722512</td>\n",
       "      <td>-0.688636</td>\n",
       "      <td>0.456967</td>\n",
       "      <td>-0.763804</td>\n",
       "      <td>-0.943549</td>\n",
       "      <td>-0.682213</td>\n",
       "      <td>0.219587</td>\n",
       "      <td>0.426326</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.894541</td>\n",
       "      <td>-0.788282</td>\n",
       "      <td>-0.871927</td>\n",
       "      <td>-1.062983</td>\n",
       "      <td>-1.173061</td>\n",
       "      <td>-1.031268</td>\n",
       "      <td>-1.064811</td>\n",
       "      <td>-0.596738</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>-1.326028</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>-1.332519</td>\n",
       "      <td>-1.095518</td>\n",
       "      <td>0.310785</td>\n",
       "      <td>-1.069638</td>\n",
       "      <td>-1.158114</td>\n",
       "      <td>-1.208880</td>\n",
       "      <td>-1.775320</td>\n",
       "      <td>0.751278</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.267444</td>\n",
       "      <td>-0.994676</td>\n",
       "      <td>-0.156402</td>\n",
       "      <td>-1.056621</td>\n",
       "      <td>-1.303609</td>\n",
       "      <td>-1.540287</td>\n",
       "      <td>-1.480616</td>\n",
       "      <td>0.178769</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>-0.840950</td>\n",
       "      <td>-1.633164</td>\n",
       "      <td>-0.856729</td>\n",
       "      <td>-0.788668</td>\n",
       "      <td>-0.564220</td>\n",
       "      <td>-0.682295</td>\n",
       "      <td>-0.740988</td>\n",
       "      <td>-0.581898</td>\n",
       "      <td>-0.796002</td>\n",
       "      <td>0.358787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.871602</td>\n",
       "      <td>-0.760624</td>\n",
       "      <td>0.311128</td>\n",
       "      <td>-0.556612</td>\n",
       "      <td>-0.538806</td>\n",
       "      <td>-0.658046</td>\n",
       "      <td>-0.291386</td>\n",
       "      <td>0.067158</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>-2.076787</td>\n",
       "      <td>-1.495172</td>\n",
       "      <td>-2.045232</td>\n",
       "      <td>-1.487850</td>\n",
       "      <td>1.327098</td>\n",
       "      <td>-0.674806</td>\n",
       "      <td>-1.239197</td>\n",
       "      <td>-1.403550</td>\n",
       "      <td>0.328400</td>\n",
       "      <td>1.933847</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.782179</td>\n",
       "      <td>-1.283883</td>\n",
       "      <td>0.933146</td>\n",
       "      <td>-0.915697</td>\n",
       "      <td>-1.394872</td>\n",
       "      <td>-1.886467</td>\n",
       "      <td>-0.064326</td>\n",
       "      <td>0.368316</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>-0.685769</td>\n",
       "      <td>0.163067</td>\n",
       "      <td>-0.744687</td>\n",
       "      <td>-0.668890</td>\n",
       "      <td>-1.239442</td>\n",
       "      <td>-1.289609</td>\n",
       "      <td>-0.956254</td>\n",
       "      <td>-0.969423</td>\n",
       "      <td>-0.364377</td>\n",
       "      <td>-0.794473</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.826283</td>\n",
       "      <td>-0.704190</td>\n",
       "      <td>-0.941040</td>\n",
       "      <td>-1.090427</td>\n",
       "      <td>-0.884885</td>\n",
       "      <td>-0.806055</td>\n",
       "      <td>-0.402078</td>\n",
       "      <td>-0.836317</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>-1.302215</td>\n",
       "      <td>-0.098883</td>\n",
       "      <td>-1.260937</td>\n",
       "      <td>-1.085645</td>\n",
       "      <td>0.178525</td>\n",
       "      <td>-0.304008</td>\n",
       "      <td>-0.508507</td>\n",
       "      <td>-0.660629</td>\n",
       "      <td>0.382807</td>\n",
       "      <td>0.027464</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.172050</td>\n",
       "      <td>-1.002509</td>\n",
       "      <td>0.831509</td>\n",
       "      <td>-0.307077</td>\n",
       "      <td>-0.217225</td>\n",
       "      <td>-0.469036</td>\n",
       "      <td>-0.504256</td>\n",
       "      <td>-0.060811</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>-1.137937</td>\n",
       "      <td>-0.124611</td>\n",
       "      <td>-1.126330</td>\n",
       "      <td>-0.987432</td>\n",
       "      <td>0.136062</td>\n",
       "      <td>-0.498899</td>\n",
       "      <td>-0.883588</td>\n",
       "      <td>-1.108981</td>\n",
       "      <td>1.369379</td>\n",
       "      <td>0.230081</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.116101</td>\n",
       "      <td>-0.936003</td>\n",
       "      <td>-0.550754</td>\n",
       "      <td>-0.758563</td>\n",
       "      <td>-1.039128</td>\n",
       "      <td>-1.420775</td>\n",
       "      <td>-0.214753</td>\n",
       "      <td>-0.512067</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>-0.830248</td>\n",
       "      <td>-0.349139</td>\n",
       "      <td>-0.824439</td>\n",
       "      <td>-0.788928</td>\n",
       "      <td>1.132189</td>\n",
       "      <td>-0.221628</td>\n",
       "      <td>-0.399746</td>\n",
       "      <td>-0.548786</td>\n",
       "      <td>-0.139496</td>\n",
       "      <td>0.279779</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.800266</td>\n",
       "      <td>-0.745916</td>\n",
       "      <td>1.355955</td>\n",
       "      <td>-0.108999</td>\n",
       "      <td>-0.115227</td>\n",
       "      <td>-0.115587</td>\n",
       "      <td>-0.243136</td>\n",
       "      <td>0.231207</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>-0.637609</td>\n",
       "      <td>-0.300024</td>\n",
       "      <td>-0.675049</td>\n",
       "      <td>-0.648104</td>\n",
       "      <td>-0.916449</td>\n",
       "      <td>-0.805952</td>\n",
       "      <td>-0.925383</td>\n",
       "      <td>-0.932387</td>\n",
       "      <td>-0.861290</td>\n",
       "      <td>-0.298762</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.798868</td>\n",
       "      <td>-0.710105</td>\n",
       "      <td>-0.693046</td>\n",
       "      <td>-0.494643</td>\n",
       "      <td>-0.532125</td>\n",
       "      <td>-0.659064</td>\n",
       "      <td>0.008050</td>\n",
       "      <td>-0.688625</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>-0.910515</td>\n",
       "      <td>0.336141</td>\n",
       "      <td>-0.929089</td>\n",
       "      <td>-0.830499</td>\n",
       "      <td>-0.720147</td>\n",
       "      <td>-0.847752</td>\n",
       "      <td>-0.629734</td>\n",
       "      <td>-0.937783</td>\n",
       "      <td>-1.278407</td>\n",
       "      <td>0.291248</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.842788</td>\n",
       "      <td>-0.751671</td>\n",
       "      <td>1.400676</td>\n",
       "      <td>-0.365726</td>\n",
       "      <td>-0.005213</td>\n",
       "      <td>-0.682908</td>\n",
       "      <td>-0.210496</td>\n",
       "      <td>0.103720</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>-1.328703</td>\n",
       "      <td>-0.662544</td>\n",
       "      <td>-1.317347</td>\n",
       "      <td>-1.106691</td>\n",
       "      <td>0.401278</td>\n",
       "      <td>-0.529204</td>\n",
       "      <td>-0.724603</td>\n",
       "      <td>-0.967461</td>\n",
       "      <td>-0.926578</td>\n",
       "      <td>0.974284</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.187157</td>\n",
       "      <td>-0.993237</td>\n",
       "      <td>0.457485</td>\n",
       "      <td>-0.604195</td>\n",
       "      <td>-0.815847</td>\n",
       "      <td>-1.110943</td>\n",
       "      <td>-0.630558</td>\n",
       "      <td>-0.071394</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>-0.565369</td>\n",
       "      <td>0.219199</td>\n",
       "      <td>-0.552892</td>\n",
       "      <td>-0.612508</td>\n",
       "      <td>0.097080</td>\n",
       "      <td>0.112769</td>\n",
       "      <td>0.025323</td>\n",
       "      <td>0.073217</td>\n",
       "      <td>-0.378885</td>\n",
       "      <td>0.980655</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.702634</td>\n",
       "      <td>-0.736803</td>\n",
       "      <td>-0.274301</td>\n",
       "      <td>-0.335849</td>\n",
       "      <td>-0.407858</td>\n",
       "      <td>-0.279880</td>\n",
       "      <td>-1.066230</td>\n",
       "      <td>-0.062735</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>-0.129254</td>\n",
       "      <td>-0.040412</td>\n",
       "      <td>0.057115</td>\n",
       "      <td>-0.224073</td>\n",
       "      <td>-1.361956</td>\n",
       "      <td>1.896220</td>\n",
       "      <td>2.326393</td>\n",
       "      <td>0.509060</td>\n",
       "      <td>-0.491325</td>\n",
       "      <td>1.871405</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.199089</td>\n",
       "      <td>-0.446477</td>\n",
       "      <td>-1.868375</td>\n",
       "      <td>0.739195</td>\n",
       "      <td>1.626300</td>\n",
       "      <td>0.301690</td>\n",
       "      <td>-0.822140</td>\n",
       "      <td>1.060114</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>-1.132585</td>\n",
       "      <td>0.085885</td>\n",
       "      <td>-1.078479</td>\n",
       "      <td>-0.992369</td>\n",
       "      <td>0.992968</td>\n",
       "      <td>0.276485</td>\n",
       "      <td>-0.470274</td>\n",
       "      <td>-0.651064</td>\n",
       "      <td>0.299383</td>\n",
       "      <td>1.887971</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.160861</td>\n",
       "      <td>-0.981406</td>\n",
       "      <td>-0.221450</td>\n",
       "      <td>-0.447060</td>\n",
       "      <td>-0.818074</td>\n",
       "      <td>-0.994339</td>\n",
       "      <td>-0.843427</td>\n",
       "      <td>0.197050</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>-1.609904</td>\n",
       "      <td>-0.933850</td>\n",
       "      <td>-1.576444</td>\n",
       "      <td>-1.260765</td>\n",
       "      <td>1.187877</td>\n",
       "      <td>-0.564559</td>\n",
       "      <td>-0.748587</td>\n",
       "      <td>-0.931652</td>\n",
       "      <td>-0.690816</td>\n",
       "      <td>1.698098</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.388575</td>\n",
       "      <td>-1.125291</td>\n",
       "      <td>1.502313</td>\n",
       "      <td>-0.272773</td>\n",
       "      <td>-0.300961</td>\n",
       "      <td>-0.359846</td>\n",
       "      <td>-0.072841</td>\n",
       "      <td>0.747410</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>-0.752657</td>\n",
       "      <td>0.399290</td>\n",
       "      <td>-0.771530</td>\n",
       "      <td>-0.721114</td>\n",
       "      <td>-0.017777</td>\n",
       "      <td>-0.625865</td>\n",
       "      <td>-0.844050</td>\n",
       "      <td>-0.911049</td>\n",
       "      <td>-0.549359</td>\n",
       "      <td>-0.135649</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.743478</td>\n",
       "      <td>-0.647915</td>\n",
       "      <td>0.591645</td>\n",
       "      <td>-0.253408</td>\n",
       "      <td>-0.725430</td>\n",
       "      <td>-0.832808</td>\n",
       "      <td>-0.765375</td>\n",
       "      <td>-0.036275</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>-1.549971</td>\n",
       "      <td>-0.950222</td>\n",
       "      <td>-1.463624</td>\n",
       "      <td>-1.223611</td>\n",
       "      <td>-0.230785</td>\n",
       "      <td>0.171985</td>\n",
       "      <td>-0.139362</td>\n",
       "      <td>-0.837468</td>\n",
       "      <td>-1.938539</td>\n",
       "      <td>1.099167</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.420466</td>\n",
       "      <td>-1.148312</td>\n",
       "      <td>-0.713373</td>\n",
       "      <td>-0.541120</td>\n",
       "      <td>-0.707169</td>\n",
       "      <td>-1.327287</td>\n",
       "      <td>-1.880810</td>\n",
       "      <td>-0.430283</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>-0.891786</td>\n",
       "      <td>-2.105610</td>\n",
       "      <td>-0.895632</td>\n",
       "      <td>-0.812831</td>\n",
       "      <td>-0.292739</td>\n",
       "      <td>-0.828593</td>\n",
       "      <td>-0.822202</td>\n",
       "      <td>-0.760208</td>\n",
       "      <td>-0.625528</td>\n",
       "      <td>-0.238869</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.849782</td>\n",
       "      <td>-0.763822</td>\n",
       "      <td>0.786788</td>\n",
       "      <td>-0.258388</td>\n",
       "      <td>-0.458634</td>\n",
       "      <td>-0.584041</td>\n",
       "      <td>0.054881</td>\n",
       "      <td>-0.044935</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0     -0.321894     -1.277660       -0.346314  -0.389320        -0.010120   \n",
       "1     -0.444969     -0.961916       -0.417508  -0.509618         0.665798   \n",
       "2     -1.401746     -1.726718       -1.401378  -1.149042         0.310785   \n",
       "3     -0.458347     -0.328090       -0.534997  -0.499745        -0.564220   \n",
       "4     -1.751708     -0.697627       -1.737116  -1.336114        -0.830828   \n",
       "5     -0.720551     -1.214511       -0.712786  -0.693313         0.359512   \n",
       "6     -0.335272      0.579381       -0.367711  -0.403091        -0.725020   \n",
       "7     -0.798142      0.415662       -0.841945  -0.748915        -0.805072   \n",
       "8     -0.295138     -0.814569       -0.356040  -0.375030        -1.467764   \n",
       "9     -0.749982     -0.370189       -0.803431  -0.723712        -1.066808   \n",
       "10    -0.862355     -0.250908       -0.895632  -0.798021        -0.187627   \n",
       "11    -0.452996     -0.119933       -0.534997  -0.490911        -1.206725   \n",
       "12    -1.638800     -1.878742       -1.634799  -1.277394        -0.028915   \n",
       "13    -1.223554     -1.156040       -1.237594  -1.050309         1.076501   \n",
       "14    -1.644151      0.270654       -1.622350  -1.284409         1.835255   \n",
       "15    -1.490306     -1.394602       -1.445728  -1.182819        -1.442705   \n",
       "16    -1.412180      0.277670       -1.410326  -1.160734         0.450006   \n",
       "17    -0.918541     -0.183082       -0.955544  -0.836735        -1.151733   \n",
       "18    -1.528834     -0.583024       -1.461679  -1.209840         0.603149   \n",
       "19    -0.525236     -0.779486       -0.583237  -0.555087         0.026078   \n",
       "20    -1.566560     -1.212172       -1.461679  -1.226729        -0.007335   \n",
       "21    -0.650986     -0.772470       -0.668047  -0.637191        -0.432656   \n",
       "22    -0.324569     -2.077544       -0.328808  -0.407768         2.169386   \n",
       "23    -0.503831     -0.426321       -0.512433  -0.545214         0.097776   \n",
       "24    -0.881084      0.268315       -0.877348  -0.817508         0.853747   \n",
       "25    -0.375405     -0.926834       -0.384051  -0.509618         0.686682   \n",
       "26    -0.733928     -0.975949       -0.755191  -0.708902        -0.049102   \n",
       "27    -0.637609      0.462439       -0.645094  -0.649663        -0.711098   \n",
       "28    -0.027583     -1.071842       -0.023026  -0.166912         1.062578   \n",
       "29    -0.032934      0.981662       -0.069710  -0.138852        -0.570485   \n",
       "30    -0.394134     -1.184106       -0.452132  -0.427255        -1.697479   \n",
       "31    -0.345974     -0.356156       -0.379771  -0.418421         0.296863   \n",
       "32    -0.685769     -0.463743       -0.722512  -0.688636         0.456967   \n",
       "33    -1.326028      0.027414       -1.332519  -1.095518         0.310785   \n",
       "34    -0.840950     -1.633164       -0.856729  -0.788668        -0.564220   \n",
       "35    -2.076787     -1.495172       -2.045232  -1.487850         1.327098   \n",
       "36    -0.685769      0.163067       -0.744687  -0.668890        -1.239442   \n",
       "37    -1.302215     -0.098883       -1.260937  -1.085645         0.178525   \n",
       "38    -1.137937     -0.124611       -1.126330  -0.987432         0.136062   \n",
       "39    -0.830248     -0.349139       -0.824439  -0.788928         1.132189   \n",
       "40    -0.637609     -0.300024       -0.675049  -0.648104        -0.916449   \n",
       "41    -0.910515      0.336141       -0.929089  -0.830499        -0.720147   \n",
       "42    -1.328703     -0.662544       -1.317347  -1.106691         0.401278   \n",
       "43    -0.565369      0.219199       -0.552892  -0.612508         0.097080   \n",
       "44    -0.129254     -0.040412        0.057115  -0.224073        -1.361956   \n",
       "45    -1.132585      0.085885       -1.078479  -0.992369         0.992968   \n",
       "46    -1.609904     -0.933850       -1.576444  -1.260765         1.187877   \n",
       "47    -0.752657      0.399290       -0.771530  -0.721114        -0.017777   \n",
       "48    -1.549971     -0.950222       -1.463624  -1.223611        -0.230785   \n",
       "49    -0.891786     -2.105610       -0.895632  -0.812831        -0.292739   \n",
       "\n",
       "    compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "0          -0.577099       -0.447952            -0.230917       0.165181   \n",
       "1           0.219010       -0.696819            -0.640762       0.462603   \n",
       "2          -0.862207       -0.888219            -0.894371      -0.088717   \n",
       "3          -1.336981       -0.935000            -0.686628      -1.350949   \n",
       "4          -0.957824       -1.050647            -1.258424      -0.255563   \n",
       "5          -0.409378       -0.456501            -0.729305      -0.596511   \n",
       "6          -0.652164       -0.675091            -0.573559      -0.110479   \n",
       "7          -1.127983       -1.042455            -1.130075      -1.249390   \n",
       "8          -0.937621       -1.018708            -0.980951      -1.764438   \n",
       "9          -1.165429       -1.005053            -1.072682       0.103520   \n",
       "10         -1.039682       -0.878720            -0.844826       0.292129   \n",
       "11         -1.332976       -1.230981            -1.301346      -0.074208   \n",
       "12         -1.074689       -0.994486            -1.212264      -0.567494   \n",
       "13         -0.588942       -1.110489            -1.087152       3.277235   \n",
       "14         -0.431845       -0.882994            -1.176455      -0.041564   \n",
       "15         -0.468768       -0.528216            -0.868863       1.819140   \n",
       "16         -0.639102       -0.981306            -1.034665      -0.444173   \n",
       "17         -1.174137       -0.798812            -0.856599      -1.173221   \n",
       "18          0.468066        2.477186            -0.330497       0.984906   \n",
       "19         -1.081307       -0.805461            -0.701099      -0.904815   \n",
       "20          0.673581       -0.217370            -0.699136       0.226841   \n",
       "21         -0.803514       -0.838825            -0.846298      -0.433292   \n",
       "22         -0.169378       -0.422662             0.204436       2.044020   \n",
       "23         -0.330307       -0.777440            -0.835751      -0.440546   \n",
       "24         -0.362353       -0.694088            -0.855863       0.009215   \n",
       "25          0.680548        0.148806             0.310147       0.371925   \n",
       "26         -0.744994       -0.746331            -0.946613       0.868839   \n",
       "27         -0.347898       -0.525011            -0.485016       0.328400   \n",
       "28          0.339184       -0.055891             0.329032       1.003041   \n",
       "29         -0.494022       -0.870884            -0.678289      -0.560240   \n",
       "30         -1.112483       -0.852005            -0.754077      -1.644744   \n",
       "31         -0.570829       -0.767347            -0.721701      -0.730714   \n",
       "32         -0.763804       -0.943549            -0.682213       0.219587   \n",
       "33         -1.069638       -1.158114            -1.208880      -1.775320   \n",
       "34         -0.682295       -0.740988            -0.581898      -0.796002   \n",
       "35         -0.674806       -1.239197            -1.403550       0.328400   \n",
       "36         -1.289609       -0.956254            -0.969423      -0.364377   \n",
       "37         -0.304008       -0.508507            -0.660629       0.382807   \n",
       "38         -0.498899       -0.883588            -1.108981       1.369379   \n",
       "39         -0.221628       -0.399746            -0.548786      -0.139496   \n",
       "40         -0.805952       -0.925383            -0.932387      -0.861290   \n",
       "41         -0.847752       -0.629734            -0.937783      -1.278407   \n",
       "42         -0.529204       -0.724603            -0.967461      -0.926578   \n",
       "43          0.112769        0.025323             0.073217      -0.378885   \n",
       "44          1.896220        2.326393             0.509060      -0.491325   \n",
       "45          0.276485       -0.470274            -0.651064       0.299383   \n",
       "46         -0.564559       -0.748587            -0.931652      -0.690816   \n",
       "47         -0.625865       -0.844050            -0.911049      -0.549359   \n",
       "48          0.171985       -0.139362            -0.837468      -1.938539   \n",
       "49         -0.828593       -0.822202            -0.760208      -0.625528   \n",
       "\n",
       "    fractal_dimension_mean    ...      perimeter_worst  area_worst  \\\n",
       "0                -0.681058    ...            -0.403305   -0.442960   \n",
       "1                 0.650606    ...            -0.504294   -0.571976   \n",
       "2                 0.770393    ...            -1.370391   -1.076530   \n",
       "3                -0.557449    ...            -0.829640   -0.707227   \n",
       "4                 0.258116    ...            -1.590552   -1.192756   \n",
       "5                -0.328071    ...            -0.678017   -0.648554   \n",
       "6                -0.742225    ...            -0.422887   -0.462784   \n",
       "7                -0.525591    ...            -0.871042   -0.754229   \n",
       "8                -0.442760    ...            -0.504573   -0.530090   \n",
       "9                -0.242692    ...            -0.851740   -0.737123   \n",
       "10               -0.501379    ...            -0.903773   -0.770696   \n",
       "11               -1.018753    ...            -0.667946   -0.582208   \n",
       "12                1.129751    ...            -1.516699   -1.140478   \n",
       "13                0.840480    ...            -1.238071   -0.990679   \n",
       "14                0.581793    ...            -1.456274   -1.142077   \n",
       "15                0.844303    ...            -1.357523   -1.084204   \n",
       "16                0.762747    ...            -1.317239   -1.051270   \n",
       "17               -0.807216    ...            -1.010356   -0.833845   \n",
       "18                2.224392    ...            -1.360041   -1.060862   \n",
       "19               -0.825056    ...            -0.795790   -0.692839   \n",
       "20                3.414607    ...            -1.442286   -1.125291   \n",
       "21               -0.492459    ...            -0.682772   -0.602991   \n",
       "22                0.433972    ...            -0.636614   -0.611944   \n",
       "23               -0.386690    ...            -0.622067   -0.585405   \n",
       "24                0.897825    ...            -0.827681   -0.740480   \n",
       "25                0.766570    ...            -0.488348   -0.596916   \n",
       "26               -0.423645    ...            -0.736764   -0.672055   \n",
       "27                0.131958    ...            -0.633817   -0.661184   \n",
       "28                0.058048    ...            -0.131950   -0.295239   \n",
       "29               -0.553626    ...            -0.313786   -0.295079   \n",
       "30               -1.251954    ...            -0.269026   -0.252074   \n",
       "31               -0.752420    ...            -0.462331   -0.461825   \n",
       "32                0.426326    ...            -0.894541   -0.788282   \n",
       "33                0.751278    ...            -1.267444   -0.994676   \n",
       "34                0.358787    ...            -0.871602   -0.760624   \n",
       "35                1.933847    ...            -1.782179   -1.283883   \n",
       "36               -0.794473    ...            -0.826283   -0.704190   \n",
       "37                0.027464    ...            -1.172050   -1.002509   \n",
       "38                0.230081    ...            -1.116101   -0.936003   \n",
       "39                0.279779    ...            -0.800266   -0.745916   \n",
       "40               -0.298762    ...            -0.798868   -0.710105   \n",
       "41                0.291248    ...            -0.842788   -0.751671   \n",
       "42                0.974284    ...            -1.187157   -0.993237   \n",
       "43                0.980655    ...            -0.702634   -0.736803   \n",
       "44                1.871405    ...            -0.199089   -0.446477   \n",
       "45                1.887971    ...            -1.160861   -0.981406   \n",
       "46                1.698098    ...            -1.388575   -1.125291   \n",
       "47               -0.135649    ...            -0.743478   -0.647915   \n",
       "48                1.099167    ...            -1.420466   -1.148312   \n",
       "49               -0.238869    ...            -0.849782   -0.763822   \n",
       "\n",
       "    smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0           0.347717          -0.599768        -0.330357   \n",
       "1          -0.172664          -0.044818        -0.553059   \n",
       "2          -0.123879          -0.945575        -0.999933   \n",
       "3          -1.562651          -1.325188        -1.179608   \n",
       "4          -0.233647          -0.829937        -1.088434   \n",
       "5           0.567253          -0.387858        -0.036391   \n",
       "6          -0.782486          -0.634072        -0.378461   \n",
       "7          -1.095528          -1.104093        -1.148875   \n",
       "8          -1.079266          -0.705447        -0.927198   \n",
       "9          -0.855665          -1.087992        -0.984967   \n",
       "10         -0.428790          -1.098283        -0.990624   \n",
       "11         -1.355719          -1.238211        -1.386654   \n",
       "12          1.538902          -0.895226        -0.874640   \n",
       "13         -0.323087          -1.034876        -1.298308   \n",
       "14          1.156747          -0.641265        -0.993964   \n",
       "15         -1.507767          -0.652331        -0.772643   \n",
       "16          0.786788          -0.660077        -0.975658   \n",
       "17         -0.262105          -1.074603        -0.751709   \n",
       "18          0.518467           0.834361         4.181581   \n",
       "19         -0.237712          -1.190074        -0.932098   \n",
       "20         -0.599540          -0.232937        -0.756163   \n",
       "21         -0.725569          -0.561038        -0.636350   \n",
       "22          0.392437          -0.817765        -1.014542   \n",
       "23         -0.266170          -0.396157        -0.623878   \n",
       "24          0.823378          -0.653438        -0.613189   \n",
       "25          0.738003           1.070063         0.768899   \n",
       "26          0.091592          -0.472511        -0.385142   \n",
       "27         -0.205188          -0.217998        -0.310760   \n",
       "28         -0.314956           0.128362        -0.235041   \n",
       "29         -0.973564          -0.603641        -0.985591   \n",
       "30         -1.416701          -0.895779        -0.793577   \n",
       "31         -0.062896          -0.611941        -0.779770   \n",
       "32         -0.871927          -1.062983        -1.173061   \n",
       "33         -0.156402          -1.056621        -1.303609   \n",
       "34          0.311128          -0.556612        -0.538806   \n",
       "35          0.933146          -0.915697        -1.394872   \n",
       "36         -0.941040          -1.090427        -0.884885   \n",
       "37          0.831509          -0.307077        -0.217225   \n",
       "38         -0.550754          -0.758563        -1.039128   \n",
       "39          1.355955          -0.108999        -0.115227   \n",
       "40         -0.693046          -0.494643        -0.532125   \n",
       "41          1.400676          -0.365726        -0.005213   \n",
       "42          0.457485          -0.604195        -0.815847   \n",
       "43         -0.274301          -0.335849        -0.407858   \n",
       "44         -1.868375           0.739195         1.626300   \n",
       "45         -0.221450          -0.447060        -0.818074   \n",
       "46          1.502313          -0.272773        -0.300961   \n",
       "47          0.591645          -0.253408        -0.725430   \n",
       "48         -0.713373          -0.541120        -0.707169   \n",
       "49          0.786788          -0.258388        -0.458634   \n",
       "\n",
       "    concave points_worst  symmetry_worst  fractal_dimension_worst  Actual  \\\n",
       "0              -0.013812       -0.000465                -0.653024  Benign   \n",
       "1              -0.827573        0.293294                -0.208503  Benign   \n",
       "2              -0.981108       -0.748346                -0.405747  Benign   \n",
       "3              -1.157614       -1.405402                -1.177406  Benign   \n",
       "4              -1.513681        0.181183                -0.580862  Benign   \n",
       "5              -0.934437       -0.326865                -0.151735  Benign   \n",
       "6              -0.022535       -0.150893                -0.817555  Benign   \n",
       "7              -1.346334       -0.772471                -0.987859  Benign   \n",
       "8              -0.638127       -0.895935                -0.284514  Benign   \n",
       "9              -0.971076       -0.272938                -0.581343  Benign   \n",
       "10             -0.968168        0.466428                -0.760306  Benign   \n",
       "11             -1.724936       -0.763956                -1.119675  Benign   \n",
       "12             -1.243978        0.344383                 0.197050  Benign   \n",
       "13             -1.511500        0.822629                -0.286920  Benign   \n",
       "14             -1.482567       -0.007561                -0.435094  Benign   \n",
       "15             -1.146855        0.432369                -0.060811  Benign   \n",
       "16             -0.938944       -0.140959                 0.286051  Benign   \n",
       "17             -0.874390       -0.819302                -0.950334  Benign   \n",
       "18              0.657901        1.774864                 1.507522  Benign   \n",
       "19             -1.031268       -0.843427                -1.061464  Benign   \n",
       "20             -1.190618       -1.026495                 1.069736  Benign   \n",
       "21             -0.627368       -0.509932                -0.484645  Benign   \n",
       "22             -0.809545       -0.379372                -0.685738  Benign   \n",
       "23             -0.734086       -0.281452                -0.335990  Benign   \n",
       "24             -0.995647       -0.305578                 0.112861  Benign   \n",
       "25              0.596836        0.780055                 0.742599  Benign   \n",
       "26             -0.776832        0.570024                -0.333104  Benign   \n",
       "27             -0.134488       -0.007561                 0.310105  Benign   \n",
       "28              0.144666        0.246463                -0.068989  Benign   \n",
       "29             -0.876571       -0.646168                -0.659279  Benign   \n",
       "30             -0.431088       -1.348637                -1.159605  Benign   \n",
       "31             -0.736267       -0.424784                -0.968615  Benign   \n",
       "32             -1.031268       -1.064811                -0.596738  Benign   \n",
       "33             -1.540287       -1.480616                 0.178769  Benign   \n",
       "34             -0.658046       -0.291386                 0.067158  Benign   \n",
       "35             -1.886467       -0.064326                 0.368316  Benign   \n",
       "36             -0.806055       -0.402078                -0.836317  Benign   \n",
       "37             -0.469036       -0.504256                -0.060811  Benign   \n",
       "38             -1.420775       -0.214753                -0.512067  Benign   \n",
       "39             -0.115587       -0.243136                 0.231207  Benign   \n",
       "40             -0.659064        0.008050                -0.688625  Benign   \n",
       "41             -0.682908       -0.210496                 0.103720  Benign   \n",
       "42             -1.110943       -0.630558                -0.071394  Benign   \n",
       "43             -0.279880       -1.066230                -0.062735  Benign   \n",
       "44              0.301690       -0.822140                 1.060114  Benign   \n",
       "45             -0.994339       -0.843427                 0.197050  Benign   \n",
       "46             -0.359846       -0.072841                 0.747410  Benign   \n",
       "47             -0.832808       -0.765375                -0.036275  Benign   \n",
       "48             -1.327287       -1.880810                -0.430283  Benign   \n",
       "49             -0.584041        0.054881                -0.044935  Benign   \n",
       "\n",
       "    Predicted  \n",
       "0      Benign  \n",
       "1      Benign  \n",
       "2      Benign  \n",
       "3      Benign  \n",
       "4      Benign  \n",
       "5      Benign  \n",
       "6      Benign  \n",
       "7      Benign  \n",
       "8      Benign  \n",
       "9      Benign  \n",
       "10     Benign  \n",
       "11     Benign  \n",
       "12     Benign  \n",
       "13     Benign  \n",
       "14     Benign  \n",
       "15     Benign  \n",
       "16     Benign  \n",
       "17     Benign  \n",
       "18     Benign  \n",
       "19     Benign  \n",
       "20     Benign  \n",
       "21     Benign  \n",
       "22     Benign  \n",
       "23     Benign  \n",
       "24     Benign  \n",
       "25     Benign  \n",
       "26     Benign  \n",
       "27     Benign  \n",
       "28     Benign  \n",
       "29     Benign  \n",
       "30     Benign  \n",
       "31     Benign  \n",
       "32     Benign  \n",
       "33     Benign  \n",
       "34     Benign  \n",
       "35     Benign  \n",
       "36     Benign  \n",
       "37     Benign  \n",
       "38     Benign  \n",
       "39     Benign  \n",
       "40     Benign  \n",
       "41     Benign  \n",
       "42     Benign  \n",
       "43     Benign  \n",
       "44     Benign  \n",
       "45     Benign  \n",
       "46     Benign  \n",
       "47     Benign  \n",
       "48     Benign  \n",
       "49     Benign  \n",
       "\n",
       "[50 rows x 32 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the predictive data in csv format\n",
    "data.to_csv(r\"C:\\Users\\sathish kumar\\Downloads\\predictive data\\result.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.321894</td>\n",
       "      <td>-1.277660</td>\n",
       "      <td>-0.346314</td>\n",
       "      <td>-0.389320</td>\n",
       "      <td>-0.010120</td>\n",
       "      <td>-0.577099</td>\n",
       "      <td>-0.447952</td>\n",
       "      <td>-0.230917</td>\n",
       "      <td>0.165181</td>\n",
       "      <td>-0.681058</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.403305</td>\n",
       "      <td>-0.442960</td>\n",
       "      <td>0.347717</td>\n",
       "      <td>-0.599768</td>\n",
       "      <td>-0.330357</td>\n",
       "      <td>-0.013812</td>\n",
       "      <td>-0.000465</td>\n",
       "      <td>-0.653024</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.444969</td>\n",
       "      <td>-0.961916</td>\n",
       "      <td>-0.417508</td>\n",
       "      <td>-0.509618</td>\n",
       "      <td>0.665798</td>\n",
       "      <td>0.219010</td>\n",
       "      <td>-0.696819</td>\n",
       "      <td>-0.640762</td>\n",
       "      <td>0.462603</td>\n",
       "      <td>0.650606</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.504294</td>\n",
       "      <td>-0.571976</td>\n",
       "      <td>-0.172664</td>\n",
       "      <td>-0.044818</td>\n",
       "      <td>-0.553059</td>\n",
       "      <td>-0.827573</td>\n",
       "      <td>0.293294</td>\n",
       "      <td>-0.208503</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.401746</td>\n",
       "      <td>-1.726718</td>\n",
       "      <td>-1.401378</td>\n",
       "      <td>-1.149042</td>\n",
       "      <td>0.310785</td>\n",
       "      <td>-0.862207</td>\n",
       "      <td>-0.888219</td>\n",
       "      <td>-0.894371</td>\n",
       "      <td>-0.088717</td>\n",
       "      <td>0.770393</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.370391</td>\n",
       "      <td>-1.076530</td>\n",
       "      <td>-0.123879</td>\n",
       "      <td>-0.945575</td>\n",
       "      <td>-0.999933</td>\n",
       "      <td>-0.981108</td>\n",
       "      <td>-0.748346</td>\n",
       "      <td>-0.405747</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.458347</td>\n",
       "      <td>-0.328090</td>\n",
       "      <td>-0.534997</td>\n",
       "      <td>-0.499745</td>\n",
       "      <td>-0.564220</td>\n",
       "      <td>-1.336981</td>\n",
       "      <td>-0.935000</td>\n",
       "      <td>-0.686628</td>\n",
       "      <td>-1.350949</td>\n",
       "      <td>-0.557449</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.829640</td>\n",
       "      <td>-0.707227</td>\n",
       "      <td>-1.562651</td>\n",
       "      <td>-1.325188</td>\n",
       "      <td>-1.179608</td>\n",
       "      <td>-1.157614</td>\n",
       "      <td>-1.405402</td>\n",
       "      <td>-1.177406</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.751708</td>\n",
       "      <td>-0.697627</td>\n",
       "      <td>-1.737116</td>\n",
       "      <td>-1.336114</td>\n",
       "      <td>-0.830828</td>\n",
       "      <td>-0.957824</td>\n",
       "      <td>-1.050647</td>\n",
       "      <td>-1.258424</td>\n",
       "      <td>-0.255563</td>\n",
       "      <td>0.258116</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.590552</td>\n",
       "      <td>-1.192756</td>\n",
       "      <td>-0.233647</td>\n",
       "      <td>-0.829937</td>\n",
       "      <td>-1.088434</td>\n",
       "      <td>-1.513681</td>\n",
       "      <td>0.181183</td>\n",
       "      <td>-0.580862</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0    -0.321894     -1.277660       -0.346314  -0.389320        -0.010120   \n",
       "1    -0.444969     -0.961916       -0.417508  -0.509618         0.665798   \n",
       "2    -1.401746     -1.726718       -1.401378  -1.149042         0.310785   \n",
       "3    -0.458347     -0.328090       -0.534997  -0.499745        -0.564220   \n",
       "4    -1.751708     -0.697627       -1.737116  -1.336114        -0.830828   \n",
       "\n",
       "   compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "0         -0.577099       -0.447952            -0.230917       0.165181   \n",
       "1          0.219010       -0.696819            -0.640762       0.462603   \n",
       "2         -0.862207       -0.888219            -0.894371      -0.088717   \n",
       "3         -1.336981       -0.935000            -0.686628      -1.350949   \n",
       "4         -0.957824       -1.050647            -1.258424      -0.255563   \n",
       "\n",
       "   fractal_dimension_mean    ...      perimeter_worst  area_worst  \\\n",
       "0               -0.681058    ...            -0.403305   -0.442960   \n",
       "1                0.650606    ...            -0.504294   -0.571976   \n",
       "2                0.770393    ...            -1.370391   -1.076530   \n",
       "3               -0.557449    ...            -0.829640   -0.707227   \n",
       "4                0.258116    ...            -1.590552   -1.192756   \n",
       "\n",
       "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
       "0          0.347717          -0.599768        -0.330357             -0.013812   \n",
       "1         -0.172664          -0.044818        -0.553059             -0.827573   \n",
       "2         -0.123879          -0.945575        -0.999933             -0.981108   \n",
       "3         -1.562651          -1.325188        -1.179608             -1.157614   \n",
       "4         -0.233647          -0.829937        -1.088434             -1.513681   \n",
       "\n",
       "   symmetry_worst  fractal_dimension_worst  Actual  Predicted  \n",
       "0       -0.000465                -0.653024  Benign     Benign  \n",
       "1        0.293294                -0.208503  Benign     Benign  \n",
       "2       -0.748346                -0.405747  Benign     Benign  \n",
       "3       -1.405402                -1.177406  Benign     Benign  \n",
       "4        0.181183                -0.580862  Benign     Benign  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading the csv file\n",
    "df=pd.read_csv(r\"C:\\Users\\sathish kumar\\Downloads\\predictive data\\result.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Tumor_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.321894</td>\n",
       "      <td>-1.277660</td>\n",
       "      <td>-0.346314</td>\n",
       "      <td>-0.389320</td>\n",
       "      <td>-0.010120</td>\n",
       "      <td>-0.577099</td>\n",
       "      <td>-0.447952</td>\n",
       "      <td>-0.230917</td>\n",
       "      <td>0.165181</td>\n",
       "      <td>-0.681058</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.165488</td>\n",
       "      <td>-0.403305</td>\n",
       "      <td>-0.442960</td>\n",
       "      <td>0.347717</td>\n",
       "      <td>-0.599768</td>\n",
       "      <td>-0.330357</td>\n",
       "      <td>-0.013812</td>\n",
       "      <td>-0.000465</td>\n",
       "      <td>-0.653024</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.444969</td>\n",
       "      <td>-0.961916</td>\n",
       "      <td>-0.417508</td>\n",
       "      <td>-0.509618</td>\n",
       "      <td>0.665798</td>\n",
       "      <td>0.219010</td>\n",
       "      <td>-0.696819</td>\n",
       "      <td>-0.640762</td>\n",
       "      <td>0.462603</td>\n",
       "      <td>0.650606</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.968553</td>\n",
       "      <td>-0.504294</td>\n",
       "      <td>-0.571976</td>\n",
       "      <td>-0.172664</td>\n",
       "      <td>-0.044818</td>\n",
       "      <td>-0.553059</td>\n",
       "      <td>-0.827573</td>\n",
       "      <td>0.293294</td>\n",
       "      <td>-0.208503</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.401746</td>\n",
       "      <td>-1.726718</td>\n",
       "      <td>-1.401378</td>\n",
       "      <td>-1.149042</td>\n",
       "      <td>0.310785</td>\n",
       "      <td>-0.862207</td>\n",
       "      <td>-0.888219</td>\n",
       "      <td>-0.894371</td>\n",
       "      <td>-0.088717</td>\n",
       "      <td>0.770393</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.741884</td>\n",
       "      <td>-1.370391</td>\n",
       "      <td>-1.076530</td>\n",
       "      <td>-0.123879</td>\n",
       "      <td>-0.945575</td>\n",
       "      <td>-0.999933</td>\n",
       "      <td>-0.981108</td>\n",
       "      <td>-0.748346</td>\n",
       "      <td>-0.405747</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.458347</td>\n",
       "      <td>-0.328090</td>\n",
       "      <td>-0.534997</td>\n",
       "      <td>-0.499745</td>\n",
       "      <td>-0.564220</td>\n",
       "      <td>-1.336981</td>\n",
       "      <td>-0.935000</td>\n",
       "      <td>-0.686628</td>\n",
       "      <td>-1.350949</td>\n",
       "      <td>-0.557449</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.597098</td>\n",
       "      <td>-0.829640</td>\n",
       "      <td>-0.707227</td>\n",
       "      <td>-1.562651</td>\n",
       "      <td>-1.325188</td>\n",
       "      <td>-1.179608</td>\n",
       "      <td>-1.157614</td>\n",
       "      <td>-1.405402</td>\n",
       "      <td>-1.177406</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.751708</td>\n",
       "      <td>-0.697627</td>\n",
       "      <td>-1.737116</td>\n",
       "      <td>-1.336114</td>\n",
       "      <td>-0.830828</td>\n",
       "      <td>-0.957824</td>\n",
       "      <td>-1.050647</td>\n",
       "      <td>-1.258424</td>\n",
       "      <td>-0.255563</td>\n",
       "      <td>0.258116</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.733191</td>\n",
       "      <td>-1.590552</td>\n",
       "      <td>-1.192756</td>\n",
       "      <td>-0.233647</td>\n",
       "      <td>-0.829937</td>\n",
       "      <td>-1.088434</td>\n",
       "      <td>-1.513681</td>\n",
       "      <td>0.181183</td>\n",
       "      <td>-0.580862</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0    -0.321894     -1.277660       -0.346314  -0.389320        -0.010120   \n",
       "1    -0.444969     -0.961916       -0.417508  -0.509618         0.665798   \n",
       "2    -1.401746     -1.726718       -1.401378  -1.149042         0.310785   \n",
       "3    -0.458347     -0.328090       -0.534997  -0.499745        -0.564220   \n",
       "4    -1.751708     -0.697627       -1.737116  -1.336114        -0.830828   \n",
       "\n",
       "   compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "0         -0.577099       -0.447952            -0.230917       0.165181   \n",
       "1          0.219010       -0.696819            -0.640762       0.462603   \n",
       "2         -0.862207       -0.888219            -0.894371      -0.088717   \n",
       "3         -1.336981       -0.935000            -0.686628      -1.350949   \n",
       "4         -0.957824       -1.050647            -1.258424      -0.255563   \n",
       "\n",
       "   fractal_dimension_mean     ...      texture_worst  perimeter_worst  \\\n",
       "0               -0.681058     ...          -1.165488        -0.403305   \n",
       "1                0.650606     ...          -0.968553        -0.504294   \n",
       "2                0.770393     ...          -1.741884        -1.370391   \n",
       "3               -0.557449     ...          -0.597098        -0.829640   \n",
       "4                0.258116     ...          -0.733191        -1.590552   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0   -0.442960          0.347717          -0.599768        -0.330357   \n",
       "1   -0.571976         -0.172664          -0.044818        -0.553059   \n",
       "2   -1.076530         -0.123879          -0.945575        -0.999933   \n",
       "3   -0.707227         -1.562651          -1.325188        -1.179608   \n",
       "4   -1.192756         -0.233647          -0.829937        -1.088434   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  Tumor_type  \n",
       "0             -0.013812       -0.000465                -0.653024           0  \n",
       "1             -0.827573        0.293294                -0.208503           0  \n",
       "2             -0.981108       -0.748346                -0.405747           0  \n",
       "3             -1.157614       -1.405402                -1.177406           0  \n",
       "4             -1.513681        0.181183                -0.580862           0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=data1\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing data for train,test and split\n",
    "x=data.iloc[:, 0:30].values\n",
    "y= data.Tumor_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y,test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(499, 30)\n",
      "(215, 30)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(499,)\n",
      "(215,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyper Parameters: {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 25, 'n_jobs': -1}\n",
      "Training Accuracy: 1.0000\n",
      "Testing Accuracy: {:.4f} 0.9813953488372092\n",
      "Confusion Metrix:\n",
      " [[107   3]\n",
      " [  1 104]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.99      0.97      0.98       107\n",
      "          0       0.97      0.99      0.98       108\n",
      "\n",
      "avg / total       0.98      0.98      0.98       215\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RF_model=RandomForestClassifier(random_state = 123)\n",
    "#hyper parameters set \n",
    "params = {'criterion':['gini','entropy'],\n",
    "          'n_estimators':[10,15,20,25,30],\n",
    "          'min_samples_leaf':[1,2,3,4,5],\n",
    "          'min_samples_split':[2,3,4,5,6], \n",
    "          'n_jobs':[-1]}\n",
    "#Making models with hyper parameters sets\n",
    "RF_model = GridSearchCV(RF_model, param_grid=params, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
    "#Learning\n",
    "RF_model.fit(x_train,y_train)\n",
    "#The best hyper parameters set\n",
    "print(\"Best Hyper Parameters:\",RF_model.best_params_)\n",
    "#Prediction\n",
    "prediction=RF_model.predict(x_test)\n",
    "#importing the metrics module\n",
    "from sklearn import metrics\n",
    "#evaluation(Train Score)\n",
    "train_score=RF_model.score(x_train,y_train)\n",
    "print('Training Accuracy: {:.4f}'.format(train_score))\n",
    "#evaluation(Accuracy)\n",
    "print(\"Testing Accuracy: {:.4f}\",metrics.accuracy_score(prediction,y_test))\n",
    "#evaluation(Confusion Metrix)\n",
    "print(\"Confusion Metrix:\\n\",metrics.confusion_matrix(prediction,y_test))\n",
    "#evaluation(Classification_report)\n",
    "print(\"Classification Report:\\n\",metrics.classification_report(y_test, prediction, labels=[1,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tumor_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Tumor_type\n",
       "339           0\n",
       "142           0\n",
       "243           0\n",
       "236           0\n",
       "712           1"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tumortype=pd.DataFrame(y_test)\n",
    "tumortype.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    108\n",
       "1    107\n",
       "Name: Tumor_type, dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#counting the labels in tumor_type\n",
    "tumortype['Tumor_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[107   3]\n",
      " [  1 104]]\n"
     ]
    }
   ],
   "source": [
    "test_score=metrics.accuracy_score(prediction,y_test)\n",
    "cm = metrics.confusion_matrix(prediction,y_test)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1405069a588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(9,9))\n",
    "sns.heatmap(cm, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Blues_r');\n",
    "plt.ylabel('Actual label');\n",
    "plt.xlabel('Predicted label');\n",
    "title = 'Accuracy Score: {0}'.format(test_score)\n",
    "plt.title(title, size = 15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Actual  Predicted\n",
       "339       0          0\n",
       "142       0          0\n",
       "243       0          0\n",
       "236       0          0\n",
       "712       1          1"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Actual': y_test, 'Predicted': prediction})  \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Actual Predicted\n",
      "339  Benign    Benign\n",
      "142  Benign    Benign\n",
      "243  Benign    Benign\n",
      "236  Benign    Benign\n",
      "712  Malign    Malign\n",
      "471  Malign    Malign\n",
      "504  Malign    Malign\n",
      "40   Benign    Benign\n",
      "366  Malign    Malign\n",
      "85   Benign    Benign\n",
      "231  Benign    Benign\n",
      "252  Benign    Benign\n",
      "548  Malign    Malign\n",
      "648  Malign    Malign\n",
      "688  Malign    Malign\n",
      "14   Benign    Benign\n",
      "193  Benign    Benign\n",
      "509  Malign    Malign\n",
      "316  Benign    Benign\n",
      "632  Malign    Malign\n",
      "103  Benign    Benign\n",
      "279  Benign    Benign\n",
      "8    Benign    Benign\n",
      "380  Malign    Malign\n",
      "478  Malign    Malign\n",
      "374  Malign    Malign\n",
      "261  Benign    Benign\n",
      "55   Benign    Benign\n",
      "576  Malign    Malign\n",
      "31   Benign    Benign\n",
      "..      ...       ...\n",
      "418  Malign    Malign\n",
      "454  Malign    Malign\n",
      "350  Benign    Benign\n",
      "436  Malign    Malign\n",
      "704  Malign    Malign\n",
      "196  Benign    Benign\n",
      "258  Benign    Benign\n",
      "165  Benign    Benign\n",
      "242  Benign    Benign\n",
      "651  Malign    Malign\n",
      "34   Benign    Benign\n",
      "520  Malign    Malign\n",
      "425  Malign    Malign\n",
      "710  Malign    Malign\n",
      "222  Benign    Benign\n",
      "426  Malign    Malign\n",
      "591  Malign    Malign\n",
      "155  Benign    Benign\n",
      "635  Malign    Malign\n",
      "435  Malign    Malign\n",
      "333  Benign    Benign\n",
      "200  Benign    Benign\n",
      "419  Malign    Malign\n",
      "621  Malign    Malign\n",
      "12   Benign    Benign\n",
      "161  Benign    Benign\n",
      "397  Malign    Malign\n",
      "497  Malign    Malign\n",
      "703  Malign    Malign\n",
      "592  Malign    Malign\n",
      "\n",
      "[215 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df['Actual']=df['Actual'].map({1:\"Malign\",0:\"Benign\"})\n",
    "df['Predicted']=df['Predicted'].map({1:\"Malign\",0:\"Benign\"})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
